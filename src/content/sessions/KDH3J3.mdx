---
code: KDH3J3
delivery: in-person
duration: '30'
end: '2024-07-12T14:30:00+02:00'
level: intermediate
next_session: FYHQUE
prev_session: GP8AMS
resources:
- description: slides
  resource: https://program.europython.eu/media/europython-2024/submissions/KDH3J3/resources/EuroPython_2024_MLtraq_VSqSvRZ.pdf
room: Terrace 2A
session_type: Talk
sessions_after:
- 89RTNU
- FYHQUE
- HX9ZWH
- N7ZC9X
- TBBKAM
- WBFDNJ
sessions_before:
- 9VFEQE
- GP8AMS
- JJAKNR
- JRGVQM
- KVNTFE
- PYV9VD
- XLGEHC
- XPXYWD
- XYXR3L
sessions_in_parallel:
- 7CJVKM
- 8FKHES
- HZSGYK
- YMMFGD
- ZXXDBV
slug: mltraq-track-your-ml-ai-experiments-at-hyperspeed
speakers:
- michele-dallachiesa
start: '2024-07-12T14:00:00+02:00'
title: 'MLtraq: Track your ML/AI experiments at hyperspeed'
track: 'PyData: Research & Applications'
tweet: ''
website_url: https://ep2024.europython.eu/session/mltraq-track-your-ml-ai-experiments-at-hyperspeed
---

Every second spent waiting for initializations and obscure delays hindering high-frequency logging, further limited by what you can track, an experiment dies. Wouldnâ€™t loading and starting tracking in nearly zero time be nice? What if we could track more and faster, even handling arbitrarily large, complex Python objects with ease?

In this talk, I will present the results of comparative benchmarks covering Weights & Biases, MLflow, FastTrackML, Neptune, Aim, Comet, and MLtraq. You will learn their strengths and weaknesses, what makes them slow and fast, and what sets MLtraq apart, making it 100x faster and capable of handling tens of thousands of experiments.

This presentation will not only be enlightening for those involved in AI/ML experimentation but will also be invaluable for anyone interested in the efficient and safe serialization of Python objects.
