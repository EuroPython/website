---
code: LBYSLP
delivery: in-person
duration: '30'
end: '2024-07-11T11:50:00+02:00'
level: intermediate
next_session: NDUKDX
prev_session: DMV8BL
resources: null
room: Terrace 2A
session_type: Talk
sessions_after:
- A3QRK3
- BUH9SD
- CMETS8
- KLXQAM
- KXF8JY
- NDUKDX
- NFCPVM
- QQMDWQ
- RSRDBM
sessions_before:
- 7PEXTK
- DMV8BL
- K3CJUX
- K77Z8V
- PZKNPZ
- UFURPH
sessions_in_parallel:
- BUT9E7
- NKFDPW
- R3P9UX
- SHUQ9L
- W97HPJ
slug: forecasting-the-future-with-earthpt
speakers:
- mike-smith
start: '2024-07-11T11:20:00+02:00'
title: Forecasting the future with EarthPT
track: 'PyData: LLMs'
tweet: EarthPT is a time series earth observation foundation model trained on TBs
  of satellite imagery.  It can predict future satellite observations and produces
  embeddings that can be used downstream.
website_url: https://ep2024.europython.eu/session/forecasting-the-future-with-earthpt
---

We introduce EarthPT -- an open source Earth Observation (EO) pretrained transformer written in Python and PyTorch. EarthPT is a 700 million parameter decoding transformer foundation model trained in an autoregressive self-supervised manner and developed specifically with EO use-cases in mind.

EarthPT is trained on time series derived from satellite imagery, and can accurately predict future pixel-level surface reflectances across the 400-2300 nm range well into the future. For example, forecasts of the evolution of the Normalised Difference Vegetation Index (NDVI) have a typical error of approximately 0.05 (over a natural range of -1 -> 1) at the pixel level over a five month test set horizon, out-performing simple phase-folded models based on historical averaging. We also demonstrate that embeddings learnt by EarthPT hold semantically meaningful information and could be exploited for downstream tasks such as highly granular, dynamic land use classification, crop yield, and drought prediction.

Excitingly, we note that the abundance of EO data provides us with -- in theory -- quadrillions of training tokens. Therefore, if we assume that EarthPT follows neural scaling laws akin to those derived for Large Language Models (LLMs), there is currently no data-imposed limit to scaling EarthPT and other similar ‘Large Observation Models.’

EarthPT is released under the MIT licence here: https://github.com/aspiaspace/EarthPT.
