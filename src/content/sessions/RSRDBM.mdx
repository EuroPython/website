---
code: RSRDBM
delivery: in-person
duration: '30'
end: '2024-07-11T12:25:00+02:00'
level: intermediate
next_session: DNYFYG
prev_session: BUT9E7
resources: null
room: Forum Hall
session_type: Talk
sessions_after:
- BUH9SD
- CEW8S9
- DNYFYG
- KHTUSV
- KLXQAM
- KXF8JY
- PSGLDJ
- VFMXAD
- WKLEEW
sessions_before:
- BUT9E7
- LBYSLP
- R3P9UX
- SHUQ9L
- W97HPJ
- XLGEHC
sessions_in_parallel:
- A3QRK3
- CMETS8
- NDUKDX
- NFCPVM
- QQMDWQ
slug: lies-damned-lies-and-large-language-models
speakers:
- jodie-burchell
start: '2024-07-11T11:55:00+02:00'
title: Lies, damned lies and large language models
track: 'PyData: LLMs'
tweet: Want to use LLMs, but are troubled by their tendency to hallucinate? Find out
  how to both measure and moderate hallucinations in Python in this talk.
website_url: https://ep2024.europython.eu/session/lies-damned-lies-and-large-language-models
---

Would you like to use large language models (LLMs) in your own project, but are troubled by their tendency to frequently “hallucinate”, or produce incorrect information? Have you ever wondered if there was a way to easily measure an LLM’s hallucination rate, and compare this against other models? And would you like to learn how to help LLMs produce more accurate information?

In this talk, we’ll have a look at some of the main reasons that hallucinations occur in LLMs, and then focus on how we can measure one specific type of hallucination: the tendency of models to regurgitate misinformation that they have learned from their training data. We’ll explore how we can easily measure this type of hallucination in LLMs using a dataset called TruthfulQA in conjunction with Python tooling including Hugging Face’s `datasets` and `transformers` packages, and the `langchain` package.

We’ll end by looking at recent initiatives to reduce hallucinations in LLMs, using a technique called retrieval augmented generation (RAG). We’ll look at how and why RAG makes LLMs less likely to hallucinate, and how this can help make these models more reliable and usable in a range of contexts.
