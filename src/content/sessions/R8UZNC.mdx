---
code: R8UZNC
delivery: in-person
duration: "30"
end: null
level: intermediate
next_talk_code: null
prev_talk_code: null
room: null
slug: which-llm-said-that-watermarking-generated-text
speakers:
  - adam-kaczmarek
start: null
state: confirmed
submission_type: Talk
talks_after: null
talks_in_parallel: null
title: Which LLM said that? - watermarking generated text
track: "PyData: LLMs"
tweet: ""
website_url: https://ep2024.europython.eu/session/which-llm-said-that-watermarking-generated-text
---

With the emergence of large generative language models there comes a problem of
assigning the authorship of the AI-generated texts to its original source. This
raises many concerns regarding eg. social engineering, fake news generation and
cheating in many educational assignments. While there are several black-box
methods for detecting if text was written by human or LLM they have significant
issues.

I will discuss how by watermarking you can equip your LLM with a mechanism that
undetectable to human eye can give you the means of verifying if it was the true
source of a generated text.
