[
  {
    "code": "LTMDS9",
    "title": "The Geometry of the Universe",
    "speakers": [
      {
        "code": "SVGULC",
        "name": "John Gill",
        "biography": "I grew up in Yorkshire, UK and always had an interest in space.\r\n\r\nI was lucky enough to be taught by Colin Rourke, when studying mathematics at Warwick some 40 years ago.\r\n\r\nAfter graduating I worked with computers for all my career, using python and linux almost exclusively since 2000.\r\n\r\nThis included a period of many years living and working in Dublin, when I first discovered the python world.\r\n\r\nMy interest in space-time has been rekindled by Colin Rourke's work, after many years of assuming astronomy only had minor details to work out.\r\n\r\nI am now semi-retired, teaching skiing in the winter and do some python mentoring as well.\r\n\r\nI write code to help me explore the universe.",
        "avatar": null,
        "slug": "john-gill"
      }
    ],
    "submission_type": "Poster",
    "slug": "the-geometry-of-the-universe",
    "track": "Python Friends",
    "state": "confirmed",
    "abstract": "A place to come and talk about the geometry of the universe.\r\n\r\nSagittarius A* and where is the Sun?\r\n\r\ngamma ray bursts\r\n\r\ngravitational waves.\r\n\r\nWhat will James Webb see?\r\n\r\nHow to test different models?\r\n\r\nPython, matplotlib, scipy, astropy\r\n\r\nunits and constants.   Hubble and c\r\n\r\nBut maybe Hubble's not constant?",
    "description": "",
    "duration": "60",
    "python_level": "",
    "domain_level": ""
  },
  {
    "code": "7DJJMK",
    "title": "PySnooper: Never use print for debugging again",
    "speakers": [
      {
        "code": "RJ7N8Z",
        "name": "Ram Rachum",
        "biography": "Ram Rachum is a software developer specializing in Python, and a Fellow of the Python Software Foundation.\r\n\r\nWhen he's not writing his biography in the third person, Ram is doing Python infrastructure work for clients, giving Python training to teams that would like to deepen their Python skills, and organizing the bi-monthly PyWeb-IL conference.",
        "avatar": "https://program.europython.eu/media/avatars/Cyan_background_square_hqn11tb.jpg",
        "slug": "ram-rachum"
      }
    ],
    "submission_type": "Talk",
    "slug": "pysnooper-never-use-print-for-debugging-again",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "I had an idea for a debugging solution for Python that doesn't require complicated configuration like PyCharm. I released PySnooper as a cute little open-source project that does that, and to my surprise, it became a huge hit overnight, hitting the top of Hacker News, r/python and GitHub trending.\r\nIn this talk I'll go into:\r\n\r\n* How PySnooper can help you debug your code.\r\n* How you can write your own debugging / code intelligence tools.\r\n* How to make your open-source project go viral.\r\n* How to use PuDB, another debugging solution, to find bugs in your code.\r\n* A PEP idea for making debuggers easier to debug.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "LLC3KD",
    "title": "Game Development with CircuitPython",
    "speakers": [
      {
        "code": "CSLXTY",
        "name": "Radomir Dopieralski",
        "biography": "A Python programmer by day, an electronics hobbyist by night. Building spider robots, hand-held game consoles, ergonomic keyboards and all kinds of gadgets. Very much into CircuitPython.",
        "avatar": "https://program.europython.eu/media/avatars/gogles-big_OCjYWs4.jpg",
        "slug": "radomir-dopieralski"
      }
    ],
    "submission_type": "Talk",
    "slug": "game-development-with-circuitpython",
    "track": "Makers",
    "state": "confirmed",
    "abstract": "With a large selection of handheld devices running CircuitPython, it's natural to want to make games for them. But where to start? What are the options available for the hardware, the libraries and other resources? And how do you use all of that? This talk aims to give a gentle introduction for everyone.",
    "description": "Making games on small devices is great fun and also a great way to learn. You don't have to worry about breaking anything, and the games tend to be much simpler than on the big computers. And with CircuitPython you don't need to install anything on your computer, all you need is a text editor. But it's not easy to decide what you need exactly: what hardware to get, which libraries to use and how to actually put it all together to spend the minimum time on all that, and maximum time on the game itself? I'm going to go over the available options, their pros and cons, and show some examples to get you started.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "G7MNXY",
    "title": "From pip to poetry - Python (many) ways of packaging and publishing",
    "speakers": [
      {
        "code": "PK8LSS",
        "name": "Vinícius Gubiani Ferreira",
        "biography": "Love to code, to read other people's code, and to help others achieve what they want with code. Be it directly or by guiding them to find out for themselves.",
        "avatar": "https://program.europython.eu/media/avatars/profile_xKpnCpq.jpeg",
        "slug": "vinicius-gubiani-ferreira"
      }
    ],
    "submission_type": "Talk",
    "slug": "from-pip-to-poetry-python-many-ways-of-packaging-and-publishing",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Ever had issues to manage your python packages and environment? Do you know how to create and share a package to the community? It can be challenging if you've never done it, but it also doesn't have to be hard. There is always a better tool to fit our needs.\r\n\r\nIn this presentation, I'd like to discuss how Python's package managers appeared and evolved with time. Discussing pip, pipenv, and poetry, presenting each of their weak and strong points. Also intend to present how to package and publish a simple code with each one of them, and suggest which package manager should you choose, whether you are just starting with python, or feel like there is something bothering and never knew you could solve it easily and painless.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "CXADJQ",
    "title": "How To Train Your Graphics Card (To Read)",
    "speakers": [
      {
        "code": "F3JRJQ",
        "name": "Matthew Carrigan",
        "biography": "Hi! I used to be a biologist, then I became a computational biologist, and then I gave up all pretense and started coding full-time. I'm currently a machine learning engineer at Hugging Face, but sometimes I try to sneak in some protein models into my job, for old time's sake.",
        "avatar": "https://program.europython.eu/media/avatars/matt_UBJfvPM.png",
        "slug": "matthew-carrigan"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "how-to-train-your-graphics-card-to-read",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "This tutorial aims to introduce new users to modern NLP using the open-source HuggingFace Transformers library. We'll use massive, pre-existing language models that you might have heard of like BERT and GPT to solve real-world tasks. By the end of this tutorial you'll be able to classify documents, get your computer to read a text and answer questions about it, and even translate between languages!",
    "description": "Most practical machine learning these days is \"supervised learning\". In supervised learning, we show a model a collection of example inputs and outputs, and train it to give the right output for each input. For example, we might show it pictures of animals, combined with a \"label\" for each picture like \"cat\" or \"dog\", in order to train it to identify which animal is in each photo. Or we could show it samples of text from Twitter posts, and give the tweets \"labels\" like \"toxic\" or \"not toxic\", in order to train it to identify unwanted tweets and filter them out automatically. In effect, the model learns to predict the correct \"label\" for any input that it sees.\r\n\r\nThe golden rule in supervised learning is that the more data you have, the better the model you can train. More data means more accuracy, whether the task is recognizing animals in images, or classifying text, or even driving a self-driving car. This is a real problem, though, when data collection isn't free; without a huge dataset of inputs and labels, it might be hard or impossible to train a model that's accurate enough for what you want it to do.\r\n\r\nProbably the single biggest revolution in machine learning in the last 5 years, particularly in NLP (natural language processing), has been the arrival of \"foundation models\", huge models trained for very long periods on vast amounts of text data. These models offer a solution to the problem of limited training data - by bringing a huge amount of linguistic prior knowledge with them, they greatly reduce the amount of data needed to learn a new task. In 2016, training a model to classify toxic comments might have required millions (or even tens of millions!) of examples and labels in order to achieve acceptable accuracy, but in 2022, we can start with a foundation model that already \"knows\" a lot about language, and achieve the same accuracy with a tiny fraction of that, and in a much shorter time, too!\r\n\r\nFoundation models can be intimidating, though - they're often created by industrial or academic research labs and published in papers that can be very impenetrable for people without a strong research background. In this tutorial, we'll show you how to abstract away that complexity and load, train and use foundation models without needing a Ph.D, or even any prior experience in machine learning! By the end of this 3-hour session, you should have the knowledge and code samples you need to train a better machine learning model than someone at the cutting edge of the field in 2016 could have achieved even with an entire research team.\r\n\r\nIn this course, we will use HuggingFace Transformers combined with the TensorFlow machine learning library. We will also use some of the most popular data science libraries in Python like Numpy and Pandas when preparing our data. You don't have to be familiar with any of these before attending the tutorial, and I'll do my best to explain what we're doing with them as we go! I don't assume any specific background in machine learning, and we won't need any mathematics beyond high school level. I will, however, assume that you're reasonably fluent in Python!",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "RMLCKR",
    "title": "A Personal Brand? Surprise, you already have one!",
    "speakers": [
      {
        "code": "7RBHLZ",
        "name": "Frédéric Harper",
        "biography": "As the Director of Developer Relations at Mindee, Frédéric Harper helps developers merge the physical and digital worlds using the magic of machine learning coupled with the ease of APIs. Fred has shared his passion for technology on the stage at dozens of events around the world. He’s helped build successful communities at npm, Mozilla, Microsoft, DigitalOcean, and Fitbit, and is the author of the book Personal Branding for Developers at Apress. Behind this extrovert is a very passionate individual who believes in the power of communication... and cat videos.",
        "avatar": "https://program.europython.eu/media/avatars/fred_z1RngGv.png",
        "slug": "frederic-harper"
      }
    ],
    "submission_type": "Poster",
    "slug": "a-personal-brand-surprise-you-already-have-one",
    "track": "Career, Life,...",
    "state": "confirmed",
    "abstract": "Why should you care about your personal brand? After all, it’s not like you are an actor or the lead singer for a rock band. In fact, it’s never been more important for you to think about yourself as a brand. Doing so will provide rocket fuel for your career. You’ll find better jobs and become a  “thought leader” in your industry. You’ll become known for your expertise and leadership; people will seek your advice and point of view. As a developer, there are many tools you can use to build a personal brand, and this presentation will help you learn how to get visibility, make a real impact, and achieve your goals. You don’t need to be a marketing expert or a personal branding guru— you can be yourself and get your dream job or reach the next level of your career.",
    "description": "",
    "duration": "60",
    "python_level": "",
    "domain_level": ""
  },
  {
    "code": "HAKFFR",
    "title": "How we are making Python 3.11 faster",
    "speakers": [
      {
        "code": "LUY39H",
        "name": "Mark Shannon",
        "biography": "I've been using Python since 2005.\r\nI have an extensive background in compilers, virtual machines and static analysis for dynamic languages, specifically Python.\r\nAfter a long interlude working on static analysis tools, I have returned to performance work over the last couple of years.\r\n\r\nI am currently working as technical lead with the \"Faster CPython\" team funded by Microsoft.",
        "avatar": "https://program.europython.eu/media/avatars/IMG_20191130_122850_3mkOJrs.jpg",
        "slug": "mark-shannon"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-we-are-making-python-3-11-faster",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "Python 3.11 is between 10% and 60% faster than Python 3.10, depending on the application. \r\nWe have achieved this in a fully portable way by making the interpreter adapt to the \r\nprogram being run, and by streamlining key data structures.\r\n\r\nIn this talk I will explain what changes we have made, and how they improve performance.",
    "description": "The \"Faster CPython\" project aims to speed up Python, specifically CPython, by a large factor over the next few releases.\r\nThe first release to see the benefits of this work is Python 3.11.\r\n\r\nPython 3.11 includes the following major changes:\r\n\r\n* Adaptive specializing interpreter (PEP 659)\r\n* Consecutively allocated execution frames\r\n* Zero cost try-except\r\n* More regular object layout\r\n* Lazily created object dictionaries.\r\n\r\nI will describe each of these, describing how each helps speed up Python, and how they interact with each other.\r\n\r\nI will end the talk with some possible directions for Python 3.12.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "CFRUXG",
    "title": "Synergize AI and Domain Expertise - Explainability Check with Python",
    "speakers": [
      {
        "code": "CCZUDR",
        "name": "Pranjal Biyani",
        "biography": "Pranjal is an experienced AI Scientist building the first AI powered platform to accelerate R&D for Material Sciences across the globe. He loves opening black-box models to reveal insightful AI secrets that help decision makers adapt with the ever changing Industry needs. He also loves to teach and mentor passionate individuals aspiring to be a part of the Data Science Community, all with his favourite language, Python!",
        "avatar": null,
        "slug": "pranjal-biyani"
      }
    ],
    "submission_type": "Talk",
    "slug": "synergize-ai-and-domain-expertise-explainability-check-with-python",
    "track": "PyData: Ethics in AI",
    "state": "confirmed",
    "abstract": "The talk focuses on establishing guidelines for Explainable AI by diving into fundamental concepts and checkpoints, before accepting AI models to make decisions. We go through explainers, types, and algorithms with a simple implementation in Python, to strengthen our understanding of \"WHY?\" the model predicts a certain value and \"HOW?\" to validate it with experiential learning of experts to bridge potential gaps",
    "description": "We will go through the Why? How? and What? of Model Explainability to build consistent, robust and trustworthy models. We explore the inability of complex models to deliver meaningful insights, cause-effect relationships and inter-connected effects within data and how explainers can empower decision makers with more than just predictions. We evaluate an intuitive game-theory based algorithm, SHAP, with a working implementation in Python. We will also pin-point intersections necessary with domain experts with 2 practical industry applications to facilitate further exploration.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "E73V8G",
    "title": "Automate the Boring Stuff with Slackbot(ver.2)",
    "speakers": [
      {
        "code": "3TLEGG",
        "name": "Takanori Suzuki",
        "biography": "Takanori([@takanory](https://twitter.com/takanory)) is a Vice Chairperson of [PyCon JP Association](https://www.pycon.jp/).\r\nHe is also a Director of [BeProud Inc.](https://www.beproud.jp/careers/en/), and his title is \"Python Climber\".\r\nTakanori held PyCon JP 2014 to 2016 as the Chairperson.\r\nCurrently he teaches Python to beginners as a lecturer at [Python Boot Camp](https://pycamp.pycon.jp/) all over Japan.\r\nIn addition, he published several [Python books](https://www.amazon.co.jp/%E9%88%B4%E6%9C%A8%E3%81%9F%E3%81%8B%E3%81%AE%E3%82%8A/e/B00W95A036/).\r\nTananori plays trumpet, climbs boulder, loves Lego, ferrets and beer.",
        "avatar": "https://program.europython.eu/media/avatars/sokidan1002x1002_QLUmEpL.jpg",
        "slug": "takanori-suzuki"
      }
    ],
    "submission_type": "Talk",
    "slug": "automate-the-boring-stuff-with-slackbot-ver-2",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Today, there are many tasks to repeat in the company/community.\r\nIn addition, we often use chat such as Slack for daily communication.\r\nSo, I created a chatbot([PyCon JP Bot](https://github.com/pyconjp/pyconjpbot)) to automate various boring tasks related to holding PyCon JP.\r\n\r\nIn this talk, I will first explain how to create a chatbot using [Bolt for Python](https://slack.dev/bolt-python/concepts).\r\nI will tell you how to registers bot's integration on Slack and how to create a simple bot in Python that responds to specific keywords.",
    "description": "In addition, we often use chat such as Slack for daily communication.\r\nSo, I created a chatbot([PyCon JP Bot](https://github.com/pyconjp/pyconjpbot)) to automate various boring tasks related to holding PyCon JP.\r\n\r\nIn this talk, I will first explain how to create a chatbot using [Bolt for Python](https://slack.dev/bolt-python/concepts).\r\nI will tell you how to registers bot's integration on Slack and how to create a simple bot in Python that responds to specific keywords.\r\n\r\nAnd as a specific case, I will explain how to make a bot command to perform the following operations and technical problems.\r\n\r\n- Emoji reaction\r\n- Calculator: SymPy\r\n- Karma(plusplus): Peewee\r\n- Search issues, display issue details: JIRA API\r\n- Create multiple issues from a template: JIRA API, Sheets Spreadsheet API\r\n- Account management of G Suite(user, alias, group and member): G Suite API\r\n- etc.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "9EH9PG",
    "title": "Packaging security with Nix",
    "speakers": [
      {
        "code": "ADBNZ8",
        "name": "Ryan Lahfa",
        "biography": "FOSS developer, Nix expert, software engineering expert with a love for formal methods and mathematics.",
        "avatar": null,
        "slug": "ryan-lahfa"
      }
    ],
    "submission_type": "Talk",
    "slug": "packaging-security-with-nix",
    "track": "Security",
    "state": "confirmed",
    "abstract": "Managing securely dependencies is becoming an increasing concern of the industry. Here, we showcase how Nix, a functional-oriented package manager, can get us very far and close class of vulnerabilities that PyPI / pip had in the past, e.g. rogue PyPI packages that steals personal data.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "RWKPFX",
    "title": "Open Science: Building Models LIke We Build Open-Source Software",
    "speakers": [
      {
        "code": "LKGJ7S",
        "name": "Steven Kolawole",
        "biography": "Steven Kolawole has his technical skillset cuts across Data Science and Software Engineering, with a bias for ML Research these days. His research interests focus on resource-efficient machine learning in terms of computational resources and low-resource/limited labeled data.\r\n\r\nHe is and has been heavily involved in varieties of ML subfields including ML Engineering, Software Engineering, Data Engineering, Data Science/Analytics, and Cloud Computing.\r\n\r\nSteven is also big on knowledge sharing via community mentorship and collective growth, open-source development, meetups facilitation, speakership, technical writing, research, and he gets kicks from helping tech muggles find their feet.",
        "avatar": "https://program.europython.eu/media/avatars/08.42_1Rtwig6.jpeg",
        "slug": "steven-kolawole"
      }
    ],
    "submission_type": "Talk",
    "slug": "open-science-building-models-like-we-build-open-source-software",
    "track": "PyData: Ethics in AI",
    "state": "confirmed",
    "abstract": "The use of transfer learning has begun a golden era in applications of Machine Learning but the development of these models “democratically” is still in the dark ages compared to best practices in Software Engineering. I describe how methods of open-source software development can allow models to be built by a distributed community of researchers.",
    "description": "Here, I elaborate on why we should develop tools that will allow us to build pre-trained models in the same way that we build open-source software. Specifically, models should be developed by a large community of stakeholders who continually update and improve them. Realizing this goal will require porting many ideas from open-source software development to building and training models, which motivates many threads of interesting research and opens up machine learning research for much larger participation.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "MBJUKF",
    "title": "Work in Progress: Implementing PEP 458 to Secure PyPI downloads",
    "speakers": [
      {
        "code": "ANZZRH",
        "name": "Kairo de Araujo",
        "biography": "I am an Open Source Software Engineer at VMware Inc, a staff member of the VMware Open Source Program Office (OSPO), working on the Security Supply Chain team.\r\nCurrently, I am focused on PyPI.org, Python-TUF, and some contributions to Tern Tools.\r\nAs a Software Engineer, I have contributed to Open Source and writing software since 2013.\r\nI am a former system engineer; however, I use these technologies daily. I have long experience in Infrastructures such as Networking, Cloud, Virtualization, Storage Area Networks, and Storage Disks.\r\nI have worked for IBM, ING, and Forescout in the past.",
        "avatar": "https://program.europython.eu/media/avatars/Kairo_de_Araujo_y22uEvQ.jpg",
        "slug": "kairo-de-araujo"
      },
      {
        "code": "H3JGWN",
        "name": "Lukas Pühringer",
        "biography": null,
        "avatar": null,
        "slug": "lukas-puhringer"
      }
    ],
    "submission_type": "Talk",
    "slug": "work-in-progress-implementing-pep-458-to-secure-pypi-downloads",
    "track": "Security",
    "state": "confirmed",
    "abstract": "[PEP 458](https://peps.python.org/pep-0458/) uses cryptographic signing on PyPI to protect Python packages against attackers. In this talk we will share our lessons learned from the ongoing implementation work in PyPI/Warehouse with the Python community. How does PEP 458 work and what is TUF? What protection can it offer now and what does it enable in the future? And how am I affected as a Python developer and as a user?",
    "description": "Attacks on software repositories are extremely common and can have a vast impact. A single successful compromise of the content distribution infrastructure can affect millions of users, voluntarily installing the infected packages.\r\n\r\n[PEP 458](https://peps.python.org/pep-0458/) was designed to protect PyPI against a variety of possible attacks on PyPIs own content distribution network and PyPI mirrors, while giving administrators a mechanism to recover from a compromise if it happens. In addition, PEP 458 is a fundamental stepping stone for more advanced protection described in [PEP 480](https://peps.python.org/pep-0480/).\r\n\r\nBoth PEP 458 and 480 implement a specification called [\"The Update Framework\" (TUF)](http://theupdateframework.io/), which introduces a series of roles, keys and metadata formats that are published along with the packages they protect, and can be verified by a client software such as pip.\r\n\r\nOver the past couple of months we have made an effort to integrate the latest version of the Python TUF reference implementation with PyPI/Warehouse (see [draft PR](https://github.com/pypa/warehouse/pull/10870)).\r\n\r\nIn this talk we will give an introduction to PEP 458 and TUF, how it works and what it is good for. We will report from the work-in-progress integration with Warehouse, what challenges we face and how Python developer and user workflows are affected, as well as an expected timeline for the integration. And last but not least, we want to give an outlook of what comes after PEP 458, that is full developer-to-user end-to-end protection of Python packages as described by PEP 480.\r\n\r\nWith our talk we also hope to spark interest in software supply chain security and to encourage the community to get involved by reviewing, commenting and contributing to the PEP 458 and PEP 480 integration efforts.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "JBHNRE",
    "title": "Creating the Next Generation of Billionaires - Part 4",
    "speakers": [
      {
        "code": "8QTNH7",
        "name": "Lilian",
        "biography": "Lilian studied Computer Science at high school and did her PhD in Computer Modelling. She went on to looking at computer applications and programming in the pharmaceutical sector before entering formal teaching for the next generation. She is currently engaged in teaching Python programming, C# and Javascript. She has given lectures in conferences both in the UK and abroad about the teaching of Computer Programming to young people. She has ran computer clubs including that of 'computer-assisted' investment for children and is a full member of the British Computer Society.\r\n\r\nLilian firmly believes that in this emergent brave new world, the Anthrpocene age, the computer (with its associated technologies) is the harbinger to transform globally man's short slavish existence to a better one - a world community defined by longer, richer and freer life experiences. She believes it is imperative that our schools empower our young children with his new knowledge, and Lilian herself did help reshape the Computer Science Department of an independent boys' school as Head of Department. She has produced for children more than 75 YouTube (online) videos on Computer Science and Programming - and has had more than 12,000 hits globally.",
        "avatar": null,
        "slug": "lilian"
      }
    ],
    "submission_type": "Talk",
    "slug": "creating-the-next-generation-of-billionaires-part-4",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "Our generation of young people in school (aged 5-18) have noticed the connection between Computer pRogramming, Technology, Bitcoinism Success, Climate Change and Billionaires.\r\n\r\nOn mass young people are clamouring to master the skill of Computer pRogramming. It has been dubbed the ‘4th’ R’ (computer pRogramming) along with Reading, wRiting and aRithmetic. So, governments worldwide have launched initiatives to have it taught in schools from Kindergarten to all the way to high school. And now young people are successfully mastering this skill.\r\n\r\nThis talk will describe a case study whereby Computer Programming (Python) was introduced for the first time to a group of young people and how the young people are using it to explore and understand real world problems and data such as those relating to climate change, world population growth and carbon dioxide emissions with Python visualisation libraries such as Matplotlib, Numpy and Pandas. We will talk about the joys and challenges and discoveries made by the young people. We will conclude with suggestions on how to proceed in this area.",
    "description": "",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "MADLNQ",
    "title": "Python Packaging Automation — Auto-Publish to PyPI via Pull Requests",
    "speakers": [
      {
        "code": "P9YEAF",
        "name": "Justin Mayer",
        "biography": "Justin Mayer is a serial entrepreneur, investor, and advocate for data portability and privacy. His latest project is [Fortressa.com](https://fortressa.com), which replaces expensive SaaS data silos with self-hosted open-source applications. He also maintains the [Pelican static site generator](https://github.com/getpelican/pelican) as well as a number of other projects for Python, Django, and the Fish shell.\r\n\r\nJustin speaks Japanese and Italian, graduated with honors from the University of California, Berkeley, and received his M.B.A. from the Wharton School of Business.\r\n\r\nHe writes about security and privacy at [justinmayer.com](https://justinmayer.com) and via [@JMayer on Twitter](https://twitter.com/jmayer).",
        "avatar": "https://program.europython.eu/media/avatars/jm_c7gpVSI.jpg",
        "slug": "justin-mayer"
      }
    ],
    "submission_type": "Talk",
    "slug": "python-packaging-automation-auto-publish-to-pypi-via-pull-requests",
    "track": "DevOps",
    "state": "accepted",
    "abstract": "A huge source of friction in software is publishing new releases. Somebody has to manually review commits and write a change-log, add a version number, and publish to PyPI. We will cover a better way: an automated process in which new versions are automatically published by merging pull requests.",
    "description": "Empowering anyone to issue a new release by submitting a pull request? At first glance, it seems like an outlandish idea. Upon further inspection, however, the benefits become clear.\r\n\r\nOne of the biggest sources of friction in software development is packaging and publishing new releases. Somebody has to sift through the commits and write a change-log, tag it with a new version number, and publish the package to PyPI. And usually only one or two people have the access necessary for this last step.\r\n\r\nThe unfortunate result is an infrequent release cadence. Bug fixes and new features are sitting there in the `main` branch, but hardly anybody is benefiting from them because they aren’t in a shipped release yet.\r\n\r\nThankfully, there’s a better way: a continuous release process where new versions are auto-published via pull requests — without any manual monkeying.\r\n\r\nIn this environment, all pull requests must include a release file that describes the changes within. This file must also include whether the new version should be a major, minor, or patch release.\r\n\r\nThe continuous integration (CI) process looks for this file, and if one hasn’t been included, the tests will fail, and the pull request won’t be merged. Otherwise, a maintainer merges the pull request, and the CI process then uses the release file to put the description into the change-log, increment the version number, commit, tag, build, and publish the new release to PyPI.\r\n\r\nSo with almost no human input, every code contribution results in a new release in a matter of minutes. Every feature and bug-fix has its own release, without anyone having to remember to package and publish a new version. Plus, if a bug is found, it’s now much easier to trace it to a specific release version.\r\n\r\nPerhaps the best part is that all contributors get to issue their own releases. What better way to welcome new contributors than to reward them with a dedicated release composed entirely of their own work?\r\n\r\nAttendees of this talk will take home the following knowledge and skills:\r\n\r\n* what kinds of problems are introduced by an infrequent release cadence\r\n* how automated releases solve those problems and provide myriad ancillary benefits\r\n* how to format and parse the release file\r\n* how to use continuous integration (CI) systems to automate releases\r\n* how to add deployment code so new versions are released when PRs are merged\r\n* how to use [AutoPub](https://github.com/autopub/autopub) to facilitate this process",
    "duration": "30",
    "python_level": "none",
    "domain_level": "some"
  },
  {
    "code": "SMTMWT",
    "title": "Data Validation for Data Science",
    "speakers": [
      {
        "code": "3Y9QDE",
        "name": "Natan Mish",
        "biography": "Senior Machine Learning Engineer at Zimmer Biomet - the world's leading Orthopaedic medical devices company. London School of Economics graduate with an MSc in Applied Social Data Science. Passionate about using Machine Learning to solve complicated problems. I have experience analysing, researching and building data products in the financial, real estate, transportation and healthcare industries. Curious about (almost) everything and always happy to take on new experiences and challenges.",
        "avatar": "https://program.europython.eu/media/avatars/Screenshot_2022-03-27_at_14.28.28_jeQZNkR.png",
        "slug": "natan-mish"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "data-validation-for-data-science",
    "track": "PyData: Data Engineering",
    "state": "confirmed",
    "abstract": "Have you ever worked really hard on choosing the best algorithm, tuned the parameters to perfection, and built awesome feature engineering methods only to have everything break because of a null value? Then this tutorial is for you! \r\nData validation is often neglected in the process of working on data science projects. In this tutorial, we will demonstrate the importance of implementing data validation for data science in commercial, open-source, and even hobby projects. We will then dive into some of the open-source tools available for validating data in Python and learn how to use them so that edge cases will never break our models.\r\nWe will see how we can leverage PyData tools such as Pandas, PySpark and Tensorflow for defining schemas and enforcing strict data types. The open-source Python community will come to our help and we will explore wonderful packages such as Pydantic for defining data models, Pandera for complementing the use of Pandas, and Great Expectations for diving deep into the data.\r\nThis tutorial will benefit anyone working on data projects in Python who want to learn about data validation. Some Python programming experience and understanding of data science are required. The examples used and the context of the discussion is around data science, but the knowledge can be implemented in any Python oriented project.",
    "description": "For this tutorial, you will need a working Python environment with Jupyter installed. We will go through the hands-on exercises together in Jupyter notebooks. The context of the tutorial is a standard data science project with the common practice architecture of data ingestion, feature engineering, model training, model serving, etc.\r\nIn the first part of the tutorial, we will go through all of the common pitfalls where unexpected data values can impact the model performance, or even worse - break the run altogether. In light of the potential consequences, we will discuss the importance of data validation.\r\nFor the second part of the tutorial, we will try some simple and straightforward methods to ensure that the data is correct. We will use the tools already implemented in our project for handling data such as Pandas, PySpark and Tensorflow to show how we can use them to apply some simple validation methods.\r\nFinally, for the last part of the tutorial, we will dive into some of the open-sourced tools in the Python community that can help us with the validation task:\r\nPydantic - For defining data models, types, and simple checks.\r\nPandera - Used on top of Pandas Dataframes for schema validation.\r\nGreat Expectations - a framework for data testing, quality, and profiling.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "3ZGCQR",
    "title": "Python for Arts, Humanities and Social Sciences",
    "speakers": [
      {
        "code": "7CNJVE",
        "name": "Arjumand Younus",
        "biography": "Dr Arjumand Younus is a Research Scientist in Afiniti AI, and a part-time lecturer in Technological University Dublin. Before this appointment, Arjumand has contributed to SFI funded projects during her different post-doctoral positions at CONSUS-UCD and INSIGHT-UCD. She is also serving in the capacity of co-director for Women in Research Ireland which is a volunteer-run registered charity working for better representation of women and under-represented groups in academia.\r\n\r\nArjumand received a joint PhD in Computer Science from National University of Ireland Galway (Ireland) and University of Milano-Bicocca (Italy), MS degree in Computer Science from Korea Advanced Institute of Science and Technology (South Korea), and BS in Computer Science from the University of Karachi (Pakistan). Her research focuses on Machine Learning, Natural Language Processing, and Data Science for Social Good. Arjumand is passionate about the value of artificial intelligence technology to make society better, and at the moment is involved as an academic partner in various AI for Social Good projects.",
        "avatar": "https://program.europython.eu/media/avatars/headshot_arjumandyounus_KdYrxO6.jpg",
        "slug": "arjumand-younus"
      }
    ],
    "submission_type": "Talk",
    "slug": "python-for-arts-humanities-and-social-sciences",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "Computational methods particularly those involving data analytics are now taking root in various humanities disciplines. However, students and researchers working in these disciplines lack the necessary programming proficiency and coding experience . The need then arises to make Python-based computational methods accessible – we present case-studies of how to do this via various Python modules being taught at College of Business in Technological University Dublin and by means of walkthrough of an interdisciplinary social good project called InEire. It comes down to complementing existing quantitative and qualitative methods with methods based on analysis of various types of data specific to the social science problem being solved. We essentially go through the process of building curiosity-driven exploration in social science students via a theoretically driven research question rather than the Python technique itself, and then focusing on the various steps involved in solving that question; and finally boiling it down to a concrete Python-based data analytics methodology. This project-based teaching methodology helped us develop Python skills in newbies eventually leading to a Python-based data analytic skills in students of disciplines other than Computer Science.",
    "description": "The various areas within humanities and social sciences such as political science, sociology, psychology, economics etc. have evolved to a point where they have been complementing existing qualitative and quantitative methods with methods rooted in data science. This shift in paradigm is primarily driven by real-world, publicly available data sets that cover a variety of scholarly domains and have the potential to solve fundamental research questions in these intriguing fields. There is however a huge bottleneck to be overcome before realizing the full potential of data science in arts, humanities and social sciences; and that bottleneck relates to a fear of programming in students/researchers within these disciplines. Our talk presents some tips and tricks from course modules being taught in Technological University Dublin; the fundamental idea is to present an overview of data science toolkit and how it relates to problem solving in the real world. \r\n\r\nFirst we will present ways to make the data science lifecycle being made easy via tools such as Google colab and Jupyter notebooks followed by explaining how showing students the big picture and the workflow lifecycle of a data science technique helps grasps concepts in a very effective manner. We will present examples from exploratory data analysis and classification using data-driven research questions; and look into elegant solutions that can easily be plugged into a social scientist’s skillset. Examples of continuous assessment projects based on different Python libraries are also presented with a view to further establish use of Python as a valuable tool for arts, humanities, and social sciences.\r\n\r\nFinally, we will give an overview of an Irish research council funded project emanating from a combination of STEM and HUMANIITIES disciplines that aims to perform an economic assessment of anti-immigrant sentiment in Ireland. Various phases of the project will be explained emphasizing particularly those where Python tools play a major role in interpretion of research outcomes. These research outcomes obtained through smart use of Python data analytic tools play a key role in building relationships between data scientists and policy makers in both government and not-for-profit sector.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "L7PFLV",
    "title": "Protocols in Python: Why You Need Them",
    "speakers": [
      {
        "code": "CSV3TP",
        "name": "Rogier van der Geer",
        "biography": "Before joining GoDataDriven, Rogier obtained a PhD in particle physics. Rogier gained hands-on experience with handling enormous quantities of data and processing, or 'charming,' them into a manageable format before performing complicated analyses. After his PhD he exchanged physical science for data science at GoDataDriven, where he is now putting his skills to use on more business-driven problems. He likes applying data science to anything; be it his daily commute, improving his photography skills or the contents of his lunch box.",
        "avatar": "https://program.europython.eu/media/avatars/Screenshot_2022-03-16_at_14.59.51_7NEnkCC.png",
        "slug": "rogier-van-der-geer"
      }
    ],
    "submission_type": "Talk",
    "slug": "protocols-in-python-why-you-need-them",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Protocols have been around since Python 3.8. So what are they, and how can they help you write better code? And how are they different from Abstract Base Classes? In this talk I will introduce you to both concepts (ABCs and Protocols), and show you by example how they can make your life easier, and your code cleaner.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "MMWYWZ",
    "title": "Applications of Python in Computational Chemistry and Material Design",
    "speakers": [
      {
        "code": "9W9CWW",
        "name": "Owain Beynon",
        "biography": "PhD Student in Computational Chemistry at Cardiff University. \r\nResearch interests: software development, material science, catalysis, solid state physics.",
        "avatar": null,
        "slug": "owain-beynon"
      }
    ],
    "submission_type": "Poster",
    "slug": "applications-of-python-in-computational-chemistry-and-material-design",
    "track": "~None of the above",
    "state": "accepted",
    "abstract": "Computational chemistry is the branch of chemistry that studies chemical systems through simulation and involves HPC architecture and software packages. Python has become an integral part of computational modelling of materials in recent years, with development of packages such as the Atomic Simulation Environment (ASE) which is a set of modules for manipulating, running and visualising atomic simulation. Furthermore, ASE integrates seamlessly with many electronic structure software packages, used for calculating the energy and properties of systems based on some level of theory, e.g Density Functional Theory (DFT). Moreover, the combination with other Python packages that integrate with ASE provide an ecosystem for atomic simulations. Packages such as CatLearn, a machine-learning approach used for calculating energies needed for reactions, along with Phonopy and FHI-vibes, both are for studying lattice dynamics of materials, to name a few, provide a comprehensive toolkit for the computational study of materials and chemical systems\r\n\r\nIn our research, such approaches are essential to further our understanding of materials and chemical processes, and of particular interest are materials for green and sustainable processes, such as catalysts used to produce fossil fuel alternatives. In this regard, as Python software becomes increasingly popular for the simulation and study of materials, it also provides the tools and methods needed for tackling some of the challenges of today",
    "description": "Applications of Python in Computational Chemistry and Material Design\r\nOwain T. Beynon, Alun Owens, Andrew J. Logsdail\r\nCardiff Catalysis Institute, School of Chemistry, Cardiff University, Cardiff, Wales.\r\n\r\nComputational methods afford an insight into the behaviours and properties of materials and recently Python packages have increasingly become a powerful tool for the study of chemical systems. Computational chemistry is the branch of chemistry that studies chemical systems through simulation and involves HPC architecture and software packages. In general, there are two categories of simulation, dynamic and static and of these types, atoms in the system may be described by varying levels of theory: molecular (classical) mechanics (MM), quantum mechanics (QM) or a combination of the two (QM/MM). Static calculations obtain the property of the system at a fixed geometry, whereas dynamic calculations study the evolution of a system over a given timeframe. \r\n\r\nPython has become an integral part of computational modelling of materials in recent years, with development of packages such as the Atomic Simulation Environment (ASE) [1], which is a set of modules for manipulating, running and visualising atomic simulation. Furthermore, ASE integrates seamlessly with many electronic structure software packages, used for calculating the energy and properties of systems based on some level of theory, e.g Density Functional Theory (DFT), such as FHI-aims and VASP. [2,3] Moreover, the combination with other Python packages that integrate with ASE provide an ecosystem for atomic simulations (figure 1). Packages such as CatLearn, [4] a machine-learning approach used for determining transition states and energies needed for reactions, along with Phonopy and FHI-vibes, [5,6] both are for studying lattice dynamics of materials, and Py-ChemShell,[7] used for QM/MM calculations, to name a few, provide a comprehensive toolkit for the computational study of materials and chemical systems. \r\n\r\nIn our research, such approaches as outlined above are essential to further our understanding of materials and chemical processes, and of particular interest are materials for green and sustainable processes such as catalysts used for biofuel production, and battery materials, namely, zeolite Tin-BETA and Prussian Blue, [8-10] respectively. In collaboration with experimentalists, we seek to understand the synthetic methods and properties of these materials, with the aim to further establish them as viable alternatives to fossil fuels. In this regard, as Python software becomes increasingly popular for the simulation and study of materials, it also provides the tools and methods needed for tackling some of the grand challenges of today. \r\n\r\nReferences \r\n[1] A. Hjorth Larsen, et al. J. Phys. Condens. Matter 29 273002 (2017) [2] V. Blum, et al.  Comput. Phys. Commun., 180, 2175–2196 (2009) [3] G. Kresse and J. Hafner, Phys. Rev. B 47 , 558 (1993) [4] A. Garrido Torres, et al. Phys. Rev. Lett., 122, (2019)[5]A. Togo, I. Tanaka, Scr. Mater, 108 (2015). [6] F. Knoop et al. J. Open Source Softw. (2020) [7] Y. Lu, et al. J. Chem. Theory Comput., 15, 1317–1328 (2019) [8] A. Corma et al. Nature, 412, 423–426 (2001) [9] C. Hammond, S. Conrad, I. Hermans, Angew. Chem. Int., 51, 11736–11739 (2012)[10] C. Ling. et al. J. Phys. Chem C 117 (2013)",
    "duration": "60",
    "python_level": "",
    "domain_level": ""
  },
  {
    "code": "ZSCTME",
    "title": "Correlating messy data with \"correlate\"",
    "speakers": [
      {
        "code": "9DMGRT",
        "name": "Larry Hastings",
        "biography": "Larry is a 200 foot assault robot manufactured by Yoyodyne Propulsion Systems, a major US defense contractor.  He is suitable for heavy assault against heavily armored stationary targets, like laying siege to a walled city, or protecting supply lines during forward maneuvers.",
        "avatar": "https://program.europython.eu/media/avatars/pycon.profile.pic_2Ohe0DM.png",
        "slug": "larry-hastings"
      }
    ],
    "submission_type": "Talk",
    "slug": "correlating-messy-data-with-correlate",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "An introduction to the **correlate** Python library.  You tell **correlate** about two datasets that should map to each other, and it determines the best matches for you.  The novel scoring algorithm at the heart of **correlate** means it copes exceedingly well with messy real-world data.  **correlate** supports fuzzy matching, weighted matching, and ordering.",
    "description": "Data correlation!  What could be more computer science-y!  Ever needed to find matching items between two sets of data?  Maybe even messy real-world data, with inexact string matches?  Come find out how the novel scoring algorithm and clever heuristics at the heart of **correlate** solve this problem with ease!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "CPNE9S",
    "title": "AI for Content Moderation at PayPal",
    "speakers": [
      {
        "code": "J98AEX",
        "name": "Raghotham Sripadraj",
        "biography": "Raghotham is an AI Architect at PayPal and leads AI teams for the Customer Success Platform. He comes with rich background in building AI platforms and teams for startups and large enterprises. Drawing on his deep love for data science and neural networks and his passion for teaching, Raghotham has conducted workshops across the world and given talks at a number of data science conferences. Apart from getting his hands dirty with data, he loves traveling, Pink Floyd, and masala dosas.",
        "avatar": "https://program.europython.eu/media/avatars/2022-04-03_22.40.18_BPxR1BI.jpg",
        "slug": "raghotham-sripadraj"
      },
      {
        "code": "XENQTK",
        "name": "Ryan Roggenkemper",
        "biography": null,
        "avatar": null,
        "slug": "ryan-roggenkemper"
      }
    ],
    "submission_type": "Talk",
    "slug": "ai-for-content-moderation-at-paypal",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "Online platforms have a hard time combating hate, hate speech, explicit content and other NSFW material. Most of the solutions are rule based keyword approaches which are brittle and can be bypassed easily. At PayPal, we have a wide range of user generated content and there is a great need to automatically identify and flag hate, explicit and other typologies, to improve user experience and adhere to regulatory policies. In this talk we showcase how AI can help us identify such content with great precision.",
    "description": "Online content moderation at scale is a non trivial task especially with an ever changing landscape of hate, hate speech with changing geopolitical scenarios. Moderation platforms need to support multiple typologies like - hate, sexually explicit, violence, bullying, spam and other toxic material. Add multi-language support for all typologies and it becomes an uphill task. In this talk we will cover the below topics:\r\n\r\n1. Why is Text Content Moderation is hard? Why we need AI?\r\n2. What are the available open-source datasets to train models?\r\n3. What are the available pre-trained models for content moderation?\r\n4. Why pre-trained models do not always work?\r\n5. Data labelling strategies and how to leverage open data and models?\r\n6. How to build multi-language support and challenges?",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "SGP3PM",
    "title": "Rapid prototyping in BBC News with Python and AWS",
    "speakers": [
      {
        "code": "EWRKHR",
        "name": "Ben Nuttall",
        "biography": "Ben is a senior software engineer in BBC News Labs, an innovation team in BBC R&D. Ben was previously community manager at Raspberry Pi.",
        "avatar": null,
        "slug": "ben-nuttall"
      }
    ],
    "submission_type": "Talk",
    "slug": "rapid-prototyping-in-bbc-news-with-python-and-aws",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "BBC News Labs is an innovation team within BBC R&D, working with journalists and production teams to build prototypes to demonstrate and trial new ideas for ways to help journalists or bring new experiences to audiences.\r\n\r\nWorking in short project cycles, it's important for us to be able to quickly build processing pipelines connected to BBC services, test and iterate on ideas and demonstrate working prototypes. We make use of modern cloud technologies to accelerate delivery and reduce friction.\r\n\r\nIn this talk I will share our ways of working, our ideation and research methods, and the tools we use to be able to build, deploy and iterate quickly, the BBC's cloud deployment platform, and our use of serverless AWS services such as Lambda, Step Functions and Serverless Postgres.",
    "description": "BBC News Labs is an innovation team within BBC R&D, working with journalists and production teams to build prototypes to demonstrate and trial new ideas for ways to help journalists or bring new experiences to audiences.\r\n\r\nWe work in short project cycles to research and build prototypes. We have worked with the BBC's flagship radio news programme production team to enrich programme timelines with metadata to provide enhanced experiences to the audience. We are currently working with local radio teams around the UK to provide the means to capture highlights in live radio for re-use and for social media, reducing the workload for producers, and getting more mileage from linear broadcast programmes.\r\n\r\nWorking in short cycles, it's important for us to be able to quickly build processing pipelines connected to BBC services, test and iterate on ideas and demonstrate working prototypes. We make use of modern cloud technologies to accelerate delivery and reduce friction.\r\n\r\nIn this talk I will share our ways of working, our ideation and research methods, and the tools we use to be able to build, deploy and iterate quickly, the BBC's cloud deployment platform, and our use of serverless AWS services such as Lambda, Step Functions and Serverless Postgres.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "QJDCYS",
    "title": "Dr. Jekyll & Mr. Hyde - transition from developer to manager without going crazy or becoming evil",
    "speakers": [
      {
        "code": "8B79FL",
        "name": "Jakub Paczkowski",
        "biography": "Python development enthusiast for the last 11 years, currently working as Director of Engineering at SpotOn. I love clean and straightforward solutions, focused on usability and robustness. I am privately a motorcycling enthusiast in summer and squash lover in winter.",
        "avatar": "https://program.europython.eu/media/avatars/T02G0JQBC-UUTHKAS8N-5842edf034ff-512_JnL4JO5.jpeg",
        "slug": "jakub-paczkowski"
      }
    ],
    "submission_type": "Talk",
    "slug": "dr-jekyll-mr-hyde-transition-from-developer-to-manager-without-going-crazy-or-becoming-evil",
    "track": "Career, Life,...",
    "state": "confirmed",
    "abstract": "In the career of many developers, there comes the point of deciding \"what next?\". The typical two choices are- to stay on the technical path and pursue the way of a software architect or take a leap of faith and jump to a people management role. In my talk, I'll show you the pros, cons, and challenges of pursuing the latter.",
    "description": "You've been a developer for a couple of years already. Your journey started as an intern/junior-level position where you were learning to code; then, going through mid and senior positions, you were offered the team lead or even engineering manager role. At this moment, you have plenty of questions and doubts. How to answer them to make sure you make a good decision? How to prepare for the new role if you want to take it? I'll help you answer these questions and prepare for your future role.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "TDUFJ9",
    "title": "From circuit board design to finished product: the hobbyist’s guide to hardware manufacturing",
    "speakers": [
      {
        "code": "HBPEU7",
        "name": "Sebastian Roll",
        "biography": "Sebastian is a consultant, speaker and workshop organizer.\r\n\r\nHe has ten years of experience spanning Oil & Gas, Industrial IT and IoT. His main areas of interest include consulting practices, IoT and Python.",
        "avatar": "https://program.europython.eu/media/avatars/Sebastian_Roll_lxEMZjv.jpg",
        "slug": "sebastian-roll"
      }
    ],
    "submission_type": "Talk",
    "slug": "from-circuit-board-design-to-finished-product-the-hobbyists-guide-to-hardware-manufacturing",
    "track": "Makers",
    "state": "confirmed",
    "abstract": "Ever wondered how hardware is made, or curious about making your own? \r\n\r\nWe share our experiences manufacturing a programmable gamepad for use in IoT/MicroPython workshops. \r\n\r\nWe will cover the entire production process, including:\r\n\r\n- Designing the PCB (Printed Circuit Board)\r\n- Choosing microcontroller and parts\r\n- Finding, ordering and assembling components\r\n- Pulling together firmware, drivers and software\r\n\r\nMistakes were indeed made along the way. Let's turn them into valuable lessons!",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "YC7KJU",
    "title": "Code coverage through unit tests running in sub-processes/threads: Locally and automated on GitHub",
    "speakers": [
      {
        "code": "T8FLGG",
        "name": "Saransh Chopra",
        "biography": "I am Saransh, a sophomore at the University of Delhi, pursuing a major in Information Technology and Mathematics. In daylight, I work towards my academic skills and professional commitments, and by night, I develop and maintain open-source research software written in Python, which I believe are the key to collaborative and reproducible research. Currently, I develop PyBaMM, BattBot, liionpack, and my contributions range from DeepXDE to Colour. I also like to experiment with Python a lot in the form of projects, which are all available on my GitHub!",
        "avatar": "https://program.europython.eu/media/avatars/PyCon_Squared_5BJkaJz.jpg",
        "slug": "saransh-chopra"
      }
    ],
    "submission_type": "Talk",
    "slug": "code-coverage-through-unit-tests-running-in-sub-processes-threads-locally-and-automated-on-github",
    "track": "DevOps",
    "state": "confirmed",
    "abstract": "Unit testing and code coverage are two essential aspects of an open-source codebase. These unit tests often run in spawned sub-processes or threads as sub-processes or multi-threading allow them to run parallelly. They also make it easier to stop the tests midway if the process is taking too much time (probabilistic tests).\r\n\r\nHowever, running unit tests in a sub-process creates a problem in the local repository as well as in the remote repository. As the documentation of `coverage.py` says — *“Measuring coverage in those sub-processes can be tricky because you have to modify the code spawning the process to invoke coverage.py.”*",
    "description": "The *“Code coverage”* value of a codebase depicts how much of the production/development code is covered by the running unit tests. In the world of open-source, all the maintainers try their best to keep this percentage high, and this process is often automated through tools like `GitHub Actions` and `Codecov`. Hence, code coverage becomes a good metric (not always) to check if a particular codebase is well tested and reliable.\r\n\r\nOpen source maintainers often prefer to run these unit tests in sub-processes or threads as it allows them to run in parallel and reduce the `CI` (continuous integration) run time on pull requests. They also make it easier to stop the tests midway if they are taking too much time (probabilistic tests).\r\n\r\nIn this talk, we will first try to use `coverage.py` in the default mode on the unit tests running in a sub-process or a thread. After going through the results, we will build a solution to cover the “un-covered” code in the local repository. As a final step, we will also configure a `CI` (continuous integration) pipeline using `GitHub Actions` and `Codecov` to automate this process in our remote repository.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "Q3FPVG",
    "title": "Raise better errors with Exception Groups",
    "speakers": [
      {
        "code": "VM3NZN",
        "name": "Or Chen",
        "biography": "I've been writing Python every day for 5 years, excited about Deep Learning, VR Gaming, and my dog Chika",
        "avatar": "https://program.europython.eu/media/avatars/1634304370356_45bm3T9.jpg",
        "slug": "or-chen"
      }
    ],
    "submission_type": "Talk",
    "slug": "raise-better-errors-with-exception-groups",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "New to python 3.11, Exception Groups help you raise and handle errors more robustly than ever before - you will delve deep into the current gaps in python's exception handling mechanisms, and get to know Error Groups, and a new python keyword except*, that can be used to overcome those issues and to write cleaner code.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "87XUMG",
    "title": "Why is it slow? Strategies for solving performance problems",
    "speakers": [
      {
        "code": "9JJFPM",
        "name": "Caleb Hattingh",
        "biography": "TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD TBD",
        "avatar": "https://program.europython.eu/media/avatars/sqfortekmojitwitch_VVdyZFb.jpg",
        "slug": "caleb-hattingh"
      }
    ],
    "submission_type": "Talk",
    "slug": "why-is-it-slow-strategies-for-solving-performance-problems",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "You have a performance problem, and you don't know what to do. All you know is that one of your endpoints is very slow; and perhaps it only affects a certain user. How do you figure out why it's slow, and what can you do to catch performance problems before they hurt users in production? This talk will step through several scenarios involving typical performance problems and how to diagnose them.",
    "description": "You have a performance problem, and you don't know what to do. All you know is that one of your endpoints or applications is too slow; and perhaps it only affects a certain user or customer. How do you figure out why it's slow, and what can you do to catch performance problems before they hurt users in production?\r\n\r\nWe'll go through a wide range of strategies for detecting and diagnosing performance problems in typical production workloads. We'll cover both web-based domains as well as backend domains and other analytical applications involving number-crunching and big-data applications.\r\n\r\nWe'll step through the following high-level strategies:\r\n\r\n- Tracing: through instrumentation of your code, you will get detailed traces of where the time is spent in generating your web server responses.\r\n- Profiling: we'll look at profiling strategies using both the Python built-in cProfile tool, as well as awesome 3rd party libraries like pyspy, including how to use these with pytest\r\n- Isolation: how to figure out if performance is affected by CPU, or memory, disk, or network IO limitations.\r\n- Reasoning: we'll look at common scenarios that result in performance regressions such as the needless execution of sub-queries in rendering web views, or algorithmic analysis and \"big-O\" notation, or concurrency problems resulting from exhaustion of threads in a pool and asyncio concurrency limitations resulting from overloaded subscription.\r\n- Prophylaxis: we'll look at how to include benchmarks within your CI pipeline, including with pytest and other technologies to catch performance regressions ahead of time.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "F9FURV",
    "title": "PyArrow and the future of data analytics",
    "speakers": [
      {
        "code": "AQNTYV",
        "name": "Alessandro Molina",
        "biography": "Relying on Python as his primary development language for more than 15 years, has always been interested in Python as a Development Platform.\r\n\r\nHe worked as CTO and team leader of Python teams for the past 10 years and is currently core developer of the [TurboGears2](http://turbogears.org) web framework and a contributor to the [Apache Arrow](https://arrow.apache.org/) project.\r\n\r\nAlessandro is the author of [Crafting Test-Driven Software with Python](http://www.pythontdd.com) and [Modern Python Standard Library Cookbook](https://www.pythonstandardlibrarybook.com/)\r\nand has authored many OpenSource Python projects like the [DEPOT](https://depot.readthedocs.io/en/latest/) file storage framework and the [DukPy](https://github.com/amol-/dukpy#dukpy) JavaScript interpreter for Python.\r\n\r\nAlessandro has been an [active speaker](https://pyvideo.org/speaker/alessandro-molina.html) to tens of European conferences since 2012",
        "avatar": null,
        "slug": "alessandro-molina"
      }
    ],
    "submission_type": "Talk",
    "slug": "pyarrow-and-the-future-of-data-analytics",
    "track": "PyData: Data Engineering",
    "state": "confirmed",
    "abstract": "In this talk we will introduce PyArrow and talk bout the transformation that the Arrow format is allowing in the Data Analytics world.\r\n\r\nPyArrow provides an in-memory format, a disk format, a network exchange protocol, a dataframe library and a query engine all integrated in a single library. But the Arrow ecosystem doesn't stop there and allows you to work integrating multiple different technologies. It can be a swiss army knife for data engineers and it integrates zero cost with NumPy and Pandas in many cases.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "PQADBJ",
    "title": "Unfolding the paper windmills",
    "speakers": [
      {
        "code": "7T3KC8",
        "name": "Mai Giménez",
        "biography": "Mai Giménez is a research engineer working at Deepmind. She holds a PhD in natural language processing, and her main research interest is in language and the sociotechnical impacts of these models in the real world.\r\nShe's a former board member of the Spanish Python Association, helped organise several PyConES conferences and is a proud member of the Pyladies.",
        "avatar": "https://program.europython.eu/media/avatars/image_iYEZORj.png",
        "slug": "mai-gimenez"
      }
    ],
    "submission_type": "Talk",
    "slug": "unfolding-the-paper-windmills",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "Research is done on the shoulders of giants. Luckily and unluckily, those giants spoke paper-English and documented their achievements kind of publicly so we could advance the science. \r\n\r\nIn this talk, we will dissect the structure of a paper, looking for the essential points that will help us understand it and implement it. Following we will get our hands dirty and implement the paper using Python. \r\nIn particular, we will dive into the seminal paper \"Attention is all you need\" and implement a transformer using JAX.\r\n\r\nThe key takeaways from this talk are:\r\n - Demystify academic reading.\r\n - Understand the Transformer architecture.\r\n - An introduction to the JAX ecosystem.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "YJYBHC",
    "title": "Super Search with OpenSearch and Python",
    "speakers": [
      {
        "code": "ZLLVEH",
        "name": "Laysa Uchoa",
        "biography": "Laysa is a developer working towards a more diverse and fun Python community by organizing Pyladies Munich Chapter. Her passion for sharing knowledge and OSS has led her to work as developer advocate for Aiven. She help users understand databases and do cool things with them. Besides Python, she like cyberpunk movies, tea, and human languages.",
        "avatar": "https://program.europython.eu/media/avatars/DSC_0672_1_wcU720A.jpg",
        "slug": "laysa-uchoa"
      }
    ],
    "submission_type": "Talk",
    "slug": "super-search-with-opensearch-and-python",
    "track": "PyData: Data Engineering",
    "state": "confirmed",
    "abstract": "OpenSearch is an open source and free document database with search and aggregation superpowers, based on Elasticsearch. This session covers how to use OpenSearch to perform both simple and advanced searches on semi-structured data such as a product database.",
    "description": "OpenSearch is an open source and free document database with search and aggregation superpowers, based on Elasticsearch. This session covers how to use OpenSearch to perform both simple and advanced searches on semi-structured data such as a product database. Search is pretty useful inside applications, so we'll also discuss how to connect to OpenSearch from existing Python applications, work with data in the database, and perform search and aggregation queries from Python. This talk is recommended for Python developers whose applications are ready to gain some search superpowers.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "VXJK3Z",
    "title": "Packaging Python in 2022",
    "speakers": [
      {
        "code": "8YFYD9",
        "name": "Jeremiah Paige",
        "biography": "I am a long time Python developer of almost a decade. For most of that time I have used the language to drive systems programs in and on top of C. Python is a diverse and quickly growing community and I love to contribute to it even as I try to keep up. I currently help ActiveState deliver secure, pre-build python projects to enterprise customers and individual developers.",
        "avatar": "https://program.europython.eu/media/avatars/FB_IMG_1479148712979_7HSytv7.jpg",
        "slug": "jeremiah-paige"
      }
    ],
    "submission_type": "Talk",
    "slug": "packaging-python-in-2022",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "Packaging in Python is one place where the common adage \"There should be one and preferably only one obvious way to do it\" doesn't seem to apply. There are a lot of choices to make when publishing python code. What is absolutely essential and what is optional?",
    "description": "The Python packaging landscape is experiencing a renaissance but along with new standards and new tools comes a lot of new choices when publishing. setup.cfg or pyproject.toml? Do you need a setup.py instead or in addition? There can be a lot of confusion but understanding modern trends can make sharing your code easier than ever before.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "ZGSULC",
    "title": "Best practices to open source a product and creating a community around it",
    "speakers": [
      {
        "code": "HGSWKF",
        "name": "Adrin Jalali",
        "biography": "I'm a computer scientist / bioinformatician who has turned to be a core developer of `scikit-learn` and `fairlearn`, and work as a Machine Learning Engineer at Hugging Face. I'm also an organizer of PyData Berlin.\r\n\r\nThese days I mostly focus on aspects of machine learning and tools which help with creating more ethical and fair decision making systems. This trend has influenced me to work on `fairlearn`, and to work on aspects of `scikit-learn` which would help tools such as `fairlearn` to work more fluently with the package; and at Hugging Face, my focus is to enable the community of these libraries to be able to share their models more easily and be more open about their work.",
        "avatar": "https://program.europython.eu/media/avatars/Farb3SW3229-w-small_mpaHfiN.png",
        "slug": "adrin-jalali"
      }
    ],
    "submission_type": "Talk",
    "slug": "best-practices-to-open-source-a-product-and-creating-a-community-around-it",
    "track": "Community & Diversity",
    "state": "confirmed",
    "abstract": "In certain areas of the industry open source has become mainstream, whether it be a small part of a product, a “community edition of a product”, or creating a whole business around an open source product. One could assume the only thing required to do so is to make the source code of the project publicly accessible, possibly by putting it on a platform such as GitLab or GitHub, and one couldn’t be more wrong.\r\n\r\nIn this talk we explore those aspects such as the licence and the governance of the project and the impact they can have. Then we talk about common mistakes teams make which create an environment where outsiders don’t necessarily feel welcomed to the project. First impressions matter and it’s important that new contributors and users stay once they encounter the project.",
    "description": "There are many aspects of open sourcing a product which are often overlooked yet greatly impact the community and activities around the project. One of the first things people think about is the licence [1], which is very important, but what people don’t often think about is the governance of it, which impacts the speed, decision making processes, and the kind of engagement one can get from contributors to the project who don’t work in the company.\r\n\r\nNot every project is open sourced for the same purpose. On one side of the “openness” spectrum some projects are out there to give a bit of visibility to what a team is doing or to showcase a research or another product, and on the other spectrum the creators of a project put it out there to create a user and contributing community so that eventually the community would be active enough for the original creators to become a minority in the contributing and governance team. Depending on what the goals are, one needs to create or use a governance model which matches those goals and needs. One can look at the following categories from this perspective [2]:\r\n\r\n- \"Do-ocracy\"\r\n- Founder-leader\r\n- Self-appointing council or board\r\n- Electoral\r\n- Corporate-backed\r\n- Foundation-backed\r\n\r\nThen we talk about some practices which can fend people off when they try to join a community, giving concrete detailed examples on how it can look like while interacting with contributors and users online, such as [3]:\r\n\r\n- Lack of onboarding\r\n- Nothing in writing\r\n- Leadership is a mystery\r\n- No path to success\r\n- Poor communication\r\n- Lack of transparency\r\n- Not seeing ourselves in others\r\n\r\n[1] Licences and Standards, https://opensource.org/licenses\r\n[2] Understanding open source governance models, https://www.redhat.com/en/blog/understanding-open-source-governance-models\r\n[3] Brain Proffitt, Seven Deadly Sins of Open Source Communities",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "WFJ7XP",
    "title": "Robyn: An async web framework written in Rust",
    "speakers": [
      {
        "code": "ZPQUMD",
        "name": "Sanskar Jethi",
        "biography": "Sanskar is a Software Engineer at Bloomberg, London during the day and a FOSS maintainer during the night. He is the author and maintainer of Robyn, which is one of the faster web frameworks in the Python ecosystem.\r\n\r\nSanskar loves attending, speaking and organising conferences and has been an active part of various Open Source and Python conferences.",
        "avatar": null,
        "slug": "sanskar-jethi"
      }
    ],
    "submission_type": "Talk",
    "slug": "robyn-an-async-web-framework-written-in-rust",
    "track": "Web",
    "state": "confirmed",
    "abstract": "Python web frameworks, like FastAPI, Flask, Quartz, Tornado, and Twisted, are important for writing high-performance web applications and for their contributions to the web ecosystem. However, even they posit some bottlenecks either due to their synchronous nature or due to the usage of python runtime. Most of them don’t have the ability to speed themselves due to their dependence on *SGIs. This is where Robyn comes in. Robyn tries to achieve near-native Rust throughput along with the benefit of writing code in Python. In this talk, we will learn more about Robyn. From what is Robyn to the development in Robyn.",
    "description": "With the effort put in at every Python version to increase the runtime performance, we know that throughput efficiency is one of the top priority items in the Python ecosystem.\r\n\r\nInspired by the extensibility and ease of use of the Python Web ecosystem and the increased focus on performance, Robyn was born. \r\n\r\nRobyn is one of the fastest, if not the fastest Python web framework in the current Python web ecosystem. With a runtime written in Rust, Robyn tries to achieve near-native rust performance while still having the ease of writing Python code. \r\n\r\nThis talk will demonstrate the reasons why Robyn was created, the technical decisions behind Robyn, the increased performance by using the rust runtime, how to use Robyn to develop web apps, and most importantly, how the community is helping Robyn grow!\r\nFinally, I will be sharing the future plans of Robyn and would love to get feedback from the developers to see what they would like to see in it.",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "some"
  },
  {
    "code": "S8XSTF",
    "title": "ShapePipe: A modular weak-lensing processing and analysis pipeline",
    "speakers": [
      {
        "code": "VFV3HW",
        "name": "Samuel FARRENS",
        "biography": "I am a researcher at the CosmoStat lab in CEA Paris-Saclay. I work on developing software for cosmology and collaborate with a team working on biomedical imaging. You can find out more about what I do on [my website](https://sfarrens.github.io/).",
        "avatar": "https://program.europython.eu/media/avatars/office_wave_reoyMY9.jpeg",
        "slug": "samuel-farrens"
      }
    ],
    "submission_type": "Talk",
    "slug": "shapepipe-a-modular-weak-lensing-processing-and-analysis-pipeline",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "I will the present the first public release of [ShapePipe](https://cosmostat.github.io/shapepipe/), an open-source and modular weak-lensing measurement, analysis and validation pipeline written in Python. I will begin by giving an (easy-to-follow) introduction on how and why we measure the shapes of galaxies to map the distribution of dark matter in the Universe. I will then describe the design of the software, mentioning the numerous Python packages we used, and justify the choices we made. I will conclude by discussing some of the lessons we learned along the way and how these can be applied to other scientific software development projects.",
    "description": "#### Why would you want to listen to this talk?\r\n\r\nCosmology is the study of the origin, evolution, structure and ultimate fate of the Universe. From the largest galaxies down to the smallest Python programmers our story begins with the **Big Bang**. The particles that make up all of things we can touch and see only account for 5% of the energy density of the Universe. Leaving us quite literally in the dark! Weak gravitational lensing, a barely perceptible change to the shape of **galaxies** that we observe, is an indispensable tool for understanding the nature of **dark matter** and **dark energy**. However, measuring the shape of galaxies to the precision required is actually quite a tricky problem.\r\n\r\nWhat could be more interesting? 😁\r\n\r\n#### What does this have to do with Python?\r\n\r\nWell, Python has steadily become the standard programming language for cosmologists over the last decade or so... and we are no exception! In this talk I will describe the tools we have developed in Python to help us solve some of the problems with measuring the shapes of galaxies and how various existing Python packages have made this possible. \r\n\r\nWe hope that some of the things we have learned could be useful to other teams, in particular those developing scientific software.\r\n\r\n##### Resources\r\n- [ShapePipe Repository](https://github.com/CosmoStat/shapepipe)\r\n- [ShapePipe Documentation](https://cosmostat.github.io/shapepipe/)",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "ZYAD7Z",
    "title": "The beginner’s data science project checklist",
    "speakers": [
      {
        "code": "XZLFAA",
        "name": "Sara Iris Garcia",
        "biography": "Business Intelligence analyst at NHS and machine learning enthusiast. Sara is active in the Python community and efforts in empowering women in tech by leading and organizing events focused on increasing the visibility of women in stem careers.",
        "avatar": "https://program.europython.eu/media/avatars/20200525_121756_wfAB0TP.jpg",
        "slug": "sara-iris-garcia"
      }
    ],
    "submission_type": "Talk",
    "slug": "the-beginners-data-science-project-checklist",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "In this talk, I will give you tips and practical advice on what steps to follow and how to plan your data science project to avoid making the most common mistakes during its development.\r\n\r\nDespite my limited experience delivering data science projects, I have learned how to avoid certain mistakes. In this talk I will teach you how to prevent them and save you lots of headaches.",
    "description": "In this talk you will learn tips on:\r\n\r\n- Defining requirements\r\n- Outlining a data science project\r\n- Reproducibility and Readability checklist\r\n- Best practices for writing Documentation\r\n- Useful python tools\r\n- Tips on presenting your findings\r\n                       \r\nThis is a talk is intended for beginner audience.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "8RH3BC",
    "title": "Saving Lives with Predictive Geo - AI",
    "speakers": [
      {
        "code": "33UKLN",
        "name": "Sumedh Ghatage",
        "biography": "Sumedh Ghatage is an Associate Lead Data Scientist (Geospatial) at Gramener. He has worked on various smart city initiatives including sectors such as environmental resource management, location intelligence, and disaster management projects.\r\n\r\nHe drives a community called “Geospatial Awareness Hub” which helps enable Education, Employment, and Business to foster the growth and awareness of the Geospatial Industry",
        "avatar": "https://program.europython.eu/media/avatars/profile-pic_T1gCApf.png",
        "slug": "sumedh-ghatage"
      }
    ],
    "submission_type": "Talk",
    "slug": "saving-lives-with-predictive-geo-ai",
    "track": "PyData: Machine Learning, Stats",
    "state": "accepted",
    "abstract": "Leveraging geospatial Python libraries to understand and predict High-risk houses during cyclone-induced floods in urban areas considering historical openly available satellite images and urban morphological data.\r\n\r\nAssigning a flood risk score to each individual house near the coastal regions is a challenge. Also, as the land characteristics vary based on different geographical locations, prepare for emergencies on demand.    ​\r\n\r\n​",
    "description": "We will demonstrate an end-to-end methodology using geospatial Python libraries to understand the use of Multi-Criteria Decision making methods taking into account driving variables. This talk will also throw light upon:\r\n\r\n1. Getting the large imagery datasets into DL friendly format\r\n2. Resampling of Satellite image data in python\r\n3. Conducting overlay analysis with weights\r\n4. Calculation of zonal statistics at house level\r\n5. Future Scope\r\n\r\nWe'll also showcase the geo-visualization portal we created and the technologies used, how you can use Python to convert large GeoJSON output to light vector tiles, and create a seamless experience for the user through an intuitive front-end.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "ULWUP3",
    "title": "Scaling scikit-learn performances: introducing new sets of computational routines",
    "speakers": [
      {
        "code": "P8VJPK",
        "name": "Julien Jerphanion",
        "biography": "I got a MSc. in Computer Science from the Université de Technologie de Compiègne and a MSc. in Applied Maths, Computer Vision and Machine Learning from École Normale Supérieure Paris-Saclay, and have had a few experience both in research and in the industry.\r\n\r\nI am mainly interested in computational, algorithmic and mathematical methods. I first started to contribute to open-source in 2017 and since then my contributions focused on scientific software.\r\n\r\nSince April 2021, I work at Inria as a Research Software Engineer, mainly on improving performances of scikit-learn and on giving feedback on the experimental Cython+ project. I became one of scikit-learn maintainers in October 2021.",
        "avatar": "https://program.europython.eu/media/avatars/me_l3L07Kv.jpg",
        "slug": "julien-jerphanion"
      }
    ],
    "submission_type": "Talk",
    "slug": "scaling-scikit-learn-performances-introducing-new-sets-of-computational-routines",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "For more than 10 years, scikit-learn has been bringing machine learning and data science methods to the world. Since then, the library always aimed to deliver quality implementations, focusing on a clear and accessible code-base built on top of the PyData ecosystem.\r\n\r\nThis talk aims at explaining the recent on-going work of the scikit-learn developers to boost the native performances of the library.",
    "description": "scikit-learn is an open-source scientific library for machine learning in Python.\r\n\r\nSince its first release in 2010, the library gained a lot of traction in education, research and the wider society, and has set several standards for API designs in ML software. Nowadays scikit-learn is of one the most used scientific library in the world for data analysis. It provides reference implementations of many methods and algorithms to a userbase of millions.\r\n\r\nWith the renewed interest in machine-learning based methods in the last years, other libraries providing efficient and highly optimised methods (such as for instance LightGBM and XGBoost for Gradient-Boosting-based methods) have emerged. Those libraries have encountered a similar success, and have put performance and computational efficiency as top priorities.\r\n\r\nIn this talk, we will present the recent work carried over by the scikit-learn core-developers team to improve its native performance.\r\n\r\nThis talk will cover elements of the PyData ecosystem and the CPython interpreter with an emphasis on their impact on performances. Computationally expensive patterns will then be covered before presenting the technical choices associated with the new routines implementations, keeping the project requirements in mind. At the end, we will take a quick look at the future work and collaborations on hardware-specialised computational routines.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "ZK7MVG",
    "title": "Property-based testing the Python way",
    "speakers": [
      {
        "code": "TEJVNB",
        "name": "Emma Saroyan",
        "biography": "Emma is a developer advocate at Alpaca. She enjoys sharing her knowledge and learning from fellow developers.",
        "avatar": "https://program.europython.eu/media/avatars/photo_bU7CgTE.jpg",
        "slug": "emma-saroyan"
      }
    ],
    "submission_type": "Talk",
    "slug": "property-based-testing-the-python-way",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "What if I told you you could write simpler tests but still get better results ? \r\n\r\nWhat if I told you can automatically generate your test data ?\r\n\r\nThis may sound difficult to your traditional testing approach but can be easily done with property-based testing. \r\n\r\nProperty-based testing allows a range of inputs to be tested on a given aspect of a software property, abstracting away the details.\r\n\r\nIn the world of Python you can accomplish this with Hypothesis, the Python library used for property-based testing. \r\n\r\nHypothesis helps you design cleaner and clever test suites.",
    "description": "This is an introductory talk about property-based testing. The talk requires some previous knowledge about testing to make the most out of it but if you are new and curious I think you would get something out of it.\r\n\r\nThe talk approaches a simple problem from two different testing perspectives. Giving you an idea about property-based testing and how it’s different from the traditional approach with Python. \r\n\r\nThe main focus of the topic would be Hypothesis and how you can achieve your testing goals with it. \r\n\r\nBy the end of this talk you would have a solid understanding of property-based testing with Hypothesis, that would help you decide which testing approach fits your need. \r\n\r\n\r\nGiven below is a rough overview of the talk structure:\r\n\r\n- The testing problem - This is where you would explain the problem statement \r\n- The traditional approach\r\n- Cons of traditional approach\r\n- What is property-based testing ? \r\n- Intro to Hypothesis \r\n- Same problem solution with Hypothesis\r\n- Why choose Hypothesis as a go-to property based testing tool ? \r\n- Parametrized testing with Pytest vs Hypothesis approach \r\n- When or when not to use property based testing \r\n- How can you adopt `hypothesis` in your code base ? Some opinions here.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "3HCYQ9",
    "title": "Managing complex data science experiment configurations with Hydra",
    "speakers": [
      {
        "code": "RMHTBJ",
        "name": "Michal Karzynski",
        "biography": "Michal Karzynski currently works as a software architect and data scientist for Intel, specializing in applying neural network models to the domain of sound processing.\r\nHe is a chairman of the Operators Special Interest Group, part of the Open Neural Network Exchange (ONNX) standardization committee. He also runs the consulting company Atarnia.com and writes a blog, which can be found at http://michal.karzynski.pl",
        "avatar": "https://program.europython.eu/media/avatars/michal.karzynski_8sqgZB4.jpg",
        "slug": "michal-karzynski"
      }
    ],
    "submission_type": "Talk",
    "slug": "managing-complex-data-science-experiment-configurations-with-hydra",
    "track": "PyData: Software Packages & Jupyter",
    "state": "accepted",
    "abstract": "Data science experiments have a lot of moving parts. Datasets, models, hyperparameters all have multiple knobs and dials. This means that keeping track of the exact parameter values can be tedious or error prone.\r\n\r\nThankfully you're not the only ones facing this problem and solutions are becoming available. One of them is Hydra from Meta AI Research. Hydra is an open-source application framework, which helps you handle complex configurations in an easy and elegant way. Experiments written with Hydra are traceable and reproducible with minimal boilerplate code.\r\n\r\nIn my talk I will go over the main features of Hydra and the OmegaConf configuration system it is based on. I will show examples of elegant code written with Hydra and talk about ways to integrate it with other open-source tools such as MLFlow.",
    "description": "",
    "duration": "30",
    "python_level": "guru",
    "domain_level": "expert"
  },
  {
    "code": "KP9CPX",
    "title": "Inspect and try to interpret your scikit-learn machine-learning models",
    "speakers": [
      {
        "code": "KMDJAL",
        "name": "Guillaume Lemaitre",
        "biography": "I am a research engineer. I have a PhD in computer science and have been a scikit-learn core developer since 2017.",
        "avatar": "https://program.europython.eu/media/avatars/guillaumelemaitre.jpg__200x200_q85_crop_subsampling-2_upscale_9Ptqss3.jpg",
        "slug": "guillaume-lemaitre"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "inspect-and-try-to-interpret-your-scikit-learn-machine-learning-models",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "This tutorial is subdivided into three parts.\r\n\r\nFirst, we focus on the family of linear models and present the common pitfalls to be aware of when interpreting the coefficients of such models.\r\n\r\nThen, we look at a larger range of models (e.g. gradient-boosting) and put into practice available inspection techniques developed in scikit-learn to inspect such models.\r\n\r\nFinally, we present other tools to interpret models, not currently available in scikit-learn, but widely used. in practice.",
    "description": "",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "H79EHW",
    "title": "Online voting system used for primary elections for the French Presidential, must be secure right ?",
    "speakers": [
      {
        "code": "9BBUPC",
        "name": "touilleMan",
        "biography": "Coming from the C/C++ embedded software world, I ended up starting a software company specialized in end-to-end encryption solution.\r\n\r\nI fall in love with Python a long time ago, fortunately programing can be polyamorous because I've met Rust in the meantime ;-)",
        "avatar": null,
        "slug": "touilleman"
      }
    ],
    "submission_type": "Talk",
    "slug": "online-voting-system-used-for-primary-elections-for-the-french-presidential-must-be-secure-right",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "Since it inception, online voting has been an apealing but controversial technology.\r\n\r\nIndeed, what seems like a modern way of making vote cheaper and more convenient is often considered by activist and reserchers as a pandora box unleashing never-ending privacy and authenticity concerns.\r\n\r\nHowever with Covid 19 shriking our public interaction, many have considered the benefits overcome the theorical issues and online voting system have skyrocketed like never before...\r\n\r\nThe Neovote voting system has been massively used in France: tenths of Universty, hundreds of private companies and, more importantly, it was chosen to organise\r\n3 of the 5 main primary elections for the French Presidential election of 2022 (Primaires de l'Écologie, Les Républicains and Primaire Populaire).\r\n\r\nNeovote claims to have the highest possible level of security, the voter being even able to access the final ballot box to do the recount by himself and ensure his own vote has been taken into account !\r\n\r\nSo challenge accepted, this talk will walk you through the Neovote voting system to understand why their claims are \"slightly\" exagerated ;-)",
    "description": "",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "S9ANCN",
    "title": "Elephants, ibises and a more Pythonic way to work with databases",
    "speakers": [
      {
        "code": "7NWTAL",
        "name": "Marlene Mhangami",
        "biography": "Marlene is a Zimbabwean software engineer, explorer, and speaker based in the city of Harare. She is an advocate for using science and technology for social good and increasing diversity in these fields. She is a director and vice-chair for the Python Software Foundation and is currently working as a Developer Advocate at Voltron Data. In 2017, she co-founded ZimboPy, a non-profit organization that gives Zimbabwean young women access to resources in the field of technology. She is also the previous chair of PyCon Africa and is an advocate for women in tech on the continent.",
        "avatar": "https://program.europython.eu/media/avatars/marlenemedia_mkwiLgf.jpg",
        "slug": "marlene-mhangami"
      }
    ],
    "submission_type": "Talk",
    "slug": "elephants-ibises-and-a-more-pythonic-way-to-work-with-databases",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "In this talk, I will be sharing about Ibis, a software package that provides a more Pythonic way of interacting with multiple database engines. In my own adventures living in Zimbabwe, I’ve always encountered ibises (the bird versions) perched on top of elephants. If you’ve never seen an elephant in real life I can confirm that they are huge, complex creatures. The image of a small bird sitting on top of a large elephant serves as a metaphor for how ibis (the package) provides a less complex, more performant way for Pythonistas to interact with multiple big data engines. \r\n\r\nI'll use the metaphor of elephants and ibises to show how this package can make a data workflow more Pythonic. The Zen of Python lets us know that simple is better than complex. The bigger and more complex your data, the more of an argument there is to use Ibis. Raw SQL can be quite difficult to maintain when your queries are very complex. For Python programmers, Ibis offers a way to write SQL in Python that allows for unit-testing, composability, and abstraction over specific query engines (e.g.BigQuery)! You can carry out joins, filters, and other operations on your data in a familiar, Pandas-like syntax. Overall, using Ibis simplifies your workflows, makes you more productive, and keeps your code readable.",
    "description": "A few weeks ago I was working on setting up a relational database to explore records from DataSF’s Civic Art Collection. Whenever I attend a tech conference I try to spend a day or two in the city to check out its cultural scene, so this seemed like useful information! I decided to use MySQL as my database engine. Coming from a Pandas background I was surprised by how unproductive and restricted I felt writing raw SQL queries. I also spent a significant amount of time resolving errors in queries that worked with one flavor of SQL but failed with MySQL. Throughout the process, I kept thinking to myself if only there was a more Pythonic way!!! A few weeks later I was introduced to Ibis. \r\n\r\nI live in Zimbabwe and the first thing that pops into my mind when I think of the word ibis is a safari. One of my favorite things to do when I'm not working is to go on a game drive. Whenever I've been adventuring on safari I usually see ibises perched on top of an elephant. The contrast between the creatures is stark! The African Sacred Ibis is a small, elegant creature that's named after the ancient Egyptian god Thoth. While as many of us know, an elephant is a very big and complex animal. This image serves as a great metaphor for the Python package and how it interacts with big database engines.  \r\n\r\nIbis allows you to write intuitive Python code and have that code be translated into SQL. Whether you’re wanting to interact with SQL databases or wanting to use distributed DBMSs, Ibis lets you do this in Python. You can think of the python code as the less complex elegant layer sitting on top of any big data engine of your choice. At the moment, Ibis supports quite a few backends including:\r\n\r\nTraditional DBMSs: PostgreSQL, MySQL, SQLite Analytical DBMSs: OmniSciDB, ClickHouse, Datafusion Distributed DBMSs: Impala, PySpark, BigQuery In memory analytics: pandas and Dask. \r\n\r\nAnything you can write in an SQL select statement you can write in Ibis. You can carry out joins, filters, and other operations on your data in a familiar, Pandas-like syntax. In this talk, we'll go through several examples of these and compare what the SQL code would look like versus writing to the database with Ibis. Overall, using Ibis simplifies your workflows, makes you more productive, and keeps your code readable.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "RB7PNE",
    "title": "CPython 3.11 in the Web Browser - A Journey",
    "speakers": [
      {
        "code": "J3SDJ9",
        "name": "Christian Heimes",
        "biography": "Christian is an open source developer and Python core developer from Hamburg/Germany. He is well known for his work in the Python Security Response Team and as maintainer of CPython's ssl module.",
        "avatar": "https://program.europython.eu/media/avatars/importthis3_gmC9ONc.jpg",
        "slug": "christian-heimes"
      }
    ],
    "submission_type": "Talk",
    "slug": "cpython-3-11-in-the-web-browser-a-journey",
    "track": "(c)Python Internals",
    "state": "accepted",
    "abstract": "Python 3.11 alpha comes with experimental support for Web Assembly and can be built to run in modern web browsers or Node.js out of the box. I’m going to show how we achieved the goal, which obstacles we faced, and what is missing to have fully working “Python for the web”.",
    "description": "Python is ubiquitous, popular and runs almost everywhere – even on Mars. But there is one place that Python has not yet conquered: the browser. Python 3.11 may finally lay the foundation to make an old dream come true and have Python in the web browser.\r\n\r\nIn my talk I will explain how to cross-compile CPython 3.11 to Web Assembly and demonstrate how to run CPython in JavaScript engines. \r\nThe talk will cover\r\n\r\n* Why are some core developers and contributors working on Web Assembly port?\r\n* What is WASM and how do builds for browser, node, and WASI differ? What are the features and limitations of different WASM targets?\r\n* A short introduction to Python’s build system and how cross compiling works.\r\n* What problems did we run into and how did we have to modify CPython’s sources for WASM?\r\n* What does WASM support mean for the community and PyPI packages?",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "some"
  },
  {
    "code": "HE98XH",
    "title": "Machine Translation engines evaluation framework",
    "speakers": [
      {
        "code": "GYFSQB",
        "name": "Anton Masalovich",
        "biography": "Machine learning scientist and engineering manager with 15+ years of experience mostly focused on Natural Language Processing, Machine Translation and Document Recognition.\r\nEx-ABBYY, ex-Microsoft, currently working in a machine learning R&D department of a  large healthcare organization. Have a lot of experience of transforming state-of-the-art ML ideas to actual product features.",
        "avatar": null,
        "slug": "anton-masalovich"
      },
      {
        "code": "LZRDNM",
        "name": "Sahil Manchanda",
        "biography": null,
        "avatar": null,
        "slug": "sahil-manchanda"
      }
    ],
    "submission_type": "Talk",
    "slug": "machine-translation-engines-evaluation-framework",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "As an engineers in a ML R&D department of large healthcare enterprise company we were presented with the task to evaluate several Machine Translation engines and choose the one best suited for our corporate needs. To do that we created extendable Python-based framework that allowed us to easily plug-in different Machine Translation engines and compare them across large variety of test datasets with a unified set of quality metrics. Our goal from the start was to create universal MT evaluation framework, that will be useful not only for healthcare domain, but to a wider community as well.\r\n\r\nAt this talk we will present our evaluation framework an will do a walk-through of its capabilities. We also cover how it can be extended to new MT engines, new test datasets and new language pairs. We will also present our evaluation results for several state-of-the-art machine translation engines, both open-source and cloud-based.\r\n\r\nAll the source code of our framework will be published in open-source by the time of the talk.",
    "description": "Task of Machine Translation engine evaluation may be very challenging. Quality of Machine Translation varies greatly depending on domain and language pair. Different MT engines may have different interfaces or APIs and different requirements to run. To add to that, even definition of a good translation may be debatable, with any automatic MT quality metric providing only approximation of actual translation quality. That's why having universal evaluation framework for this task is very important. In our work we tried to create such framework.\r\n\r\n1) We defined base translation class that unified all file handling, batch creation and result processing. As a result of that, only work needed to support new MT engine was creation of small child class that implemented couple of simple functions. That allows us to easily extend our framework to MT engines and new language pairs.\r\n\r\n2) We defined set of test datasets and provided a way to add new datasets to this set. For our evaluation our aim was to create test data that covers both general and healthcare domains  EMEA dataset (https://opus.nlpl.eu/EMEA.php), OPUS-100 (https://opus.nlpl.eu/opus-100.php), Paracrawl (https://paracrawl.eu/) and several others. But our data preparations scripts can be easily extended to other domains and datasets as well.\r\n\r\n3) We defined a set of quality metrics to evaluate results of MT engines. Metrics that we used included BLEU (https://github.com/mjpost/sacrebleu), BERTScore (https://github.com/Tiiiger/bert_score), ROUGE (https://github.com/pltrdy/rouge), TER and CHRF (both also from sacrebleu implementation).\r\n\r\nBeside MT evaluation framework we will present our own evaluation results. For our evaluation we used cloud based engines - Azure Translator (https://azure.microsoft.com/en-us/services/cognitive-services/translator/), Google Translate (https://cloud.google.com/translate/), as well as open-source engines - Marian MT (https://huggingface.co/transformers/model_doc/marian.html), NVIDIA's NeMo (https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/machine_translation.html), Facebook's MBart 50 (https://huggingface.co/facebook/mbart-large-50-one-to-many-mmt), Facebook's M2M100 (https://huggingface.co/facebook/m2m100_418M). For open source engines we tried to use Huggingface's transformer implementation whenever possible. But as we mentioned our framework was designed in a way to be easily extendable to other MT engines and underlying frameworks.\r\n\r\nWe also will present evaluation results for NeMo and MarianMT engines that we fine-tuned specifically for healthcare domain. While these particular results may rather specific to our use case, they help to highlight how our framework can be extended to custom MT engines as well.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "3B9WHE",
    "title": "Python objects under the hood",
    "speakers": [
      {
        "code": "BLNV7P",
        "name": "Rodrigo Girão Serrão",
        "biography": "Rodrigo has always been fascinated by problem solving and that is why he picked up programming – so that he could solve more problems. He also loves sharing knowledge, and that is why he spends so much time writing articles in his blog [mathspp.com/blog](http://mathspp.com/blog), writing on Twitter [@mathsppblog](https://twitter.com/mathsppblog), and giving workshops and courses.\r\nYou can also find his past talks [here](https://github.com/mathspp/talks).\r\n\r\nHis main areas of scientific interest are mathematics (numerical analysis in particular) and programming in general (with a preference for the Python and APL languages), but Rodrigo also enjoys reading fantasy books, watching silly comedy movies and eating chocolate.",
        "avatar": "https://program.europython.eu/media/avatars/rgs_half_qpHwx6a.jpg",
        "slug": "rodrigo-girao-serrao"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "python-objects-under-the-hood",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "Have you ever heard of Python's **magic** methods?\r\nI am sorry, but they are not that “magic”!\r\nI agree they are really cool, but dunder methods (the name they usually go by) are just regular Python methods that you implement!\r\nAnd it is my job to help **you** learn about them.\r\n\r\n**Dunder methods** are the methods that you need to implement when you want your objects to interact with the syntax of Python.\r\nDo you want `len` to be callable on your objects? Implement `__len__`.\r\nDo you want your objects to be iterables? Implement `__iter__`.\r\nDo you want arithmetics to work on your objects? Implement `__add__` (and a bunch of others!).\r\nJust to name a few things your objects could be doing.\r\n\r\nIn this training, we will go over a series of small use cases for many of the existing dunder methods: we will learn about the way in which each dunder method is supposed to work and then we implement it.\r\nThis will make you a more well-rounded Python developer because you will have a greater appreciation for how things work in Python.\r\nI will also show you the approaches I follow when I am learning about a new dunder method and trying to understand how it works, which will help you explore the remainder dunder methods by yourself.",
    "description": "",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "NUF3K9",
    "title": "Applying machine learning capabilities to wearable IoT devices for boxing technique management",
    "speakers": [
      {
        "code": "DEZCB8",
        "name": "Anthony I. Joseph",
        "biography": "Anthony is an Australian software engineer and mathematician. As a UTS MBT graduate, Anthony is the technology co-founder of a property and cycling-tech startup and enjoys teaching and learning coding with the Australian startup scene.",
        "avatar": "https://program.europython.eu/media/avatars/Image_from_iOS_XuOClu6.jpg",
        "slug": "anthony-i-joseph"
      }
    ],
    "submission_type": "Talk",
    "slug": "applying-machine-learning-capabilities-to-wearable-iot-devices-for-boxing-technique-management",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "IoT devices are increasing in power and capabilities, now allowing developers to deploy machine learning models on the device. This talk will analyse a boxing training session with motion sensors onboard multiple IoT devices using TinyML: a TensorFlow-based framework. Ultimately, these machine-learning powered IoT devices provide feedback to boxers on their technique.",
    "description": "Internet of Things (IoT) devices are becoming more advanced through additional sensors, reduced size and increased computational power. In particular, this increase in computational power allows one to run previously-trained machine learning algorithms natively on an IoT device. \r\n\r\nThis presents an exciting opportunity: IoT devices often feature a variety of onboard sensors which can be used as inputs into a machine learning algorithm. \r\n\r\nThis talk will use the presenter's boxing training as a practical example of applying sensor data to a machine learning algorithm. In particular, this talk will demonstrate using motion sensor data obtained on an Arduino Nano 33 BLE Sense configured with TensorFlow Lite. This talk will discuss the entire analytical process from problem and data analysis through to algorithm training and deployment. It will also discuss boxing concepts and how these concepts are modelled in an IoT context.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "XUCMH3",
    "title": "A Network Embeddings based Recommendation Model with multi-factor consideration",
    "speakers": [
      {
        "code": "JFZNJ9",
        "name": "ABHISHEK",
        "biography": "Abhishek is a leading Innovation Specialist and a distinguished digital transformation leader who has worked across diversified domains retail, finance, logistics and enterprise technology. He has 13+ years of strong global business transformation experience in applied data science practice with a key focus on Artificial Intelligence, Machine Learning and NLP across various sectors. Currently working at Microsoft and delivered impactful outcomes by playing pivotal role in setting up AI CoEs while working for Maersk, Visa, Fidelity Investments and Dell. His active research interest reciprocated by 6 patents (US/ Denmark), 3 trade secrets and 5 international publications in top-peer reviews journals and conferences. He holds Master’s in industrial management & Engineering from Indian Institute of Technology Kanpur with specialization in Machine Learning & Natural Language Processing.",
        "avatar": "https://program.europython.eu/media/avatars/Abhishek_Photo_JnBJ1x1.jpg",
        "slug": "abhishek"
      }
    ],
    "submission_type": "Talk",
    "slug": "a-network-embeddings-based-recommendation-model-with-multi-factor-consideration",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "Recommendation systems are increasingly in demand to provide a personalized customer experience for diversified product mix offerings. Traditionally we use interaction information based on user preferences and item characteristics. This brings in collaborative filtering-driven recommendations with higher accuracy and relevance. However, such a method has certain limitations in utilizing implicit information like cross-domain specific factors that are equally important for making personalized recommendations. We propose an improvised way of using network embeddings based matrix factorization technique with multi-factors to make a match between both implicit and explicit features resulting in more accurate recommendation.",
    "description": "The method consists of three main steps: First, network embedding formulation performed on each user specific behavior network; Then, embeddings weight distribution estimated through intermediate layers of network with final layer for target (item purchased as labels); Finally, both factors: (a) Learned weights from implicit data (cross-domain) and (b) explicit factors from domain data used by multi-factorization method for recommendations. \r\nThe proposed method transfers knowledge across implicit and explicit factors and associated dimensions. The suggested approach tested real-world data with evidence of outperforming existing algorithms with significant lift in recommendation accuracy. Empirical experimentation outcomes illustrate the potential of both factors for making effective recommendations.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "NZJDKC",
    "title": "My journey using Docker as a development tool",
    "speakers": [
      {
        "code": "HLJHD3",
        "name": "Haseeb Majid",
        "biography": "I am software engineer with around 5 years of professional experience, currently working at ZOE. \r\nUsing mostly Python and FastAPI with Docker.",
        "avatar": null,
        "slug": "haseeb-majid"
      }
    ],
    "submission_type": "Talk",
    "slug": "my-journey-using-docker-as-a-development-tool",
    "track": "Web",
    "state": "confirmed",
    "abstract": "I have been programming in Python for 5 years and almost from day one I've been using Docker with Python. Docker is now a widely used tool across the industry, due to its flexibility. It can be used as a tool to help deploy your code in production, say using Kubernetes. It can also be used as a tool to help develop code locally, with tools such as docker-compose.\r\n\r\nIt has taken me some time to discover various features and best practices when using Docker. Especially when it comes to using it for local development.\r\n\r\nIn this talk, I would like to go over a journey I have taken with Docker whilst working with it over several years. Starting from a single build step with a full-fat image, going over multi-stage Docker images. Showing you how you can use the same Dockerfile for development and production.",
    "description": "Docker is a prevalent tool in our industry today, it is widely used for several proposes. In this talk, I would like to describe the journey I have taken with Docker and how I have learnt to use it with Python for local development. The talk will mostly focus on how we can use Docker to run all of our development tasks, so we hardly need to have anything installed locally. To the point where you can work on almost any project with nothing more than an editor, your terminal and docker. \r\n\r\nWe will look at how we can take a simple FastAPI CRUD web service and Dockerise it. The talk will be a step by step guide, starting of with a simple Docker image and improving it iteratively. \r\n\r\n- Firstly use a simple Docker image\r\n- Then add docker-compose to dockerise its dependencies such as database\r\n- Then see how we can run tests (and other tasks) directly in our Docker container (using Makefiles)\r\n  - How to use this with Github Action\r\n- Then look at multistage builds briefly\r\n   - Then split this into development and production image\r\n - Finally, look at using Poetry to manage our dependencies\r\n   -  How can we handle git dependencies that require an SSH key to be injected into the Docker image at build time\r\n\r\nI’d be a little more specific. Like, how we handle private pip packages in our docker images.  \r\n This talk is for you if you are a casual user of Docker and know a few of its features but want to improve your Docker skills.\r\n \r\n This is NOT a talk for you if you are an expert in Docker and know most of its features.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "CJNVSR",
    "title": "Mercury - Build & Share Data Apps from Jupyter Notebook",
    "speakers": [
      {
        "code": "JWK7RV",
        "name": "Piotr Płoński",
        "biography": "Software engineer with a passion for creating Data Science tools. Working on Mercury (framework for converting notebooks to web apps) and MLJAR AutoML (Automatic Machine Learning for Tabular Data).",
        "avatar": "https://program.europython.eu/media/avatars/pplonski_smile_Mz6QCW4.jpeg",
        "slug": "piotr-plonski"
      }
    ],
    "submission_type": "Talk",
    "slug": "mercury-build-share-data-apps-from-jupyter-notebook",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "Have you ever wished to magically transform your notebook into a web app and share it with non-coders? The [Mercury](https://github.com/mljar/mercury) is a new open-source framework for converting Jupyter Notebook to a web app.",
    "description": "The [Mercury](https://github.com/mljar/mercury) is a new framework for converting Jupyter Notebook to a web app. The widgets are constructed based on the YAML config (similar to R Markdown). The user can tweak the values of the widgets and execute the notebook from the top to the bottom. The notebook sharing is as simple as sending a link. What is more, you can decide whether to show or hide the code.\r\n\r\nIn the talk, I would like to show how the Python notebook can be converted to a web app and deployed to the cloud.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "HN3NNP",
    "title": "Real-time browser-ready computer vision apps with Streamlit",
    "speakers": [
      {
        "code": "FLSGCD",
        "name": "Yuichiro Tachibana",
        "biography": "Yuichiro works as a professional software developer and also loves contributing to OSS projects.\r\nAs a Pythonista, he has participated in various projects including web development, multimedia streaming, data management, computer vision, and machine learning.",
        "avatar": "https://program.europython.eu/media/avatars/pk2649_trimmed1_800_rgd5YPt.jpg",
        "slug": "yuichiro-tachibana"
      }
    ],
    "submission_type": "Talk",
    "slug": "real-time-browser-ready-computer-vision-apps-with-streamlit",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "By using Streamlit and streamlit-webrtc, we can create web-based real-time computer vision apps only with ~10 or 20 additional lines of Python code.\r\n\r\nTo turn computer vision models into real-time demos, we have conventionally used OpenCV modules such as `cv2.VideoCapture` and `cv2.imshow()`. However, such apps are difficult or impossible to share with friends, run on smartphones, or integrate with modern interactive widgets and other data views and inputs.\r\n\r\nWeb-based apps don't have such problems.\r\n\r\nStreamlit provides an easy way to build web apps quickly, and `streamlit-webrtc` allows to use real-time video streams.\r\nYou can create real-time video apps with modern interactive views and inputs, and host these apps on the cloud to use from any devices with browsers.\r\n\r\nIn this talk, I will demonstrate the development process using these libraries and show a variety of examples so that we see how easy and useful they are and can make use of them in daily development and research.`streamlit-webrtc` extends Streamlit to be capable of dealing with real-time video and audio streams.\r\nWith a combination of these libraries, developers can rapidly create real-time computer vision and audio processing apps for which OpenCV has typically been used.",
    "description": "I am the author of `streamlit-webrtc` and a member of [the Streamlit Creators program](https://streamlit.io/creators) (selected community members).\r\nThe repository of `streamlit-webrtc` is here: https://github.com/whitphx/streamlit-webrtc\r\n\r\nMy lightning talk about `streamlit-webrtc` at PyCon JP 2021 is available: https://youtu.be/_LuLs8H1gJc\r\n\r\nArticles about this library:\r\n\r\n* [Developing Web-Based Real-Time Video/Audio Processing Apps Quickly with Streamlit](https://towardsdatascience.com/developing-web-based-real-time-video-audio-processing-apps-quickly-with-streamlit-7c7bcd0bc5a8)\r\n* [Real-Time Video Streams With Streamlit-WebRTC](https://betterprogramming.pub/real-time-video-streams-with-streamlit-webrtc-bd38d15f2ef3)\r\n\r\nAs linked from the repo, demo apps I have developed are available online:\r\n\r\n* Demo showcase including real-time object detection: https://share.streamlit.io/whitphx/streamlit-webrtc-example/main/app.py\r\n  * Source code: https://github.com/whitphx/streamlit-webrtc-example/blob/main/app.py\r\n* Real-time Speech-to-Text: https://share.streamlit.io/whitphx/streamlit-stt-app/main/app_deepspeech.py\r\n  * Source code: https://github.com/whitphx/streamlit-stt-app\r\n* Real-time style transfer: https://share.streamlit.io/whitphx/style-transfer-web-app/main/app.py\r\n  * Source code: https://share.streamlit.io/whitphx/style-transfer-web-app/main/app.py\r\n* Real-time Tokyo 2020 Pictogram: https://share.streamlit.io/whitphx/tokyo2020-pictogram-using-mediapipe/streamlit-app\r\n  * Source code: https://github.com/whitphx/Tokyo2020-Pictogram-using-MediaPipe\r\n* Video chat: online demo is not available because it does not have an auth mechanism and is only for private use.\r\n  * Source code: https://github.com/whitphx/streamlit-video-chat-example",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "8D9LD8",
    "title": "Creating great user interfaces on Jupyter Notebooks with ipywidgets",
    "speakers": [
      {
        "code": "TQCKYE",
        "name": "Deborah Mesquita",
        "biography": "I’m Déborah and I’m a data scientist who really likes to write. I have a BSc in Computer Science and I’ve been working with Data Science since 2016 when I won the Microsoft Imagine Machine Learning Award.\r\n\r\nI’m a generalist, so I can grasp new technology quickly and I can learn as much as I need to reach the goals of a project. I think this gives me an advantage in writing because it’s easier for me to “zoom out” and explain things from a broader point of view than someone who has more experience in a particular technology.",
        "avatar": "https://program.europython.eu/media/avatars/scene01901_qomhn8m.jpeg",
        "slug": "deborah-mesquita"
      }
    ],
    "submission_type": "Talk",
    "slug": "creating-great-user-interfaces-on-jupyter-notebooks-with-ipywidgets",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "Jupyter notebooks are great to quickly try new ideas and experiments, but the downside is that using code to change inputs and see the results can be inefficient and error-prone. ipywidget is a Python library that solves this problem by providing a user-friendly interface with iterative widgets. It's all in Python so we don't have to worry with any CSS or Javascript. In this talk we'll learn how ipywidgets can help us build tools in the context of Data Science.",
    "description": "A useful Jupyter notebook that takes input from the user to generate results is a great candidate to become a web application, but usually data scientists don't have the front-end skills required to build one and deploy them. Using notebooks with ipywidgets can be a great solution to build teams' internal tools because we get the user-friendly widgets and don't need to worry about the deployment since it's all in Jupyter.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "KM8Z88",
    "title": "Build with Audio: The easy & hard way!",
    "speakers": [
      {
        "code": "DHPEJJ",
        "name": "Vaibhav Srivastav",
        "biography": "I am a Data Scientist and a Masters Candidate - Computational Linguistics at Universität Stuttgart. I am currently researching on Speech, Language and Vision methods for extracting value out of unstructured data.\r\n\r\nIn my previous stint with Deloitte Consulting LLP, I worked with Fortune Technology 10 clients to help them make data-driven (profitable) decisions. In my surplus time, I served as a Subject Matter Expert on Google Cloud Platform to help build scalable, resilient and fault-tolerant cloud workflows.\r\n\r\nBefore this, I have worked with startups across India to build Social Media Analytics Dashboards, Chat-bots, Recommendation Engines, and Forecasting Models.\r\n\r\nMy core interests lie in Natural Language Processing, Machine Learning/ Statistics and Cloud based Product development.\r\n\r\nApart from work and studies, I love travelling and delivering Workshops/ Talks at conferences and events across APAC and EU, DevConf.CZ, Berlin Buzzwords, DeveloperDays Poland, PyCon APAC (Philippines), Korea, Malaysia, Singapore, India, WWCode Asia Connect, Google DevFest, and Google Cloud Summit.",
        "avatar": "https://program.europython.eu/media/avatars/JFlrSzB4_400x400_e1UV9lu.jpg",
        "slug": "vaibhav-srivastav"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "build-with-audio-the-easy-hard-way",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "The audio (& speech) domain is going through a massive shift in terms of end-user performances. It is at the same tipping point as NLP was in 2017 before the Transformers revolution took over. We’ve gone from needing a copious amount of data to create Spoken Language Understanding systems to just needing a 10-minute snippet. \r\n\r\nThis tutorial will help you create strong code-first & scientific foundations in dealing with Audio data and build real-world applications like Automatic Speech Recognition (ASR) Audio Classification, and Speaker Verification using backbone models like Wav2Vec2.0, HuBERT, etc.",
    "description": "Unlike general Machine Learning problems where we either classify i.e. segregate a data point into a pre-defined class or regress around a continuous variable, audio related problems can be slightly more complex. Wherein, we either go from an audio representation to a text representation (ASR) or separate different layers of audio (Diarization) and so on. This tutorial will not only help you build applications like these but also unpack the science behind them using a code-first approach.\r\n\r\nEvery step of the way we’ll first write and run some code and then take a step back and unpack it all till it makes sense. We’ll make science *fun* again :)\r\n\r\nThe tutorial will be divided into 3 key sections:\r\n\r\n1. Read, Manipulate & Visualize Audio data\r\n2. Build your very own ASR system (using pre-trained models like Wav2Vec2.0) & deploy it\r\n3. Create an Audio Classification pipeline & infer the model for other downstream audio tasks \r\n\r\nAt the end of the tutorial, you’ll develop strong intuition about Audio data and learn how to leverage large pre-trained backbone models for downstream tasks. You’ll also learn how to create quick demos to test and share your models.\r\n\r\nLibraries: HuggingFace, SpeechBrain, PyTorch & Librosa",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "8YX9RG",
    "title": "Using animated charts to present & share your findings",
    "speakers": [
      {
        "code": "Q7VFPN",
        "name": "Peter Vidos",
        "biography": "Peter is the CEO & Co-Founder of [Vizzu](https://vizzuhq.com). \r\n\r\nHis primary focus is understanding how Vizzu's innovative approach to data visualization can be put to good use. Listening to people complaining about their current hurdles with building charts and presenting them is his main obsession, next to figuring out how to help data professionals utilize the power of animation in dataviz.\r\n\r\nPeter has been involved with digital product development for over 15 years. Earlier products/projects he worked on cover mobile app testing, online analytics, data visualization, decision support, e-learning, educational administration & social. Still, building a selfie teleport just for fun is what he likes to boast about when asked about previous experiences.",
        "avatar": "https://program.europython.eu/media/avatars/Peter_Vidos_headshot3_Ak67UYJ.jpg",
        "slug": "peter-vidos"
      }
    ],
    "submission_type": "Talk",
    "slug": "using-animated-charts-to-present-share-your-findings",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "Sharing and explaining the results of your analysis can be a lot easier and more fun when you can create an animated story of the charts containing your insights. Vizzu - a new open-source charting library, now available for Jupyter notebooks, enables just that with a simple Python interface. In this talk, the creators of Vizzu show how their technology works and provide examples of the advantages of using animation for storytelling with data.",
    "description": "In this talk we'll cover the following topics:\r\n\r\n- The problem with the well-known chart taxonomies: starting from \"what would you like to show\"\r\n- Creating a generic chart morphing engine\r\n- Advantages of using animation for storytelling - from the presenter's and the audience's perspective\r\n- Examples and best practices of using Vizzu in Jupyter",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "CQ7NBC",
    "title": "Building a Just-in-Time Python FaaS Platform with Unikraft",
    "speakers": [
      {
        "code": "GXDRHH",
        "name": "Felipe Huici",
        "biography": "Dr. Felipe Huici is CEO and Co-Founder at Unikraft UG, a start-up dedicated to lightweight and open source virtualization technologies and significantly lowering cloud infrastructure bills. In addition, Felipe is a chief researcher at NEC Laboratories Europe in Heidelberg, Germany where his main research and interests lie in the areas of high-performance software systems, and in particular specialization, virtualization and security. He has been published in several top-tier conferences and journals such as SOSP, ASPLOS, OSDI, Eurosys, SIGCOMM, NSDI, CoNEXT, and SIGCOMM CCR. Finally, Felipe is one of the founders and maintainers of the Linux Foundation Unikraft open source project.",
        "avatar": "https://program.europython.eu/media/avatars/felipehuici_ixalJ4j.jpeg",
        "slug": "felipe-huici"
      },
      {
        "code": "RRE9DV",
        "name": "Alexander Jung",
        "biography": "Alexander Jung is a Co-Founder and Chief Product Officer at the Lightweight Virtualization company Unikraft, focusing on leading unikernels into market and mass deployment.  He is also a PhD student at Lancaster University, where he focuses primarily on optimizations of unikernels for network-bound operations; delivering effective continuous integration and deployment of VNF-based services; as well as compile-time methods for inter-VM communication based on library Operating Systems.  Previously he has worked as the Chief Information Officer at UK-based startup Adjacent Systems, securing and delivering systems for local law-enforcement and government.",
        "avatar": "https://program.europython.eu/media/avatars/Photo-on-12.08.21-at-15.36_shop_copy_a4H0crA.jpg",
        "slug": "alexander-jung"
      }
    ],
    "submission_type": "Talk",
    "slug": "building-a-just-in-time-python-faas-platform-with-unikraft",
    "track": "Infrastructure: Cloud & Hardware",
    "state": "accepted",
    "abstract": "Function-as-a-Service (FaaS) platforms are one of the key service offerings for any cloud provider. To provide strong isolation, the functions are run inside heavy-weight virtual machines (and within containers inside those for orchestration reasons). Consequently, such instances take too long to boot and so are kept on all the time, even though the functions only receive requests intermittently. The end result is that current FaaS platforms are much less efficient than they could be.\r\n\r\nWe will introduce a radically novel way to build FaaS platforms based on Python and the Unikraft Linux Foundation open source project (www.unikraft.org). Unikraft is a toolkit for building fully specialized, cloud-ready virtual machines called unikernels targeting a single application . Using Unikraft we can construct extremely specialized, Python-based unikernels that use only a few MBs to run a boot in 10s of milliseconds, allowing us to bring VMs up as a request to a function comes in, and to shut it down (or suspend it) afterwards. The result: a Python-based FaaS platform that is significantly more efficient and cheaper to operate than existing offerings.\r\n\r\nIn the talk we will provide an introduction to Unikraft, how Python is built on top of it, a full description of the FaaS platform and a short demo.",
    "description": "Unikraft [1] is a unikernel (specialized virtual machine) project. Unikraft is able to target a specific application (e.g., a web server such as NGINX) and transparently build an entire software stack, from the operating system all the way up to systems libraries, that includes only the parts that the application needs and nothing more. Such specialization results in extremely short boot times (a few milliseconds compared to hundreds or thousands for Linux VMs), small image sizes and memory consumption (e.g., a few MBs vs. hundreds of MBs) and a minimal attack surface, to name a few benefits. The short boot times also allow us to bring Unikraft VMs up just-in-time, as a request for a service arrives, and to bring the instance back down (or suspend it) when the request is over, allowing for even greater efficiency.\r\n\r\nIn addition, Unikraft images are single address space: in cloud environments strong isolation is provided by the hypervisor, so for single application/single tenant VMs it does not make sense to have a kernel/user-space divide. The end result is higher efficiency in performance, with Unikraft yielding noticeably higher throughout than Linux [2].\r\n\r\nRegarding application support, we have put great effort towards making Unikraft as POSIX compatible as possible. Unikraft provides a syscall shim-layer and support for the musl libc, allowing us to run unmodified versions of Python. \r\n\r\nIn terms of orchestration, we have integrated Unikraft with major frameworks such as Kubernetes and Prometheus. This, along with extensive debugging facilities should make Unikraft easy to both use and develop for.\r\n\r\n[1] https://unikraft.org/\r\n[2] https://dl.acm.org/doi/10.1145/3447786.3456248 (best paper award)",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "JBTGFL",
    "title": "Build your own Playlist Recommender System with Python using your GDPR Data",
    "speakers": [
      {
        "code": "G8LVXX",
        "name": "Marcel Kurovski",
        "biography": "Senior Data Scientist and Innovation Lead at inovex\r\nHost of Recsperts - Recommender Systems Experts, the Podcast Show with industry and academia experts in Recommender Systems\r\nBuilding Recommenders and Personalization Solutions with Python for various industries since 5+ years\r\nCreator and Instructor of Python RecSys Training",
        "avatar": "https://program.europython.eu/media/avatars/gh_avatar_94Jm1CM.png",
        "slug": "marcel-kurovski"
      }
    ],
    "submission_type": "Talk",
    "slug": "build-your-own-playlist-recommender-system-with-python-using-your-gdpr-data",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "In my talk, we explore our usage data requested according to GDPR and leverage it - together with Spotify’s Web API - to build a personalized playlist recommender system with Python.\r\n\r\nIn 2018, the General Data Protection Regulation (GDPR) became effective in the EU. It sometimes causes data scientists great headaches. But from a consumer and Pythonista point of view this can also be interesting data for exploration. It is very useful for building personalization technology, in particular recommender systems. And there are almost endless ways to use Python for it.\r\nSo, let’s request and use our own data to build a playlist recommender system which infers our music taste from our streaming history and uses it to retrieve songs from our favorites in a new way. We will call it “Your Rediscover Past”, a personalized playlist based on your streaming history and saved songs.",
    "description": "Personalized Playlist Recommendations on Spotify are great – some of them let us discover new songs, some others help us to rediscover songs. However, rediscovery seems to be limited on the more recent past, i.e. going only a month backwards. This is a problem if you like to rediscover some of your favorite songs you might have listened to a longer while ago. Sometimes we add them to our \"liked songs\" where they likely fade away. However, you once explicitly declared those tracks as favorites. So, what is it that we can do about this missing piece in personalized playlist recommendations?\r\n\r\nWell, the first thing we do is to request our personal usage data from Spotify according to GDPR. Second, we analyze and enrich it with track audio features offered by Spotify’s rich Web API. We derive the music taste profile of ourselves from 12 months of streaming history and use this taste profile to retrieve favorite songs we haven’t listened to for more than a year. In my talk, I present you the Python package I build for this purpose, possible extensions and enable you to create your own personalized playlist to rediscover your past!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "MWET9Y",
    "title": "Three Musketeers: Sherlock Holmes, Mathematics and Python",
    "speakers": [
      {
        "code": "CPJQQS",
        "name": "Gajendra Deshpande",
        "biography": "Mr. Gajendra Deshpande holds a Master’s degree i.e., M.Tech. in Computer Science and Engineering from Visvesvaraya Technological University, Belagavi and PG Diploma in Cyber Law and Cyber Forensics from National Law School of India University, Bengaluru India. He is working as Assistant Professor at the Department of Computer Science and Engineering, KLS Gogte Institute of Technology, Belagavi, Karnataka, India. He has a teaching experience of 12+ years and Linux and Network Administration experience of one year. Under his mentorship teams have won Smart India Hackathon 2018, 2019 and 2020. Presented talks at prestigious conferences such as SciPy USA, JuliaCon, PyCon France, PyCon Hong Kong, PyCon Taiwan, COSCUP Taiwan, PyCon Africa, BuzzConf Argentina, EuroPython, PiterPy Russia and SciPy India. Worked as Reviewer and Program Committee member for reputed International Journals and conferences including JOSS, JOSE, SciPy USA, SciPy Japan, JuliaCon, JupyterCon, PyData Global, and PyCon India, and publishers include Manning USA and Oxford Univesity Press. He leads PyData Belagavi and OWASP Belagavi chapters. He is also GitHub Certified Campus Advisor",
        "avatar": "https://program.europython.eu/media/avatars/gcdprofile1_RghiOf3.jpg",
        "slug": "gajendra-deshpande"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "three-musketeers-sherlock-holmes-mathematics-and-python",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "Mathematics is a science and one of the most important discoveries of the human race on earth. Math is everywhere and around us. It is in nature, music, sports, economics, engineering, and so on.  In our daily life, we use mathematics knowingly and unknowingly.  Many of us are unaware that forensic experts use mathematics to solve crime mysteries. In this workshop, we will explore how Sherlock Holmes, the famous fictional detective character created by Sir Arthur Conan Doyle uses Mathematics and Python programming language to solve crime mysteries. In short, the workshop begins with an introduction to forensic mathematics and covers basic principles thereby setting the stage. Then, we will solve simple crime puzzles using mathematics and simple python scripts. Finally, we will solve a few complex hypothetical crime mysteries using advanced python concepts. The participants will learn how to use the concepts of mathematics such as statistics, probability, trigonometry, and graph theory, and python and its packages such as SciPy, NumPy, and Matplotlib to solve the crime puzzles.",
    "description": "Mathematics is a science and one of the most important discoveries of the human race on earth. Math is everywhere and around us. It is in nature, music, sports, economics, engineering, and so on.  In our daily life, we use mathematics knowingly and unknowingly.  Many of us are unaware that forensic experts use mathematics to solve crime mysteries. In this workshop, we will explore how Sherlock Holmes, the famous fictional detective character created by Sir Arthur Conan Doyle uses Mathematics and Python programming language to solve crime mysteries. In short, the workshop begins with an introduction to forensic mathematics and covers basic principles thereby setting the stage. Then, we will solve simple crime puzzles using mathematics and simple python scripts. Finally, we will solve a few complex hypothetical crime mysteries using advanced python concepts. The participants will learn how to use the concepts of mathematics such as statistics, probability, trigonometry, and graph theory, and python and its packages such as SciPy, NumPy, and Matplotlib to solve the crime puzzles.   \r\n\r\n<b>Outline</b>\r\n<b>1. Introduction to Forensic Mathematics and overview of basic concepts (25 Minutes)</b>\r\n- Numbers and their representation\r\n- Units of Measurements\r\n- Basic chemical calculations\r\n- Functions, Formulae and equations\r\n- Pythagoras Theorem\r\n- Trigonometric methods\r\n- Graphs\r\n- Statistics and probability\r\n\r\n<b>2. Problems</b>\r\n- Estimate the pressure of a shoe print on a soft ground (05 Minutes)\r\n- Calculate the uncertainty given the measurement of bullet diameter (05 Minutes)\r\n- Calculate the mean molar mass (10 Minutes)\r\n- Calculate the percentage of concentrations (10 Minutes)\r\n\r\n<b>------BREAK -------- (05 Minutes)</b>\r\n\r\n- Compute bloodstain thickness (05 Minutes)\r\n- Calculate terminal velocity for a fine blood droplet (05 Minutes)\r\n- Calculate the persistence of gunshot residue particles in air (05 Minutes)\r\n- Calculate the impact speed and estimate the drop height of blood droplet (05 Minutes)\r\n- Post-mortem body cooling (05 minutes)\r\n- Ricochet analysis and aspects of ballistics (10 Minutes)\r\n- Suicide, Accident or murder? (05 Minutes)\r\n- Blood stain pattern analysis (10 minutes)\r\n- Persistence of hair, fibres, and flints on clothing (05 minutes) \r\n\r\n<b>-----------BREAK-----------  (05 Minutes)</b> \r\n\r\n- Determine the time since death (05 Minutes)\r\n- Determine the age from bone or tooth material (05 Minutes)\r\n- Matching of hair evidence (05 Minutes)\r\n- Matching bite marks (05 Minutes)\r\n- DNA Profiling: Genotype and allele calculations (10 Minutes)\r\n\r\n<b>3. Advanced Problems</b> \r\n- A Game of Shadows (10 Minutes)\r\n-  Bicycle Problem (10 Minutes)\r\n-  Detect the location of a serial killer (10 Minutes)",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "LY3NUG",
    "title": "Beyond the Basics: Data Visualization in Python",
    "speakers": [
      {
        "code": "9WJJPL",
        "name": "Stefanie Molin",
        "biography": "Stefanie Molin is a software engineer and data scientist at Bloomberg in New York City, where she tackles tough problems in information security, particularly those revolving around data wrangling/visualization, building tools for gathering data, and knowledge sharing. She is also the author of \"Hands-On Data Analysis with Pandas,\" which is currently in its second edition. She holds a bachelor’s of science degree in operations research from Columbia University's Fu Foundation School of Engineering and Applied Science. She is currently pursuing a master’s degree in computer science, with a specialization in machine learning, from Georgia Tech. In her free time, she enjoys traveling the world, inventing new recipes, and learning new languages spoken among both people and computers.",
        "avatar": "https://program.europython.eu/media/avatars/IMG_6741_FP3yFK2.JPG",
        "slug": "stefanie-molin"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "beyond-the-basics-data-visualization-in-python",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "The human brain excels at finding patterns in visual representations, which is why data visualizations are essential to any analysis. Done right, they bridge the gap between those analyzing the data and those consuming the analysis. However, learning to create impactful, aesthetically-pleasing visualizations can often be challenging. This session will equip you with the skills to make customized visualizations for your data using Python.\r\n\r\nWhile there are many plotting libraries to choose from, the prolific Matplotlib library is always a great place to start. Since various Python data science libraries utilize Matplotlib under the hood, familiarity with Matplotlib itself gives you the flexibility to fine tune the resulting visualizations (e.g., add annotations, animate, etc.). This session will also introduce interactive visualizations using HoloViz, which provides a higher-level plotting API capable of using Matplotlib and Bokeh (a Python library for generating interactive, JavaScript-powered visualizations) under the hood.",
    "description": "#### Section 1: Getting Started With Matplotlib\r\nWe will begin by familiarizing ourselves with Matplotlib. Moving beyond the default options, we will explore how to customize various aspects of our visualizations. By the end of this section, you will be able to generate plots using the Matplotlib API directly, as well as customize the plots that libraries like pandas and Seaborn create for you.\r\n\r\n#### Section 2: Moving Beyond Static Visualizations\r\nStatic visualizations are limited in how much information they can show. To move beyond these limitations, we can create animated and/or interactive visualizations. Animations make it possible for our visualizations to tell a story through movement of the plot components (e.g., bars, points, lines). Interactivity makes it possible to explore the data visually by hiding and displaying information based on user interest. In this section, we will focus on creating animated visualizations using Matplotlib before moving on to create interactive visualizations in the next section.\r\n\r\n#### Section 3: Building Interactive Visualizations for Data Exploration\r\nWhen exploring our data, interactive visualizations can provide the most value. Without having to create multiple iterations of the same plot, we can use mouse actions (e.g., click, hover, zoom, etc.) to explore different aspects and subsets of the data. In this section, we will learn how to use a few of the libraries in the HoloViz ecosystem to create interactive visualizations for exploring our data utilizing the Bokeh backend.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "KMCFKN",
    "title": "Data Warehouses Meet Data Lakes",
    "speakers": [
      {
        "code": "8MDEKJ",
        "name": "Mauro",
        "biography": "Mauro Pelucchi is a senior data scientist and big data engineer \r\nresponsible for the design of the \"Real-Time Labour Market Information System on Skill Requirements\" for CEDEFOP.\r\n\r\nHe currently works as Head of Global Data Science @ EMSI Burning-Glass with the goal to develop innovative models, methods and deployments of labour market data and other data to meet customer requirements and prototype new potential solutions. His main tasks are related to advanced machine learning modelling, labour market analyses, and the design of big data pipelines to process large datasets of online job vacancies.\r\nIn collaboration with the University of Milano-Bicocca, he took part in many research projects related to the labour market intelligence systems.\r\nHe collaborates with the University of Milano-Bicocca as a lecturer at the Master Business Intelligence and Big Data Analytics and with the University of Bergamo as a lecturer in Computer Engineering.",
        "avatar": "https://program.europython.eu/media/avatars/BGT_Mauro_Pelucchi__LARGE_UV7Pfua.jpg",
        "slug": "mauro"
      }
    ],
    "submission_type": "Talk",
    "slug": "data-warehouses-meet-data-lakes",
    "track": "PyData: Data Engineering",
    "state": "accepted",
    "abstract": "Many organizations have migrated their data warehouses to datalake solutions in recent years.\r\nWith the convergence of the data warehouse and the data lake, a new data management paradigm has emerged that combines the best of 2 approaches: the botton-up of big data and the top-down of a classic data warehouse.",
    "description": "In this talk, I will explain the current challenges of a datalake and how we can approach a \r\nmoderm data architecture with the help of pyspark, hudi, delta.io or iceberg.\r\nWe will see how organize data in a data lake to support real-time processing of applications \r\nand analyzes across all varieties of data sets, structured and unstructured, how provides \r\nthe scale needed to support enterprise-wide digital transformation and creates one unique source of data \r\nfor multiple audiences.",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "expert"
  },
  {
    "code": "JL7LBG",
    "title": "Build your own linters",
    "speakers": [
      {
        "code": "JHSJBW",
        "name": "Rahul Jha",
        "biography": "I'm a senior software engineer at https://deepsource.io, where I work on developing tools to improve code health and quality.\r\n\r\nI'm the maintainer of [Vulture](https://github.com/jendrikseipp/vulture), and it will have your dead Python. Thank you!",
        "avatar": "https://program.europython.eu/media/avatars/rahul-profile-picture_VCHth3N.png",
        "slug": "rahul-jha"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "build-your-own-linters",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "Despite a ton of wonderful linters out there, it pays off to scratch your itch and learn how to write one yourself. Anytime a pet peeve starts bothering you in code reviews, you’ll have all the tools at your disposal.",
    "description": "Developers are opinionated, and it reflects in their programming style — not just the way code _looks_, but how it _feels_: its organization and readability. In such cases, maintaining consistency across a project helps everyone involved. One aspect of this is ensuring that there are (at least partial) automated tests to enforce this style.\r\n\r\nThis training aims to enable the audience to write such tests by giving them a tour of code analysis and the vast array of tools it makes available to us. First, we dissect the code using Python's `ast` and `tokenize` modules and object internals like `__dict__`. From there and on, we visit some real-world examples:\r\n- A test to detect unnecessary use of double-quotes. They are such a terrible waste of pixels, after all.\r\n- Flagging the use of list() instead of []. The former is slower – as it requires an extra lookup in \"globals\" – and might result in a bug if the name is rebound to another object.\r\n- Find if statements are nested for more than four levels. It can lead to hard-to-understand, ugly-looking code.\r\n- Look for unused imports. Shred the extra loading time and memory amounting from these unused lines of code.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "9QM8ZM",
    "title": "What transitioning from male to female taught me about leadership",
    "speakers": [
      {
        "code": "9SYDFX",
        "name": "Ivett Ördög",
        "biography": "Ivett Ördög is the founder and facilitator of Lean Poker events. She is also an Engineering Manager at Contentful, and she has been a frequent speaker at software conferences around Europe. Her passion for short feedback loops drove her to create Lean Poker, a workshop where developers have the opportunity to experiment with continuous delivery in a safe environment. Ivett is the creator and host of the Cup of Code YouTube channel inspiring the next generation of developers to broaden their knowledge.",
        "avatar": "https://program.europython.eu/media/avatars/DSC_2275_VN94PyO.jpg",
        "slug": "ivett-ordog"
      }
    ],
    "submission_type": "Talk",
    "slug": "what-transitioning-from-male-to-female-taught-me-about-leadership",
    "track": "Career, Life,...",
    "state": "confirmed",
    "abstract": "Not many leaders transition in their mid thirties but I did and it gave me a unique perspective on courage, humility, diversity and inclusion in the context of leadership. In this talk I will tell the story of my transition and along the way you will learn how you can become a better leader.",
    "description": "I’ve been struggling with gender dysphoria (a debilitating sense of disconnect from the gender assigned to someone at birth) for decades, but it took me until not so long ago to realize what it was, and how it could be treated. Nothing has been the same since. Transitioning and the events leading up to it changed my life, and the experiences I had during my transition changed me as a person, and as a leader.\r\n\r\nIt’s hard for me to open up about this period in my life, not just because it comes with tremendous vulnerability, not just because it’s very personal, but also because it has been the hardest few months in my life. The decisions I faced were far more consequential and way harder to grapple than any decisions I had to make as a leader or any time during my professional career. However I feel that other people — people who will never go through anything like I did — can learn from my story a lot exactly because it has been a very unusual and difficult problem to solve.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "M83YDN",
    "title": "Norvig's lispy: beautiful and illuminating Python code",
    "speakers": [
      {
        "code": "AX8V78",
        "name": "Luciano Ramalho",
        "biography": "Luciano Ramalho is the author of Fluent Python, published in 9 languages. He is a Principal Consultant at Thoughtworks and a Fellow of the Python Software Foundation.",
        "avatar": "https://program.europython.eu/media/avatars/LucianoRamalho2016-500x.jpg",
        "slug": "luciano-ramalho"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "norvig-s-lispy-beautiful-and-illuminating-python-code",
    "track": "Python Friends",
    "state": "confirmed",
    "abstract": "Why isn't `if` a function? Why does Python need to add keywords from time to time? What precisely is a closure, what problem does it solve, and how does it work? These are some of the fundamental questions you'll be able to answer after this tutorial: an interactive exploration of Peter Norvig's  `lis.py`–an interpreter for a subset of the Scheme dialect of Lisp in 132 lines of Python.",
    "description": "Peter Norvig of Stanford University wrote `lis.py`: an interpreter for a subset of the Scheme dialect of Lisp in 132 lines of readable Python. I took Norvig's code, updated it to modern Python coding style, and integrated it into a Jupyter notebook that provides explanations as well as interactive experiments and exercises checked automatically.\r\n\r\nWhy should you study lis.py? This is what I got out of it:\r\n\r\n* Learning how an interpreter works gave me a deeper understanding of Python and programming languages in general—interpreted or compiled.\r\n\r\n* The simplicity of Scheme is a master class of language design.\r\n\r\n* `lis.py` is a beautiful example of idiomatic Python code.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "DSCHNK",
    "title": "Managing the code quality of your project. Leave the past behind: Focus on new code.",
    "speakers": [
      {
        "code": "QQNWRG",
        "name": "Andrea Guarino",
        "biography": "Developer at SonarSource, working on SonarQube Python analyzer.\r\nPassionate about programming languages, soulslike video games and astrophotography.",
        "avatar": "https://program.europython.eu/media/avatars/andrea-guarino_09DVeT1.jpeg",
        "slug": "andrea-guarino"
      }
    ],
    "submission_type": "Talk",
    "slug": "managing-the-code-quality-of-your-project-leave-the-past-behind-focus-on-new-code",
    "track": "DevOps",
    "state": "confirmed",
    "abstract": "If you try to use Pylint or Flake8 on a legacy project, the results are usually truly overwhelming. There might be thousands of warnings, hundreds of errors and maybe even no unit tests. \r\nThe usual emotional response to this is distress, exasperation... even despair. And then the question comes: *Where do I start?*\r\n\r\nDuring this talk we will see why it’s better to set old code aside and focus first on the new code you’re writing. We’ll show some possible approaches and tools that can help you keep the focus and deliver new code with a high level of quality.",
    "description": "As developers we often have to deal with legacy projects and, at the same time, we want to keep the quality and security of our deliverables under control.\r\n\r\nAs soon as we start running some linter (like Pylint or Flake8) on such a legacy project, there is a huge number of violations. To handle those issues, we might want to start by only looking at the changed files in a pull request instead of the entire project, for example by using _git diff_\r\n```\r\npylint `git diff --name-only --diff-filter=d`\r\n```\r\n\r\nDuring this talk I’d like to push this concept a bit further and outline an approach and philosophy that can be helpful in dealing with code quality : *Clean as you code*.\r\n### What is *Clean as you code*?\r\n* Not only about violations: It can be extended to code coverage and all code metrics in general.\r\n* The quality you want to measure should be based only on recent changes.\r\n\r\n### Why *Clean as you code* matters?\r\n\r\n* It helps your team stay focused on delivering new features\r\n* It helps you deal with technical debt incrementally: Sometimes you might need to modify old code, and, at that point, you might be able to fix existing violations\r\n\r\n### How to apply *Clean as you code*?\r\n* Shaping a *quality gate* in order to define code quality standards for the software delivered by your team today\r\n* Using appropriate tools (like SonarQube)",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "YBQYF3",
    "title": "Forget Mono vs. Multi-Repo - Building Centralized Git Workflows with Python",
    "speakers": [
      {
        "code": "EZU9HM",
        "name": "David Melamed",
        "biography": "Currently CTO and Co-Founder of Jit, the Continuous Security platform for Developers. David has a PhD in Bioinformatics and for the past 20 years has been a full-stack developer, CTO & technical evangelist, mostly in the cloud, and specifically in cloud security, working for leading organizations such as MyHeritage, CloudLock (acquired by Cisco) and leading the 'advanced development team' for the CTO of Cisco's cloud security (a $500M ARR BU).",
        "avatar": "https://program.europython.eu/media/avatars/dvdmelamed-pic_drHBbME.jpeg",
        "slug": "david-melamed"
      },
      {
        "code": "TUCBCX",
        "name": "Daniel Koch",
        "biography": null,
        "avatar": null,
        "slug": "daniel-koch"
      }
    ],
    "submission_type": "Talk",
    "slug": "forget-mono-vs-multi-repo-building-centralized-git-workflows-with-python",
    "track": "DevOps",
    "state": "confirmed",
    "abstract": "The mono vs. multi-repo is an age-old debate in the DevOpsphere, and one that can still cause flame wars.  What if I were to tell you that you don't have to choose?\r\nIn this talk we will dive into how we built a centralized Git workflow that can work with any kind of repo architecture, delivered with Python.\r\n\r\nOne of the greatest recurring pains in CI/CD is the need to reinvent the wheel and define your CI workflow for each and every repository or (micro)service, when eventually 99% of the config is the same.  What if we could hard reset this paradigm and create a single, unified workflow that is shared by all of our repos and microservices?  In this talk, we will showcase how a simple solution implemented in Python, demoed on Github as the SCM, and Github Actions for our CI, enabled us to unify this process for all of our services, and improve our CI/CD velocity by orders of magnitude.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "QKS7UE",
    "title": "Bulletproof Python – Property-Based Testing with Hypothesis",
    "speakers": [
      {
        "code": "A7BNZH",
        "name": "Michael Seifert",
        "biography": "Michael is a consulting software engineer who helps product teams to develop Python software in the cloud. He worked with many different teams from various industries, but none of them practised property-based testing and only few were familiar with the concept.\r\n\r\nThis prompted him to spread the word about property-based testing and Hypothesis in an effort to help others write more robust and maintainable software.",
        "avatar": "https://program.europython.eu/media/avatars/michael_seifert_-_300x300_KY7yE8t.png",
        "slug": "michael-seifert"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "bulletproof-python-property-based-testing-with-hypothesis",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "Property-based testing is a great benefit to the robustness and maintainability of your software. Yet, the technique is still vastly underused in the Python community. The workshop gives a hands-on introduction to Hypothesis and practices different approaches for writing property-based tests.",
    "description": "Do you find yourself working through pages of copied and pasted tests to accommodate a simple code change? Does your software frequently break in unexpected ways despite your testing efforts? Don’t despair! Property-based testing could be your way out of that mess. Rather than working harder and writing more test code, property-based testing forces you to work smarter and test more code with fewer tests.\r\n\r\nTraditional tests are example-based. They require the developer to come up with arbitrary inputs and check a system’s behavior against explicit outputs. More often than not, developers only think of inputs that are handled correctly by their code, thus leaving bugs hidden. Property-based tests generate the inputs for you and in many cases they’re more likely to find invalid inputs than humans. The difficulty lies in formulating these test cases.\r\n\r\nAfter this workshop you’ll be comfortable with property-based testing using Hypothesis. You’ll have experience requesting appropriate test data from Hypothesis and in writing tests for common and more advanced properties. At work, your co-workers will be impressed by your unbreakable code ;)\r\n\r\nParticipants are expected to have basic familiarity with unit testing and a testing framework. Provided code examples use pytest.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "FND7LQ",
    "title": "Quality Assurance in Django - Testing what matters",
    "speakers": [
      {
        "code": "GLMZDC",
        "name": "Radoslav Georgiev",
        "biography": "Generalist. A multi-disciplinary problem solver & a technical team lead.\r\n\r\nCurrently leading & growing teams at HackSoft.\r\n\r\nA programmer from ~10 years, studied Computer Science in the Faculty of Mathematics and Informatics, Sofia University.\r\n\r\nFounder and CEO of HackSoft (Sofia based software company with main focus in Python, Django and Scala) and HackBulgaria (Programming courses, based in Sofia / Bulgaria with main focus of getting the students ready for their first job - either as an intern or a junior developer. Mainly focused in Python and Java)\r\n\r\nAlso doing a lot of teaching - Functional Programming classes (Racket / Haskell) @Faculty of Mathematics and Informatics , Programming with Python and Django @HackBulgaria.\r\n\r\nGitHub - https://github.com/RadoRado/",
        "avatar": "https://program.europython.eu/media/avatars/Radoslav_HackSoft_team_AiYbuH9.jpg",
        "slug": "radoslav-georgiev"
      }
    ],
    "submission_type": "Talk",
    "slug": "quality-assurance-in-django-testing-what-matters",
    "track": "Django",
    "state": "accepted",
    "abstract": "In software development, having tests is essential.\r\n\r\nWhen it comes to writing tests in Django, we often ask ourselves - “What to test?”.\r\n\r\nDjango gives us plenty of testing tools & a lot of choices for what to test - we can test models, forms, views, APIs, serializers, services, selectors, tasks & basically anything that’s well defined within the Django Framework.\r\n\r\nIn this talk, we’ll do 3 important things:\r\n\r\n1. We’ll put our quality assurance hat on.\r\n2. We’ll explore different real-life scenarios with Django apps.\r\n3. And we’ll see how to approach testing in those scenarios, so we can test the things that matter!",
    "description": "In software development, having tests is essential.\r\n\r\nAs developers, tests not only help us sleep well at night, but they also allow us to iterate faster & make changes with more confidence.\r\n\r\nIf we want quality, we need tests.\r\n\r\nWhen it comes to writing tests in Django, we often ask ourselves - “What to test?”.\r\n\r\nIt’s an important question since we don’t always have the time to test everything we want. Sometimes, we need to make a conscious decision about what to test & what to leave untested.\r\n\r\nWhen making that decision, it’s important to have a good sense of “what’s important”, so we can test that.\r\n\r\nDjango gives us plenty of testing tools & a lot of choices for what to test - we can test models, forms, views, APIs, serializers, services, selectors, tasks & basically anything that’s well defined within the Django Framework.\r\n\r\nIn this talk, we’ll do 3 important things:\r\n\r\n1. We’ll put our quality assurance hat on.\r\n2. We’ll explore different real-life scenarios with Django apps.\r\n3. And we’ll see how to approach testing in those scenarios, so we can test the things that matter!\r\n\r\nBy exploring those scenarios, we’ll also touch upon the following topics:\r\n\r\n- Having a test plan.\r\n- Naming conventions for our tests & test methods.\r\n- Django test settings.\r\n- Factories.\r\n- Test speed & optimizations.\r\n\r\nThe talk is going to be practical & pragmatic, giving plenty of examples & references for a follow-up.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "WVFUYA",
    "title": "Handling Errors the Graceful Way in Python",
    "speakers": [
      {
        "code": "ND3VKT",
        "name": "Riya Bansal",
        "biography": "Riya Bansal is an enthusiastic and passionate Software Engineer at Microsoft with 3 years of experience with enterprise volume licensing products and Microservice technologies. Riya has a lot of experience working with Data Lakes as well. She has worked from small-sized Startups to large MNCs and gained a lot of experience over the years.\r\nShe is a big Pythonista and really interested in writing Python considering the best practices. Apart from that, Riya has also led an amazing Python Community which is a volunteer-driven organization of amazing Pythonistas, enthusiasts, entrepreneurs, researchers, students, and many more with a primary interest in Python.\r\nShe has also been awarded the Google Women Tech makers Scholarship for her leadership skills and impact on the community of women in tech as well.  She has mentored over 10000+ students in the past.",
        "avatar": "https://program.europython.eu/media/avatars/Me_0z8yiRT.JPG",
        "slug": "riya-bansal"
      }
    ],
    "submission_type": "Talk",
    "slug": "handling-errors-the-graceful-way-in-python",
    "track": "Web",
    "state": "confirmed",
    "abstract": "Things rarely go as planned, especially in the world of programming. Errors are the bane of a programmer’s existence. You write an awesome piece of code, are ready to execute it and build a powerful machine learning model, and then poof. Python throws up an unexpected error, ending your hope of quick code execution.",
    "description": "In the process of programming, we are always going to encounter various errors. \r\nThings rarely go as planned, especially in the world of programming. Errors are unavoidable when writing code, which can be frustrating at times. Every single one of us has faced this issue and emerged from it a better programmer. Dealing with bugs and errors is what builds our confidence in the long run and teaches us valuable lessons along the way.\r\nSo, in this talk, we'll discuss different ways of handling errors and making our lives a little better. \r\nWe'll talk about how code written with effective exception handling strategies can help us to catch bugs early in the software developmental cycle.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "3U9T9S",
    "title": "Self-explaining APIs",
    "speakers": [
      {
        "code": "VST3SV",
        "name": "Roberto Polli",
        "biography": "Roberto joined in the [Italian Digital Transformation Department](https://innovazione.gov.it/it/progetti/api/) - to create a national API Ecosystem based on internet standards.\r\n\r\nHe's a Red Hat Certified Engineer and MySQL/MongoDB certified DBA, but loves maintaining free software.\r\n\r\nA life ago he took a Math degree, and he's really proud of it.",
        "avatar": null,
        "slug": "roberto-polli"
      }
    ],
    "submission_type": "Talk",
    "slug": "self-explaining-apis",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "To mash up various APIs, data need to have a well defined meaning: imagine meshing up healthcare APIs using different units for human temperature, or financial APIs using different currencies.\r\n\r\nThis talk describes strategies and python tools to overcome these problems in large API ecosystems such as data exchanges between different countries.",
    "description": "This talk will present strategies and python tools to create semantically interoperable REST APIs. After the problem statement, various solutions will be presented, including:\r\n\r\n* contract-first api development with OpenAPI 3, ontologies and controlled vocabularies like the ones [published by the European Union](https://op.europa.eu/en/web/eu-vocabularies/authority-tables);\r\n* the rdflib and pyld python libraries for processing json-ld and [RDF files](https://en.wikipedia.org/wiki/Resource_Description_Framework);\r\n* the use of centralized catalogs such as [schema.org](schema.org).\r\n\r\nPrerequisites:\r\n\r\n* no prior knowledge of semantics and ontologies;\r\n* practical experience with OpenAPI, json schema and data modeling and API design in general.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "expert"
  },
  {
    "code": "9PQZKF",
    "title": "Write Docs Devs Love: Ten Tricks To Level Up Your Tech Writing",
    "speakers": [
      {
        "code": "SN9SZQ",
        "name": "Mason Egger",
        "biography": "Mason is currently a Developer Advocate at Gretel. Prior to his work at Gretel, he was a Developer Advocate at DigitalOcean. Prior to this he was an SRE helping build and maintain a highly available hybrid multicloud PaaS. He is an avid programmer, speaker, educator, and writer. He is an organizer of PyTexas and actively contributes to open source projects. In his spare time he enjoys reading, camping, kayaking, and exploring new places.",
        "avatar": "https://program.europython.eu/media/avatars/attachment_6_Dicge7M.jpeg",
        "slug": "mason-egger"
      }
    ],
    "submission_type": "Talk",
    "slug": "write-docs-devs-love-ten-tricks-to-level-up-your-tech-writing",
    "track": "Community & Diversity",
    "state": "confirmed",
    "abstract": "Tutorials, blog posts, and product docs help developers learn. From our favorite tutorials to bad product docs we all consume technical writing. But what makes for good technical writing? In this talk I’ll share 10 tips and tricks to improve your technical writing skills to help your readers succeed",
    "description": "Think of that feeling you get when you follow an online tutorial or documentation and the code works on the first run. Now think of all the hours spent wasted following broken, outdated, or incomplete documentation. From our favorite tutorials to bad product docs we all consume technical writing. Tutorials, blog posts, and product docs help developers learn new things, build projects, and debug issues. But what makes one tutorial better than another? In this talk I'll discuss how you can write the documentation that developers love and I’ll share 10 tips and tricks to improve your technical writing.\r\n\r\n#### Outline\r\n* Introduction (1 min)\r\n* Why is Technical Writing Important? (4 min)\r\n* My Top 10 Tips to improve your Technical Writing (20 min)\r\n  * \\# 10 - Make Your End Goal Clear\r\n  * \\# 9 - Don’t Be Overly Verbose\r\n  * \\# 8 - Inclusive Language\r\n    * Avoid words like Simple, Easy\r\n  * \\# 7 - Avoid Technical Jargon\r\n  * \\# 6 - Define ALL Acronyms\r\n  * \\# 5 - Avoid Memes/Colloquialisms\r\n  * \\# 4 - Use Meaningful Code Samples and Variable Names\r\n  * \\# 3 - Don’t Make Your Reader Leave Your Article\r\n  * \\# 2 - Make it Easy for the Reader to Find a Single Piece of Information\r\n  * \\# 1 - Verify Your Instructions! Test, Test, Test!\r\n  * \\# 0 Bonus! - Practice, Practice, Practice\r\n* How You Can Get Started in Technical Writing (3 min)\r\n* Conclusion & Questions (2 min)",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "ZV9Y8M",
    "title": "What happens when you import a module?",
    "speakers": [
      {
        "code": "VZM8L3",
        "name": "Reuven M. Lerner",
        "biography": "Reuven is a full-time trainer in Python and data science, teaching companies around the world via in-person, online, and recorded courses. He is the author of both \"Python Workout\" and \"Pandas Workout,\" published by Manning, and writes the free, weekly \"Better developers\" newsletter read by more than 25,000 developers around the world. He lives with his wife and children in Modi'in, Israel.",
        "avatar": "https://program.europython.eu/media/avatars/reuven-headshot_eNVHHfd.jpg",
        "slug": "reuven-m-lerner"
      }
    ],
    "submission_type": "Talk",
    "slug": "what-happens-when-you-import-a-module",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "It's a rare program that doesn't include at least one \"import\" statement. But what actually happens when we import a module? How does Python find our file, decide whether to load it, and then keep track of it in memory? In this talk, I'll walk you through what happens when you \"import\" a module into Python, revealing the complexities of something seemingly simple that we use every day.",
    "description": "Modules are a key feature of Python, allowing us to easily reuse our own code and take advantage of publicly available modules from PyPI. It's a rare program that doesn't include at least one \"import\" statement. But what actually happens when we import a module? How does Python find our file? How does it decide whether it should even try to find our module? And after it finds our module file, how does Python load it into memory, assigning to its attributes?\r\n\r\nIn this talk, I'll walk you through what happens when you \"import\" a module into Python. The mechanism is surprisingly complex, in no small part because it has to take so many possibilities into consideration. We'll talk about finders and loaders, and about the many ways in which you can customize the module-loading mechanism if you find a need to do so.\r\n\r\nIf you've ever imported a module, then this talk will pull back the curtain a bit, helping you to understand what's happening under the hood.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "TE7K7D",
    "title": "Clean Architectures in Python",
    "speakers": [
      {
        "code": "7BS3PU",
        "name": "Leonardo Giordani",
        "biography": "Born in 1977 together with Star Wars, bash, Apple ][, Dire Straits, The Silmarillion, and many other great things.\r\n\r\nI started coding in April 1987 on a Sinclair ZX Spectrum. I then moved to MS-DOS PCs and in 1996 I started using Linux and became interested in operating system internals. I love software architectures, algorithms, mathematics and cryptography.\r\n\r\nI’m mainly interested in open source software. I like both the theoretical and practical aspects of computer science.\r\n\r\nI am currently working as a contractor DevOps and Python developer while I design a DevOps bootcamp that I will run in London from June 2022.\r\n\r\nFrom 2013 I blog some technical thoughts at http://thedigitalcatonline.com.\r\n\r\nIn 2018 I published the free book “Clean Architectures in Python” http://bit.ly/getpycabook",
        "avatar": "https://program.europython.eu/media/avatars/Avatar400x400_cuVmtE6.jpg",
        "slug": "leonardo-giordani"
      }
    ],
    "submission_type": "Talk",
    "slug": "clean-architectures-in-python",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "A brief talk that introduces software developers to the idea of \"clean architecture\" and discusses how to reduce coupling between parts of a software system through well-known strategies such as abstraction and inversion of control.",
    "description": "Architectural considerations are often overlooked by developers or completely delegated to a framework. We should start once again discussing how applications are structured, how components are connected and how to lower coupling between different parts of a system, to avoid creating software that cannot easily be maintained or changed. The \"clean architecture\" model predates Robert Martin, who recently brought it back to the attention of the community, and is a way of structuring applications that leverages layers separation and internal APIs to achieve a very tidy, fully-tested, and loosely coupled system.\r\n\r\nThe talk introduces the main ideas of the architecture, showing how the layers can be implemented in Python, following the content of the book \"Clean Architectures in Python\" edited by Leanpub. The book recently reached 25,000 downloads and many readers found it useful to start learning how to test software and how to structure an application without relying entirely on the framework.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "GFGSGN",
    "title": "Leading & growing software teams",
    "speakers": [
      {
        "code": "GLMZDC",
        "name": "Radoslav Georgiev",
        "biography": "Generalist. A multi-disciplinary problem solver & a technical team lead.\r\n\r\nCurrently leading & growing teams at HackSoft.\r\n\r\nA programmer from ~10 years, studied Computer Science in the Faculty of Mathematics and Informatics, Sofia University.\r\n\r\nFounder and CEO of HackSoft (Sofia based software company with main focus in Python, Django and Scala) and HackBulgaria (Programming courses, based in Sofia / Bulgaria with main focus of getting the students ready for their first job - either as an intern or a junior developer. Mainly focused in Python and Java)\r\n\r\nAlso doing a lot of teaching - Functional Programming classes (Racket / Haskell) @Faculty of Mathematics and Informatics , Programming with Python and Django @HackBulgaria.\r\n\r\nGitHub - https://github.com/RadoRado/",
        "avatar": "https://program.europython.eu/media/avatars/Radoslav_HackSoft_team_AiYbuH9.jpg",
        "slug": "radoslav-georgiev"
      }
    ],
    "submission_type": "Talk",
    "slug": "leading-growing-software-teams",
    "track": "Career, Life,...",
    "state": "confirmed",
    "abstract": "Software development is a team game.\r\n\r\nAs you progress through your career, you might end up in a leadership role, taking care of  your own team, or even of multiple teams.\r\n\r\nAs a team lead, it’s up to you to establish a good working rhythm, set the right expectations, communicate up and down the chain of command and effectively help your team grow in both technical and non-technical terms.\r\n\r\nAs a team lead, you want to enable your team to reach its full potential.\r\n\r\nThe main goal of this talk is to provide pragmatic real-life examples, about how to achieve those things.",
    "description": "Software development is a team game.\r\n\r\nAs you progress through your career, you might end up in a leadership role, taking care of  your own team, or even of multiple teams.\r\n\r\nAs a team lead, it’s up to you to establish a good working rhythm, set the right expectations, communicate up and down the chain of command and effectively help your team grow in both technical and non-technical terms.\r\n\r\nAs a team lead, you want to enable your team to reach its full potential.\r\n\r\nThe main goal of this talk is to provide pragmatic real-life examples, about how to achieve those things.\r\n\r\nWe are going to cover the following topics:\r\n\r\n1. What’s the role of a team lead?\r\n2. Managing expectations & responsibilities.\r\n3. Establishing a good work rhythm.\r\n4. Establishing a good form of communication.\r\n5. What does team growth look like?\r\n\r\nThis talk is the natural sequel of the following talks from previous EuroPythons:\r\n \r\n- EuroPython 2017 - Practical Debugging - Tips, Tricks and Ways to think - https://www.youtube.com/watch?v=9Ys4gCUtTh8\r\n- EuroPython 2018 - Django structure for scale and longevity - https://www.youtube.com/watch?v=yG3ZdxBb1oo\r\n- EuroPython 2019 - Software patterns for productive teams - https://www.youtube.com/watch?v=fEy68VRmOeQ",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "LCNBCC",
    "title": "Debugging asynchronous programs in Python",
    "speakers": [
      {
        "code": "E9QEAS",
        "name": "Andrii Soldatenko",
        "biography": "Hi there! I’m Pythonista from Ukraine, I'm working remotely as a Senior Software Engineer at Astronomer. Also I'm a speaker at many PyCons and meetups around the globe. In my free time I’m crossFit and gymnastic amateur.",
        "avatar": null,
        "slug": "andrii-soldatenko"
      }
    ],
    "submission_type": "Talk",
    "slug": "debugging-asynchronous-programs-in-python",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Recently the interest in asynchronous programming has grown dramatically.\r\n Unfortunately, asynchronous programs do not always have reproducible behavior. Even when they are run with the same inputs, their results can be radically different.\r\n\tIn this talk I'll show you different approaches on how to debug asynchronous programs in Python.",
    "description": "Luckily, when it comes to debugging asynchronous applications in python, we have a couple of options to consider. The writers of the asyncio module have very kindly provided a debug mode, which is quite powerful and can really aid us in our debugging adventures without the overhead of modifying the system's code base too dramatically. In particular I'll show you what asyncio debug mode means for developers, and how to source tracebacks for unhandled exceptions in futures. Also how to detect accidental blocking for I/O. We discuss how to monitor the asyncio event loop and collect metrics in statsD.\r\nFinally we discuss monitor and cli capabilities for asyncio applications based on aiomonitor and aioconsole. Also we discuss how asynchronous python works in REPL via autoawait based on ipython and how to do it in vanilla python REPL.",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "some"
  },
  {
    "code": "BZL7YY",
    "title": "How a popular MMORPG made me a better developer",
    "speakers": [
      {
        "code": "3CVRJD",
        "name": "Valerie Shoskes",
        "biography": "A lifelong gamer, cat mom, and abstract thinker who discovered software development by writing scripts with python in her college years and never looked back. She lives in Cleveland, Ohio, with her friends and three cats. She brings her perspective of neurodivergence in coding with her six years of professional development.",
        "avatar": "https://program.europython.eu/media/avatars/60753290_234917830798883_1901400361449553920_n_wNXvY1e.jpg",
        "slug": "valerie-shoskes"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-a-popular-mmorpg-made-me-a-better-developer",
    "track": "Community & Diversity",
    "state": "confirmed",
    "abstract": "Have you heard of the critically acclaimed MMORPG Final Fantasy XIV?\r\n\r\nAs an active player since 2015, I've used my \"problem-solving programmer brain\" to analyze my experiences in the world of Eorzea and apply them into important software lessons. From finding solutions to a housing crisis, to tracking cheaters, to networking with the president of Square Enix and applying the principles of (Y)MINASWAN, there's a lot to be learned through triumphs and failures as an MMO gamer. I will also talk about my experiences in the software community as a neurodivergent developer, and how gaming helped me break down barriers.",
    "description": "This talk will have special meaning for Final Fantasy fans, but anyone with nerdy non-coding hobbies should be able to enjoy it. The intended outcome is for attendees to see their own hobbies in a new light, where they can find their own abstract lessons.\r\n\r\nMMO gaming is becoming a more mainstream hobby, and as a lifelong gamer, I have plenty of experiences and stories to share on how the genre helped my transformation from a shy bundle of nerves to a confident professional. I also have experience applying my problem solving skills from software development into solutions for the community to combat problems that arose within the game.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "8SJSVS",
    "title": "The Design of Everyday APIs",
    "speakers": [
      {
        "code": "K7PLZQ",
        "name": "Lynn Root",
        "biography": "Lynn Root is a Staff Engineer at Spotify and resident FOSS evangelist. She is a seasoned speaker on building and maintaining distributed systems, and maintains Spotify’s audio processing framework. Lynn is a global leader of diversity in the Python community, the Chair of the PyLadies global council, and the former Vice Chair of the Python Software Foundation Board of Directors.",
        "avatar": "https://program.europython.eu/media/avatars/lynn_root_spb_sq_FiY8tmR.jpg",
        "slug": "lynn-root"
      }
    ],
    "submission_type": "Talk",
    "slug": "the-design-of-everyday-apis",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "What makes a good API for a library? Or more importantly, what makes it bad? This talk will discuss the principles of what goes into user-centered design, and how best to apply those principles when writing a Python library for fellow developers.",
    "description": "What makes a good API for a library? Or more importantly, what makes it bad?\r\n\r\nImplementing an API is an art. It’s the connection between the user and the library itself. How can we optimize that connection to make the experience more pleasing? What makes a user reach for one library over another? What goes into an ergonomic API?\r\n\r\nThis talk will first discuss what makes an API good: documentation, simplicity, consistency, completeness, and flexibility. We will apply those elements by looking at examples in the wild of good and poorly designed APIs. And we’ll discuss what to leverage and how to avoid pitfalls of bad design within Python (when [not] to use metaclasses, subclassing versus composition, decorators, etc).",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "CJYTER",
    "title": "Making Python better one error message at a time",
    "speakers": [
      {
        "code": "NLHSWB",
        "name": "Pablo Galindo Salgado",
        "biography": "Pablo Galindo Salgado works in the Python Infrastructure team at the Software Infrastructure department at Bloomberg L.P. He is a CPython core developer and a Theoretical Physicist specializing in general relativity and black hole physics. He is currently serving on the Python Steering Council and he is the release manager for Python 3.10 and 3.11. He has also a cat but he does not code.",
        "avatar": "https://program.europython.eu/media/avatars/9AwOpo3r_400x400_1_UTovywe.jpg",
        "slug": "pablo-galindo-salgado"
      }
    ],
    "submission_type": "Talk",
    "slug": "making-python-better-one-error-message-at-a-time",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "Error reporting has been an area that sadly has not improved a lot recently in the Python interpreter and users have been battling with very obscure runtime errors and puzzling syntax error messages that range from very generic (just “syntax error: invalid syntax”) to directly misleading (the error displayed for unclosed parentheses). This situation has frustrated users for a long time and has forced everyone into learning “what the interpreter really wants to say” or “where the error really could be”. This problem is especially acquitted for first-time learners of the language as they can lose a lot of time trying to decipher what the error messages they just got mean and where the problem may be.",
    "description": "Python 3.10 has been recently released and among many exciting new features, one of the biggest improvements is the inclusion of a whole new set of changes focused on improving the error messages across the interpreter and the general user experience when dealing with error messages. The new error messages have been one of the most welcomed features from very different sets of users ranging from Python teachers and educators, first-time learners, industry professionals and data scientists.\r\n\r\nIn this talk, we will cover:\r\n\r\n* What are the new improvements featured in Python 3.10.\r\n* Exciting new changes and improvements that will feature in Python 3.11.\r\n* How these improvements are useful to different sets of users from people learning Python to experienced programmers.\r\n* How the new PEG parser has unlocked adding new custom syntax errors.\r\n* How these improvements were implemented and what challenges the CPython core team faced to get them working reliably.\r\n* How users can contribute to adding new error messages: what is the workflow, how the errors are reviewed by the core team and where to find resources and help.\r\n\r\nNo matter who you are and what you do with Python, there is an improvement that will probably make you smile.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "3XNT9R",
    "title": "LocalStack: Turbocharging dev loops and team collaboration for cloud applications",
    "speakers": [
      {
        "code": "DP8DBG",
        "name": "Waldemar Hummer",
        "biography": "Waldemar is co-founder and CTO of LocalStack, where he and his team are building the world-leading platform for local cloud development, based on the hugely popular open source framework with 39k+ stars on Github. Prior to founding LocalStack, Waldemar has held several engineering and management roles at startups as well as large international companies, including Atlassian (Sydney), IBM (New York), and more recently as Head of Engineering at Zurich Insurance. Waldemar is originally from Austria and holds a PhD in Computer Science from TU Vienna, where his research focused on software engineering and reliability in large-scale distributed systems.",
        "avatar": "https://program.europython.eu/media/avatars/profile_head_3P9wr6I.png",
        "slug": "waldemar-hummer"
      }
    ],
    "submission_type": "Talk",
    "slug": "localstack-turbocharging-dev-loops-and-team-collaboration-for-cloud-applications",
    "track": "Infrastructure: Cloud & Hardware",
    "state": "confirmed",
    "abstract": "With the staggering dominance of public cloud providers, dev teams across the globe are increasingly focusing time and energy on optimizing their cloud development and deployment flows. The traditional deploy-and-test cycles against public clouds can become slow and tedious, where developers are often facing several minutes of idle times between deployments that need to be frequently triggered during testing & debugging.\r\n\r\nIn this session, we provide a hands-on introduction to LocalStack (39k+ Github stars), a fully functional local AWS cloud stack. With LocalStack, applications can be developed entirely on your local machine, reducing dev&test cycles from minutes to seconds.\r\n\r\nThe session covers interactive live coding to showcase common scenarios and use cases, different settings for local debugging of Lambdas and containerized apps (e.g., ECS/EKS), as well as some advanced new features that can radically improve productivity and team collaboration patterns.\r\nWe will also glance over the large ecosystem of tools that LocalStack natively integrates with - from IaC frameworks like Terraform or Pulumi, to application frameworks like Serverless or Architect, to a whole suite of tools provided by AWS itself (CDK, SAM, Copilot, Chalice, etc).\r\n\r\nWe'll wrap up the session with a deep dive into some of the Python internals of LocalStack, which reveals some interesting architectural patterns and hidden gems!",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "expert"
  },
  {
    "code": "DVDJWP",
    "title": "Build a production ready GraphQL API using Python",
    "speakers": [
      {
        "code": "CWD3DM",
        "name": "Patrick Arminio",
        "biography": "¡Hello there! I'm Patrick, a Swiss-Italian living in London.\r\n\r\nI'm currently mainly working on Strawberry 🍓, a modern Python library for GraphQL. I'm a huge fan of GraphQL and also a Python user for more than 10 years now, so I'm super excited to contribute to the GraphQL ecosystem in Python.\r\n\r\nI'm also the Chair of Python Italia, the association that organises events around Python in Italy, I'm currently working on the new website for the conference with some friends.",
        "avatar": "https://program.europython.eu/media/avatars/667029.jpeg",
        "slug": "patrick-arminio"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "build-a-production-ready-graphql-api-using-python",
    "track": "Web",
    "state": "confirmed",
    "abstract": "This workshop will teach you how to create a production ready GraphQL API using Python and Strawberry. We will be using using Django as our framework of choice, but most of the concept will be applicable to other frameworks too.\r\n\r\nWe'll learn how GraphQL works under the hood, and how we can leverage type hints to create end to end type safe GraphQL queries.\r\n\r\nWe'll also learn how to authenticate users when using GraphQL and how to make sure our APIs are performant.\r\n\r\nIf we have enough time we'll take a look at doing realtime APIs using GraphQL subscriptions and how to use GraphQL with frontend frameworks such as React.",
    "description": "Agenda of the worshop\r\n\r\n- Workshop introduction\r\n\t- The introduction will explain the goal of the workshop and make sure everyone is ready to start\r\n- Intro to type hints\r\n\t- Before looking at what GraphQL is, we'll do a short introduction on type hints in Python, since we'll be using the a lot during the workshop.\r\n- Introduction to GraphQL\r\n\t- Here we'll be looking at what GraphQL is, how it works and why it has been created\r\n- Our first GraphQL API\r\n\t- Here we'll get our hands dirty by creating our first GraphQL API using Strawberry. We'll also take time to see how to configure Strawberry with Django.\r\n- Let's test our API\r\n\t- I'm a big fan of TDD, so before continuing with our workshop we'll quickly see how to test our GraphQL API using pytest.\r\n- Schema design\r\n\t- In this section we'll spend time taking a look at how to design a GraphQL schema. We'll also understand the difference between queries and mutations.\r\n- Authentication\r\n\t- In this section we'll implement authentication to our GraphQL API. We'll discuss session based auth vs JWT authentication.\r\n- Performance / Monitoring / Observability\r\n\t- In this section we'll discuss how we can add observability/monitoring to our APIs and make sure we can keep our API performant over time.\r\n\t- We'll also see how we can use dataloaders to make our queries efficient. We'll also talk about other potential performance improvements (SQL optimisation, Static Queries and more)\r\n- **Bonus**\r\n\t- Integration with React\r\n\t\t- In this section we'll see how we can use GraphQL with a frontend framework like React.\r\n\t- Subscriptions\r\n\t\t- In this section we'll see what subscriptions are in GraphQL and how you can leverage them to build realtime APIs.",
    "duration": "180",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "VUTSHW",
    "title": "Walk-through of Django internals",
    "speakers": [
      {
        "code": "RUX9LK",
        "name": "Hitul Mistry",
        "biography": "Hitul is the founder of Digiqt Technolabs. He helps companies in building Technology products, DevOps and Data Engineering. \r\n\r\nHe is experienced in the development of large-scale enterprise mission-critical and fault tolerance distributed applications in e-commerce, insurance, finance, and health care domains.",
        "avatar": "https://program.europython.eu/media/avatars/1563792480043_ppImby8.jpeg",
        "slug": "hitul-mistry"
      }
    ],
    "submission_type": "Talk",
    "slug": "walk-through-of-django-internals",
    "track": "Django",
    "state": "confirmed",
    "abstract": "⭐ The talk will cover the Django codebase internals and showcase various moving parts in the code.\r\n\r\n⭐ Talk will cover the internals of CGI, WSGI, working on runserver, views, Middleware, app loading, Django settings load, ORM, Django utilities, etc.",
    "description": "⭐ Talk will start with the introduction of how does end to end web request works internally in Django.\r\n\r\n⭐ The talk will introduce users to the internals of ORM, database backend, middleware, etc.\r\n\r\n⭐ The talk will also cover, all processes Django does internally to start a server.\r\n\r\n⭐ At the end of the talk attendees will be able to understand the internal code structure of Django, how does Django server start, how does Django serves the requests, etc.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "WWRGSS",
    "title": "Async Django",
    "speakers": [
      {
        "code": "7HPWPW",
        "name": "Ivaylo Donchev",
        "biography": "Currently working as Technical team lead in HackSoft in Bulgaria.\r\n\r\nA programmer for ~7 years, working with Python and DJango for 6 years.\r\n\r\nSpeaker at EuroPython 2018 and PyCon Balkan 2018.",
        "avatar": "https://program.europython.eu/media/avatars/personal_KPiB7nc.jpg",
        "slug": "ivaylo-donchev"
      }
    ],
    "submission_type": "Talk",
    "slug": "async-django",
    "track": "Django",
    "state": "confirmed",
    "abstract": "Python has a full set of tools for asynchronous programming - multiprocessing, multithreading, coroutines, etc. And Django uses most of them.\r\n\r\nSince Django 3, we have the ability to create fully async non-blocking Django views that could handle thousands of requests concurrently.\r\n\r\nIn this talk, we'll focus on 2 key topics:\r\n1. The motivation and the decisions behind the Django async support\r\n2. Choosing the right tools to make our views async and efficient",
    "description": "This talk will cover:\r\n\r\n1. What is the difference between asynchrony and concurrency?\r\n2. Python and Django tools for asynchronous programming.\r\n3. Examples of efficient and inefficient \"async\" Django views.\r\n4. How does Django handle requests asyncronously - the path from `NGINX` to the database\r\n5. How should we handle thread-blocking operations?\r\n6. A brief history and roadmap of Django's async support",
    "duration": "30",
    "python_level": "some",
    "domain_level": "expert"
  },
  {
    "code": "HJWZ37",
    "title": "How much time does it take to write tests? A case study",
    "speakers": [
      {
        "code": "QRKRQL",
        "name": "Antonis Christofides",
        "biography": "I've been writing software for more than 30 years. I’ve written software to streamline the management of hydro/meteorological measurements; to make time series visualization and processing easy; to provide irrigation advice; and much more. I have been working with automatic meteorological stations since 1992; I’ve occasionally written programs to interface directly with meteorological loggers; I’ve dug out dusty old handwritten weather observations and keyed them in myself; I have created various web sites and web-accessible databases; I’ve administrated servers, including email and network, and high-availability databases with automatic failover. I have written the book on Django deployment (https://djangodeployment.com).\r\n\r\nIn research, I’ve worked on water-related decision making when there are conflicting objectives; on evaluation of climate models; on causation and determinism in hydrology and the climate; and more. My opinion on climate change is that there is no evidence that it is man-made.\r\n\r\nI help scientists and engineers create software. In particular, I help them bring their models to the web.",
        "avatar": null,
        "slug": "antonis-christofides"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-much-time-does-it-take-to-write-tests-a-case-study",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "Writing automated tests takes time. As developers, we are constantly pressed by management to deliver early, which means we are tempted to skip writing some of the tests. Of course, in the long term, the time needed to write tests is paid off.\r\n\r\nBut how much of our time do we spend in order to write tests? Is it half? Is it three-quarters? This can be difficult to measure, particularly if we are using test-driven development, because in that case writing tests is integrated in the process of writing code.\r\n\r\nWhile I like test-driven development, I can only practice it when I have a good idea of what code I want to write. But sometimes my idea of how to approach the problem at hand is quite vague and I experiment a lot. In these cases, I write the code first and the tests after that. \r\n\r\nIn one such case I first finished the functionality I was developing and proclaimed it \"beta\". I then went on to write the unit tests for it. As a result, I have a clear idea how much time I spent writing documentation and main code, and how much I spent writing tests. In this talk I examine the implications of all this.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "WX9PBG",
    "title": "Writing Faster Python 3",
    "speakers": [
      {
        "code": "8D7B98",
        "name": "Sebastian Witowski",
        "biography": "Sebastian is a Python consultant and online course creator based in Poland. He started his journey with programming as a software developer at CERN, where he fell in love with Python (and teaching). Now he is helping companies untangle their complicated architecture and build all sorts of interesting Python projects.\r\n\r\nIn his spare time, he talks about Python, best practices in programming, and productivity.",
        "avatar": "https://program.europython.eu/media/avatars/2019-07-29_profesjonalny_fotograf_small_YUM1emC.jpg",
        "slug": "sebastian-witowski"
      }
    ],
    "submission_type": "Talk",
    "slug": "writing-faster-python-3",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Did you know that Python preallocates integers from -5 to 257? Reusing them 1000 times, instead of allocating memory for a bigger integer, can save you a couple milliseconds of code’s execution time. If you want to learn more about this kind of optimizations then, … well, probably this presentation is not for you :) Instead of going into such small details, I will talk about more “sane” ideas for writing faster code.\r\n\r\nAfter a brief overview of different levels of optimization and how they work in Python, I will show you simple and fast ways of measuring the execution time of your code and finally, discuss examples of how some code structures could be improved.\r\n\r\nYou will see:\r\n\r\n* The fastest way of removing duplicates from a list\r\n* How much faster your code is when you reuse the built-in functions instead of trying to reinvent the wheel\r\n* What is faster than the “for loop”\r\n* If the lookup is faster in a list or a set\r\n* When it’s better to beg for forgiveness than to ask for permission",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "9VWGLC",
    "title": "Simple data validation and setting management with Pydantic",
    "speakers": [
      {
        "code": "7UGD3J",
        "name": "Teddy Crepineau",
        "biography": "Teddy is a Data Platform Engineer at Stuart (a sustainable last-mile delivery company). He is currently working on data platform infrastructure and data pipelines (ingestion, transformation, and consumption). \r\n\r\nTeddy has been working in the data field for 5 years in Analytics, Business Intelligence, and Engineering teams. He loves contributing to open source projects in his downtime and studying software engineering and Python fundamentals.",
        "avatar": null,
        "slug": "teddy-crepineau"
      }
    ],
    "submission_type": "Talk",
    "slug": "simple-data-validation-and-setting-management-with-pydantic",
    "track": "PyData: Data Engineering",
    "state": "confirmed",
    "abstract": "When processing data, validating its structure and its type is critical. Bad record types or changes in structure can often result in processing errors or worst in wrong data output. Yet, solving this problem cleanly and efficiently can be challenging. It often results in complicated code logic and increases complexity; consequently decreasing code readability. Pydantic is an efficient and elegant answer to these challenges\r\n\r\nWe expect you'll leave this talk with a good understanding of:\r\n\r\n- Existing challenges in data validation\r\n- What Pydantic Models, Validators, and Convertors are\r\n- How to leverage Pydantic in your day to day (using real-life examples)\r\n- [Bonnus] How to use Code Generation to create Pydantic Models from any data sources",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "GRG9SC",
    "title": "Tales of Python Security",
    "speakers": [
      {
        "code": "PMWVSA",
        "name": "Steve Dower",
        "biography": "Steve is an engineer who tells people about Python and then gives them excuses to use it and great tools to use it with. He is a core developer and Windows expert for CPython, a member of the Python Security Response Team, and works at Microsoft as a roaming Python expert, making sure Python users are well supported across all their platforms.",
        "avatar": "https://program.europython.eu/media/avatars/Headshot_Python_2q9HWBk.jpg",
        "slug": "steve-dower"
      }
    ],
    "submission_type": "Talk",
    "slug": "tales-of-python-security",
    "track": "Security",
    "state": "confirmed",
    "abstract": "Security vulnerabilities receive huge publicity but also significant secrecy. In this session, we will walk through some of the biggest issues of the last few years from the perspective of a member of the Python Security Response Team. You'll learn how we work to protect all CPython users, how you can help, and how you can help protect yourself from malicious attackers.",
    "description": "In this session, you'll learn about recent security issues in CPython and the core parts of our ecosystem. You'll hear about the process by which they were filed, how they were reviewed, analysed, shared (when appropriate), resolved and ultimately disclosed to the public.\r\n\r\nAs well as real stories of security vulnerabilities, you'll learn how you can help by responsibly reporting potential issues, and how to protect yourself against common risks, as well as the best ways to find out about major issues and how to respond.",
    "duration": "30",
    "python_level": "none",
    "domain_level": "some"
  },
  {
    "code": "HWMZZG",
    "title": "Music and Code",
    "speakers": [
      {
        "code": "WADEN9",
        "name": "Nicholas H.Tollervey",
        "biography": "A recovering former member of the Python community.\r\n\r\nMusic, philosophy, teaching, writing & computing. Just like this bio: concise, honest and full of useful information. Everything I say is false...",
        "avatar": null,
        "slug": "nicholas-h-tollervey"
      }
    ],
    "submission_type": "Talk",
    "slug": "music-and-code",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "A playful exploration of the similarities and differences between music and code. What could coders learn from musicians, especially when it comes to learning, training and mentoring? (A personal perspective from someone who has been a professional musician, a professional teacher, and a professional coder.)",
    "description": "Learning to code requires a long term investment of time and effort to acquire a set of skills, theory, knowledge and experience in order to effectively make software. Learning to play an instrument requires a long term investment of time and effort to acquire a set of skills, theory, knowledge and experience in order to effectively make music.\r\n\r\nI will compare and contrast certain aspects of the worlds of code and music and will explore questions such as: what would music lessons look like if we taught music like we teach coding (and vice versa)? Who are the virtuoso coders we should celebrate as role models? (And why?) How do musicians and coders sustain AND develop their cultures across generations? Is coding an art? Is music a science? What could folks do to cultivate their practice of music and code? How can we tell if someone is an \"expert\", and should we trust their advice?\r\n\r\nMost of all, it'll be practical, fun and thoughtful.\r\n\r\nI hope to make a space for some interesting and stimulating ideas. Then we can all explore them together in the corridor track.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "7FNTEJ",
    "title": "Memory Problems, Did Collector Forgot to Clean the Garbage?",
    "speakers": [
      {
        "code": "3HJ87E",
        "name": "Pratibha Jagnere",
        "biography": "Pratibha is an enthusiast Pythoniasta, passionate for coding and books. Through her PyCon talks, she love to explore and share new things she learn in Python.",
        "avatar": "https://program.europython.eu/media/avatars/profile_image_vgEgAJs.png",
        "slug": "pratibha-jagnere"
      }
    ],
    "submission_type": "Talk",
    "slug": "memory-problems-did-collector-forgot-to-clean-the-garbage",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "Memory Problems are the worst nightmare of every developer whose code is serving large files in a production environment. If you ever faced issues of memory leaking in application or if frequent unexpected Out of Memory Exception is raising your anxiety levels, then this talk is for you. This talk aims to summarize the common Memory issues in Python. It is overwhelming to see them even when logic in code is properly optimized. However it is more scary that some of these errors are hard to find and harder to fix.",
    "description": "In recent years, we have seen many improvements in Python Garbage Collection but there are some instances when it doesn’t work as expected. This results in memory crunch for the application leading it to crash. Although there are multiple ways to overcome the memory challenges, sometimes it is difficult to find what we can improve in our code and infrastructure that can make them memory efficient. In such cases, it helps to have an understanding of what is going on behind the curtains at a low level where memory is being managed.\r\n\r\nThis presentation aims to give a quick overview of\r\n\r\n1. How CPython manages the Memory allocation\r\n2. Common memory errors we see in day to day production code and how we can improve them\r\n\r\nWe will share what we have learned so far and encourage you to try it with your own projects. We'll walk through a simple example, with screenshots and code wherever required.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "USWAD9",
    "title": "`typing.Protocol`: type hints as Guido intended",
    "speakers": [
      {
        "code": "AX8V78",
        "name": "Luciano Ramalho",
        "biography": "Luciano Ramalho is the author of Fluent Python, published in 9 languages. He is a Principal Consultant at Thoughtworks and a Fellow of the Python Software Foundation.",
        "avatar": "https://program.europython.eu/media/avatars/LucianoRamalho2016-500x.jpg",
        "slug": "luciano-ramalho"
      }
    ],
    "submission_type": "Talk",
    "slug": "typing-protocol-type-hints-as-guido-intended",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "If your type-hinted Python code is Java flavored, you're probably underusing `typing.Protocol`. Python is literally built on structural typing, a.k.a. duck typing. It's how `__special__` methods work. Type hints were introduced in Python 3.5 without support for duck typing, but it was added in Python 3.8 and we should all be using `typing.Protocol` to have our code statically checked **and** Pythonic.",
    "description": "Duck typing and static typing are not opposites. Go is a successful statically checked language with support for duck typing through interfaces that work like `typing.Protocol` does. A `Protocol` subclass defines an interface that past and future classes can implement without any coupling to the interface: they simply provide the required methods. That's statically checked duck typing: a powerful combination!\r\n\r\nIn this talk we'll get back to basics looking at how duck typing is used in Python since the beginning, how `__dunder__` methods leverage that idea to support what we recognize as **Pythonic** code. Then we'll see how `typing.Protocol` fills the gap in the original PEP 484—Type Hints, and finally lets us properly annotate code that leverages the flexibility and loose coupling of duck typing. Finally, we'll look at the experience of the Go community to learn what makes a good Protocol. Spoiler alert: your favorite Python ABC may not be the basis of a useful Protocol!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "QQJFSS",
    "title": "On the benefits of using workflows: insights from two software tools in the context of computational neuroscience",
    "speakers": [
      {
        "code": "YDZC9Z",
        "name": "Aurélien Jaquier",
        "biography": "Hi, my name is Aurélien Jaquier, from Switzerland, I am 27 and I currently work for the Blue Brain Project as a Scientific Software Developer. I have a Master of Science MSc in Physics from the EPFL (Ecole Polytechnique Fédérale de Lausanne), with a master thesis centered on dwarf galaxy simulation.\r\nI love sciences and coding, and have been blessed with a job where I can help fundamental brain research with my coding skills. I develop and maintain different software in the context of neuron cell simulation and electrophysiological parameter optimization, such as EModelRunner, BluePyOpt or eFel.\r\nFeel free to talk to me in english, french or japanese.",
        "avatar": "https://program.europython.eu/media/avatars/photo_DyCk2BJ.jpg",
        "slug": "aurelien-jaquier"
      }
    ],
    "submission_type": "Poster",
    "slug": "on-the-benefits-of-using-workflows-insights-from-two-software-tools-in-the-context-of-computational-neuroscience",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "The Blue Brain Project strives to simulate the whole mouse brain. The amount of data and code this implies is astoundingly high, and it requires the development of software tools that have both a strict and clear structure and that are resilient to errors that will manifest when developing complex code. Workflows are a straightforward way to maintain structure in toolchains that grow increasingly complex. Workflow management packages such as Luigi bring functionality to run different tasks in parallel, keep track of completed tasks and improve the reproducibility. This poster will present two Blue Brain Project software tools, the e-model-packages software and BluePyEModel, focusing on the creation and distribution of in-silico neuron cells. The e-model-packages software collects cells from an in-silico brain circuit and arranges them in individual ‘neuron packages’ to be distributed to the public through the Blue Brain online portals. The cells packages it creates are designed to be easily run with the open source EModelRunner package. The BluePyEModel software creates and optimizes in-silico neurons and is able to reproduce features from real neuronal experiment recordings. Under the hood, it uses the open source BluePyEfe and eFel packages to extract the electrophysiological features from experimental cells, and the open source BluePyOpt simulator to optimize and validate the parameters of the in-silico neurons.",
    "description": "",
    "duration": "60",
    "python_level": "",
    "domain_level": ""
  },
  {
    "code": "MZS3MM",
    "title": "EModelRunner: a Python package to run online available biological neuron model implementations",
    "speakers": [
      {
        "code": "HYZCUT",
        "name": "Anıl Tuncel",
        "biography": "I am a Software Engineer with working experience in multidisciplinary scientific fields such as simulation neuroscience and genomics.\r\n\r\nAt the Blue Brain Project, we are building biologically detailed digital reconstructions and simulations of the mouse brain. We are running supercomputer-based simulations for understanding the multi-level structure and function of the brain.\r\n\r\nBefore joining Blue Brain Project, I was employed by ETH Zurich to work on Roche Tumour Profiler Project. I designed data analysis pipelines and statistical methods to provide personalised treatments for cancer patients.\r\n\r\nI volunteer as a Contributing Member at the Python Software Foundation. My contributions relate to the creation or maintenance of open-source software available to the public at no charge.\r\n\r\nhttps://wiki.python.org/psf/AnilTuncel",
        "avatar": "https://program.europython.eu/media/avatars/Goldwyn_Shooting_ETH_KP_2019_0628_tT9k0YP.jpg",
        "slug": "anil-tuncel"
      }
    ],
    "submission_type": "Poster",
    "slug": "emodelrunner-a-python-package-to-run-online-available-biological-neuron-model-implementations",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "The Blue Brain Project hosts several online portals from which users can download single neuron model implementations. These contain the information necessary to simulate the electrical behavior of a neuron. EModelRunner is a Python library that provides a unified interface to the users to run these downloaded models. It gives the users the ability to customize the properties of the neurons, apply various stimuli in order to observe the corresponding behavior, or activate the synapses that are present on the morphology of the neuron. This way neuroscientists can investigate the neurons in a self-contained environment and conduct digital experiments on them.",
    "description": "The brain is undoubtedly the most complex organ in the human body. Over the decades, scientists have been using theoretical and experimental approaches to understand the brain. With the recent advancement of computer systems and the availability of big data, a new discipline, namely simulation neuroscience, is emerged as a complementary approach alongside experimental, theoretical and clinical neuroscience. As the name suggests, simulation neuroscience attempts to understand the brain by simulating it in a computer.\r\nHere we present EModelRunner, a Python package designed to run the simulated neuron model implementations provided by the Blue Brain Project online portals. It is capable of simulating biologically detailed neuron models. A neuron model describes a single cell in the brain and consists of a morphology and equations that simulate its electrical behavior. EModelRunner uses the Neuron simulator under the hood. The Neuron simulator is implemented in C++, but also provides a Python interface to the user. For computing the properties of the membrane channels, Neuron uses compiled mechanisms written using the Neuron Model Description Language (NMODL). EModelRunner abstracts away the Neuron and NMODL implementation layers from the end-users and provides them with a pure Python API. It supplies the users with the ability to customize the properties of the neurons and apply various stimuli to them in order to observe their behavior. Another use-case for the EModelRunner is to provide a standard way of running the neuron models provided by the Blue Brain Project.",
    "duration": "60",
    "python_level": "",
    "domain_level": ""
  },
  {
    "code": "C9LDHB",
    "title": "Developers Documentation: your secret weapon",
    "speakers": [
      {
        "code": "7RBHLZ",
        "name": "Frédéric Harper",
        "biography": "As the Director of Developer Relations at Mindee, Frédéric Harper helps developers merge the physical and digital worlds using the magic of machine learning coupled with the ease of APIs. Fred has shared his passion for technology on the stage at dozens of events around the world. He’s helped build successful communities at npm, Mozilla, Microsoft, DigitalOcean, and Fitbit, and is the author of the book Personal Branding for Developers at Apress. Behind this extrovert is a very passionate individual who believes in the power of communication... and cat videos.",
        "avatar": "https://program.europython.eu/media/avatars/fred_z1RngGv.png",
        "slug": "frederic-harper"
      }
    ],
    "submission_type": "Talk",
    "slug": "developers-documentation-your-secret-weapon",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "You can have the best product in your expertise area, but if your documentation isn’t on par with the flawless experience you want to offer to the world, success is not guaranteed. Let’s be real here: documentation is often an afterthought and rarely included in life cycle development processes. Still, documentation is the secret weapon for greater adoption, and growth that you may have not known you could achieve.\r\n\r\nIt’s time for you to step up your game and measure up to the big players. Learn about the benefits of high quality and educational documentation and the true role it plays in the developer community. You’ll also learn the principles of a solid foundation, and tips on how to use one of the most powerful developer relations’ tools.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "JJQSXA",
    "title": "Let's talk about JWT",
    "speakers": [
      {
        "code": "JX8YLX",
        "name": "Jessica Temporal",
        "biography": "Jessica Temporal is Senior Developer Advocate at Okta for Auth0. [Pizza de Dados](http://pizzadedados.com/en/) co-founder and co-host, Pizza is the first and most beloved Brazilian podcast about data science. Jessica is also part of the instructors team in Data Bootcamp and LinkedIn Learning. She is part of PyLadies Brazil, the Brazilian network that promotes and empowers women in technology. Creator of [GitFichas](https://gitfichas.com/en), a git study cards collection available in English and Portuguse. She was born in warm weather and keeps herself warm in the cold Brazilian south with sweaters she knits herself.",
        "avatar": "https://program.europython.eu/media/avatars/profile-jt_kncvxT2.png",
        "slug": "jessica-temporal"
      }
    ],
    "submission_type": "Talk",
    "slug": "let-s-talk-about-jwt",
    "track": "Web",
    "state": "confirmed",
    "abstract": "JSON Web Tokens, or JWTs for short, are all over the web. They can be used to track bits of information about a user in a very compact way and can be used in APIs for authorization purposes. Join me and learn what JWTs are, what problems it solves, how you can use JWTs, and how to be safer when using JWTs on your applications.",
    "description": "JSON Web tokens dominated the way we give access to APIs and how we carry data from users, but to use JWTs safely we need to understand how they came to life and how JWTs can be useful.\r\nIn this talk we will take a closer look at the famous three-part structure that forms a JSON Web Token, and the claims each JWT can carry.\r\nBut knowing it’s history and structure is not enough, we need also to understand the algorithms used in creating a token and how you can use JWTs as access tokens or as ID tokens.\r\nAfter understanding JWTs on a deeper level, we will create and validate a JWT together using the PyJWT library and discuss things you should avoid doing to be safer when using JWTs in your projects.\r\n\r\n1. How did JWT come to life? Talk about the JOSE specification;\r\n2. What actually is a JSON Web Token and its structure: header, payload, and signature;\r\n3. What is a claim and its standardization efforts;\r\n4. The different types of algorithms that can be used to create JWTs and what is JWKs;\r\n5. Let's create a token together using PyJWT;\r\n6. What is an access token and an ID token;\r\n7. Things to avoid to be safer with JWTs",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "AKJCWL",
    "title": "Dance with shadows: stubs, patch and mock",
    "speakers": [
      {
        "code": "CLQCZS",
        "name": "María Andrea Vignau",
        "biography": "I gave many talks in spanish and two in english. I come from Argentina and gave five talks on PyCon Argentina, gave a talk in Europython https://youtu.be/s7110IaMEOs, a charla at PyCon Charlas 2019, and this year in PyCon España and other for Basis Technology on extending forensic software using python (https://youtu.be/ocuFZ8RA1p8). I was also organizer in 9 events in my city, Resistencia Chaco, collaborator in many others, including mentoring at PyCon Charlas 2022.",
        "avatar": "https://program.europython.eu/media/avatars/me_-_saco_btsKqZy.jpg",
        "slug": "maria-andrea-vignau"
      }
    ],
    "submission_type": "Talk",
    "slug": "dance-with-shadows-stubs-patch-and-mock",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "To ensure quality, automated testing is a must. But sometimes is impossible or very expensive to use real environments. In this case, you can isolate some parts of a system and use fake simulated objects.",
    "description": "A comprehensive but simple introduction to the use of fake objects. Explain how to inject this object and use in test using patch and the awesome and powerful mock objects . Last, I present some very interesting specialized libraries for mocking on web development.\r\n\r\nOutline\r\n\r\n0:00 I present the key factors to use fake objects, and present some dangers. \r\n\r\n3:00 Discuss some wanted characteristics in this kind of components. \r\n\r\n6:00 Patching: how to do that and some common mistakes. After that I present patch scopes and some disadvantage in the use of this technique. \r\n\r\n10:00 Inverse dependency as an possible alternative to patch \r\n\r\n13:00 Mocks properties: return value, side effect and specs. Using mocks as spy functions or wrappers. Asserting on callings. \r\n\r\n21:00 Using special libraries for mocking. Presenting pyvcr and moto.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "DZZ8X9",
    "title": "Classifying LEGO Bricks with Machine Learning",
    "speakers": [
      {
        "code": "8DK3QT",
        "name": "Piotr Rybak",
        "biography": "Piotr Rybak is a Machine Learning Researcher with experience in industry and academia. In his work, he mainly focuses on Natural Language Understanding but once in a while, he likes to dive into other topics. In his free time, he's a big fan of board games, Lego bricks, and boulder climbing.",
        "avatar": "https://program.europython.eu/media/avatars/photo_saoAk1U.jpg",
        "slug": "piotr-rybak"
      }
    ],
    "submission_type": "Talk",
    "slug": "classifying-lego-bricks-with-machine-learning",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "There are over 70 000 different Lego bricks and they appear in almost 200 different colors. Even the most hardcore AFOLs (Adult Fan of Lego) don’t know all of them. Let alone be able to recognize them. So I got curious whether it’s possible to create an application that can recognize the particular brick using only its photo.",
    "description": "During this talk, I will walk you through my journey to create the Lego bricks recognition application in Python. I will start with dataset creation and introduce some Lego-specific concepts and resources. Then, I will explain a few different Machine Learning approaches to solve Lego bricks recognition task – classification, detection, and metric learning. Finally, I will show what has worked, what hasn’t, and how you can play with it yourself.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "NVKPEJ",
    "title": "How to craft awesome Machine Learning demos with Python",
    "speakers": [
      {
        "code": "BGUJLS",
        "name": "Omar Sanseviero",
        "biography": "Omar Sanseviero is a Machine Learning Engineer working at Hugging Face in the Open Source team democratizing the usage of Machine Learning. Previously, Omar worked as a Software Engineer at Google in the teams of Assistant and TensorFlow Graphics. Omar is passionate about education and co-founded AI Learners, a Spanish-speaking community of people that want to learn about AI and its different applications.",
        "avatar": null,
        "slug": "omar-sanseviero"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-to-craft-awesome-machine-learning-demos-with-python",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "Building interactive Machine Learning demos is now easier than ever. With Open Source libraries such as Gradio and Streamlit, you can use Python to craft demos, and use Spaces to share them with the rest of the ML ecosystem as well as non-ML people.  Learning to create graphic interfaces for models is extremely useful for sharing with other people interesting in them. All of this leverages free, open-source tools that anyone can use.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "S78FW7",
    "title": "When Models Query Models",
    "speakers": [
      {
        "code": "SBZRSP",
        "name": "Michal Maciejewski",
        "biography": "Enthusiastic, hard-working software engineer with contagious energy and passion for working on interdisciplinary projects. Focused on delivering high-quality products in a timely manner. Servant leader always eager to learn from and with team members while instilling the ownership, autonomy, and sense of responsibility. \r\n\r\nOver ten years of experience as a software developer for modelling and analysis of complex systems.  Passionate about model-based system engineering solutions improving existing analysis workflows while ensuring reproducibility. Currently, the lead developer of an MLOps framework to support the design of superconducting accelerator magnets. Formerly, a technical lead for an agile team of experts and scientists creating signal monitoring framework for the Large Hadron Collider.",
        "avatar": null,
        "slug": "michal-maciejewski"
      }
    ],
    "submission_type": "Talk",
    "slug": "when-models-query-models",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "The design of large-scale engineering systems, including but not limited to aerospace, particle accelerators, nuclear power plants, is carried out by a wide range of numerical models such as CAD files, finite-element models, and machine learning surrogate models to name a few.  In order to provide a uniform modelling interface, we encapsulate numerical models in notebooks. A notebook is controlling model creation, execution, and query of results. Numerical solvers are embedded into Docker containers and provide an isolated and reproducible environment exposing a language-agnostic REST API. A model registry enables efficient queries of models. The overall system is represented as a collection of models that exchange data. Then, the design optimization involves execution of a dependency tree of models to study the impact of a parameter change and perform its optimization. In this contribution, we present a model query mechanism allowing notebook models to query one another. The model dependencies are represented with a graph with suitable processing algorithms. In order to ensure that only affected models are executed we derive and cache a model resolution order. The presented modelling framework relies on open source-technologies (packages: pydantic, Fast API, Jupyter, papermill, scrapbook, containers: Docker and Openshift as well as databases: MongoDB and Redis) and the talk will focus on good practices and design decisions encountered in the process.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "GAVCZ8",
    "title": "Try Something Different: Explore MicroPython! (a rough guide for newcomers)",
    "speakers": [
      {
        "code": "HYCU7H",
        "name": "Andy Piper",
        "biography": "Developer Advocate. API tinkerer. Friendly DEV.to moderator & community helper. IoT hacker (Eclipse IoT / MQTT). Perpetual student. LEGO fan. Prefer they/them pronouns.",
        "avatar": null,
        "slug": "andy-piper"
      }
    ],
    "submission_type": "Talk",
    "slug": "try-something-different-explore-micropython-a-rough-guide-for-newcomers",
    "track": "Makers",
    "state": "confirmed",
    "abstract": "MicroPython - a reimplementation of Python for microcontrollers - is nine years old. How can you find your way in a jungle of tiny chips, circuits, and jumper wires? In this session, we will run through a brief introduction to the world of MicroPython. Beyond the basics, we will explore the projects, tools, and the  community that helped your intrepid speaker to get started as a newcomer.",
    "description": "MicroPython is a reimplementation of Python for microcontrollers, originally developed as a result of a Kickstarter campaign. Today, it is an approachable way into programming for many young people, via boards like the Raspberry Pi Pico, the BBC micro:bit and the CodeBug - you can even run it on LEGO bricks! It is increasingly being used in commercial fields as well. MicroPython is helping Python to get into even more places, and making programmers more efficient as it does so.\r\n\r\nAndy Piper wanted to learn more, so he spent some time travelling and adventuring on the internet, to discover the community and projects around MicroPython.\r\n\r\nThe goal of this session is to briefly explain the What, Why and How of MicroPython. There *will* be circuit boards, and discussion of microcontrollers! We will take a look at examples, from established development boards to brand new ones. We will also acknowledge how MicroPython has been built upon, to enable different ways of working (with CircuitPython), and LEGO robots (via PyBricks). \r\n\r\nFinally, and most importantly, you'll get a good sense of the places you can find and learn from the MicroPython community, and how you can get involved and contribute!",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "83QRQG",
    "title": "An Introduction to Apache TVM",
    "speakers": [
      {
        "code": "8ZHWHC",
        "name": "Leandro Nunes",
        "biography": "I'm a software engineer, currently working on compilation tools for machine learning workloads and contributing to the Apache TVM Compiler Stack as a PMC member and committer. In the academic background, I hold a M.S. degree in Microelectronics and a B.S. degree in Computer Science.",
        "avatar": null,
        "slug": "leandro-nunes"
      }
    ],
    "submission_type": "Talk",
    "slug": "an-introduction-to-apache-tvm",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "Apache TVM is an open source machine learning compiler framework for CPUs, GPUs, and machine learning accelerators. It aims to enable machine learning engineers to optimize and run computations efficiently on any hardware backend.\r\n\r\nThis talk will present an introduction to Apache TVM using its Python API, and demonstrated using examples of deep learning models being execute in CPUs and Microcontrollers.",
    "description": "This talk will present an introduction to Apache TVM using its Python API, and will include a demonstration using examples of deep learning models being executed in CPUs and Microcontrollers.\r\nApache TVM is a very flexible compilation stack for deep learning models, supporting many input formats such as TensorFlow, TFLite, Keras, PyTorch, ONNX, etc. as well as many target hardware like CPUs, GPUs and neural networks accelerators.\r\n\r\nThis talk will present a walkthrough of TVM Python API from installation to usage, demonstrating its features using a series of quick practical projects.\r\n\r\nThe high-level agenda is:\r\n\r\n- TVM in a nutshell (a brief description of what is TVM)\r\n- How to install\r\n- Introduction to TVM Python API\r\n- Practical demos: Compiling and tuning a model\r\n- Compiling and running a model on an embedded target\r\n- Final Remarks",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "ENL98A",
    "title": "An introduction to HTTPX",
    "speakers": [
      {
        "code": "P9XQDF",
        "name": "Tom Christie",
        "biography": "Tom is aht author of a number of widely used open source packages, and works on open source full time, through his collaboratively funded business, Encode OSS Ltd.",
        "avatar": null,
        "slug": "tom-christie"
      }
    ],
    "submission_type": "Talk",
    "slug": "an-introduction-to-httpx",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "An introduction to a fully featured HTTP client and command-line tool for Python.\r\n\r\nHTTPX is the result of a huge amount of dedicated design time to build a new HTTP client for Python from the ground up. It provides both HTTP/1.1 and HTTP/2, as well as supporting either sync or async styles of concurrency.\r\n\r\nThis talk will provide an introduction to the motivation behind the package, and an overview of the design.",
    "description": "HTTPX is a new HTTP client library for Python, built around the well-established API\r\ndesign of \"requests\", while adding several new features.\r\n\r\nIt is the result of a huge amount of design work, having being backed by a collaboratively\r\nfunded approach.\r\n\r\nThe talk will discuss the motivations behind building an entirely new HTTP client for Python.\r\nIt will also provide an overview of the design layering, to help give the audience an understanding of the architecture underpinning the package.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "BVRBYQ",
    "title": "Predicting urban heat islands in Calgary",
    "speakers": [
      {
        "code": "7CNVPN",
        "name": "Anand S",
        "biography": "Anand is a co-founder of Gramener, a data science company. He leads a team that automates insights from data and narrates these as visual data stories. He is recognized as one of India's top 10 data scientists, and is a regular TEDx speaker.\r\n\r\nAnand is a gold medalist at IIM Bangalore and an alumnus of IIT Madras, London Business School, IBM, Infosys, Lehman Brothers, and BCG.\r\n\r\nMore importantly, he has hand-transcribed every Calvin & Hobbes strip ever and dreams of watching every film on the IMDb Top 250.\r\n\r\nHe blogs at https://s-anand.net. His talks are at https://bit.ly/anandtalks",
        "avatar": "https://program.europython.eu/media/avatars/Anand-Lift-Conference_qQFm1CL.jpg",
        "slug": "anand-s"
      }
    ],
    "submission_type": "Talk",
    "slug": "predicting-urban-heat-islands-in-calgary",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "confirmed",
    "abstract": "This talk explains how geospatial Python libraries can help us understand and predict Land Surface Temperature in urban areas using historical openly available satellite images and urban morphological data. This makes data science a powerful tool to plan and design urban areas while reducing the impact of urban warming.",
    "description": "Dealing with extreme heatwaves can be challenging, it has become the necessity to understand the land surface temperature (LST) change and its driving factors to reduce the impact and achieve more sustainable planning methods for city growth.\r\n\r\nThis module will help you understand how to calculate LST from the openly available satellite imageries and merge it with urban morphological factors (like building height, building count, FSI, building block coverage, etc.) to predict the temperature trend and mitigate the impact.\r\n\r\nWe will demonstrate an end-to-end methodology using geospatial Python libraries to understand the use of spatial regression methods taking into account the variation over time. This talk will also throw light upon:\r\n\r\n- Getting the large imagery datasets into DL friendly format\r\n- Spatial aggregation of different variables\r\n- Understanding correlation between variables for feature engineering\r\n- Application & comparison of different regression methods on the same data\r\n- Future scope\r\n\r\nWe'll also showcase the geo-visualization portal we created and the technologies used, how you can use Python to convert large GeoJSON output to light vector tiles, and create a seamless experience for the user through an intuitive front-end.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "PAXMHN",
    "title": "Native Packaging of GUI Apps on Windows and macOS",
    "speakers": [
      {
        "code": "SS7TTG",
        "name": "Tiago Montes",
        "biography": "Freelance Consultant and Trainer with lots of experience on back-end development and architecture, relational and spatial databases, networks, infrastructure, automation, and more.\r\n\r\nMember of the Mu Editor development team.\r\n\r\nWhat matters is learning, having fun, and being and making others happy! :-)",
        "avatar": "https://program.europython.eu/media/avatars/tiago.montes_cgAAO1f.png",
        "slug": "tiago-montes"
      }
    ],
    "submission_type": "Talk",
    "slug": "native-packaging-of-gui-apps-on-windows-and-macos",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "Distributing Python GUI applications to end users is a challenge: will they need to install Python? If so, which version? If not, how do they install the application? From a random ZIP file? How native does the process feel? Will their system trust your code? For a fluid experience, it needs to be signed and (on macOS) notarized beforehand.\r\n\r\nWelcome to [`pup`](https://pypi.org/project/pup/), the tool that the [Mu Editor](https://codewith.mu/) development team has created to package and distribute it in platform-native formats to Windows and macOS users around the world.\r\n\r\nIn this session I will show how `pup` can be used to package GUI Applications for distribution: natively on Windows and macOS, and in early stages of development for distribution-agnostic Linux artifacts. In short, if it's `pip`-installable it is `pup`-packageable!\r\n\r\nI will then describe the way `pup` works (and how it differs from comparable tools) leading on to a call-for-action moment, where I'll share its current state of development, what's good, what's bad, and where I'd like it to be headed to.\r\n\r\nI'll wrap up the talk with a set of future-looking thoughts that `pup` has helped identify not only on the specifics of CPython's distribution, but also on the Python ecosystem as whole.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "SHXRMJ",
    "title": "How I wrote a Python client for HTTP/3 proxies",
    "speakers": [
      {
        "code": "CNVAFW",
        "name": "Miloslav Pojman",
        "biography": "I build data pipelines for change safety and performance monitoring in Akamai. Our Protocol optimization team implements and deploys standards for the future Internet.\r\n\r\nPreviously, I worked for Seznam.cz, where I moved from complex business applications to big data processing.\r\n\r\nI have a software engineering degree from Czech technical university in Prague, but I started to write webs a long time before studying it.",
        "avatar": "https://program.europython.eu/media/avatars/Miloslav_Pojman_Qfkhusm.jpg",
        "slug": "miloslav-pojman"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-i-wrote-a-python-client-for-http-3-proxies",
    "track": "Web",
    "state": "confirmed",
    "abstract": "[MASQUE](https://tools.ietf.org/id/draft-schinazi-masque-01.html) (Multiplexed Application Substrate over QUIC Encryption) is a draft of a new protocol that allows running proxy or VPN services indistinguishable from HTTPS servers. Akamai built a managed proxy service based on the MASQUE protocol [to provide egress proxy](https://www.akamai.com/blog/cloud/powering-and-protecting-online-privacy-icloud-private-relay) for iCloud Private Relay.\r\n \r\nWhile working on the proxy at Akamai, I wrote a Python client for testing the proxy service. The MASQUE protocol can tunnel traffic through HTTP/3 or HTTP/2, but common Python libraries only support HTTP/1.1. The tunneled traffic can use any protocol on top of TCP or UDP, including all HTTP versions, so MASQUE can be proxied through MASQUE for onion routing.\r\n\r\nIn this talk, I will show that the MASQUE proxy design is simple and yet client implementations are complex. To put everything into context, I will recap how HTTP proxies operate and how HTTP versions differ. I will highlight lessons learned from designing a low-level HTTP client using Python asyncio.",
    "description": "",
    "duration": "30",
    "python_level": "none",
    "domain_level": "some"
  },
  {
    "code": "SE83WQ",
    "title": "Lint All the Things!",
    "speakers": [
      {
        "code": "GLYM3N",
        "name": "Luke Lee",
        "biography": "I've been developing software professionally for almost 20 years. During that time, I've written device drivers for SSDs, desktop GUIs, and web applications. Now I'm working for Octopus Energy trying to save the world from Climate Change. In addition to writing software, I enjoy writing, teaching yoga, cycling, and chasing my Corgi.",
        "avatar": "https://program.europython.eu/media/avatars/IMG_8325_45G8ZsD.jpg",
        "slug": "luke-lee"
      }
    ],
    "submission_type": "Talk",
    "slug": "lint-all-the-things",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Code that’s uniform is easier to read, write, and debug, but writing down your standards and conventions in a README that no one reads isn’t enough. The explosion of CI and linter tools allow you to no only document your standards and conventions, but make sure people actually adhere to them.",
    "description": "Many teams document the conventions for their projects. However, documentation gets out of date, forgotten, or sometimes ignored. Simple documentation requires team members to constantly remember all the ‘rules’ for your project. You can better enforce those rules and free up your team members to think about harder problems using linting tools like flake8, import linter, and pre-commit.\r\n\r\nThese tools provide tons of useful stuff out of the box, but you can push them so much further with customization. This allows your project to formally document conventions, but also enforce them automatically on every commit, merge, and build. This can make code reviews faster and more focused on the problems your code is meant to solve.\r\n\r\nThis talk will introduce tools like flake8, import linter, and pre-commit along with some of their built-in functionality. Then, we’ll briefly explore some ways to customize them to fit your projects’ specific needs. Some examples of custom linter rules we’ll tour are:\r\n\r\n- Code formatted automatically and uniformly\r\n- Code doesn’t import across architecture layers violating separation of concerns\r\n- Common conventions are used\r\n- Common anti-patterns are avoided\r\n- Specific layers are fully tested\r\n- Proper git commit message formatting\r\n- Merge commits don’t exist in topic/feature branches\r\n\r\nFinally, we’ll discuss ways to use those custom linter rules on every commit, merge, and build with continuous integration or git hooks.\r\n\r\nBy the end of the talk, you’ll see several real-world linter rules used on Kraken, which is a large Django-based project used to supply green energy to millions of users across the world. In addition, expect no shortage of ideas for your own projects along the way!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "E7CX9K",
    "title": "CPython bugs & risky features",
    "speakers": [
      {
        "code": "KL7QNZ",
        "name": "disconnect3d",
        "biography": "Disconnect3d is a security engineer at Trail of Bits where he hunt for security bugs in different kinds of software using both manual code analysis and various tools like static analyzers, fuzzers and others. He specializes in low level aspects and likes to understand how things works under the hood. On his free time, Disconnect3d plays CTF security competitions with justCatTheFish team and plays DoTA2 moba game.",
        "avatar": "https://program.europython.eu/media/avatars/cropped_5gRT9IF.jpg",
        "slug": "disconnect3d"
      }
    ],
    "submission_type": "Talk",
    "slug": "cpython-bugs-risky-features",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "In this talk we will look into a few bug cases or doubtful features in CPython some of which are still present (and known to bugs.python.org) and may impose a security risk for admins or organizations.",
    "description": "In this talk we will look into a few bug cases or doubtful features in CPython some of which are still present (and known to bugs.python.org) and may impose a security risk for admins or organizations.\r\n\r\nWe will learn why running Python interpreter in random directory can be harmful which is related to interpreter libs loading, a possibility for installed modules to inject code into any Python script execution (even if the installed library is not imported), a socket.inet_aton issue that actually comes from glibc and risks involved with those cases and possible mitigations of those risks.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "JWUZ7E",
    "title": "Common Python Mistakes with Kubernetes, How They Can Cause Vulnerabilities and How to Solve Them!",
    "speakers": [
      {
        "code": "P3VFZX",
        "name": "Christopher Van Der Made",
        "biography": "After 5 years of being a Consulting Systems Engineer Security for Cisco customers for the Dutch market, Christopher Van Der Made is now Developer Advocate, focusing on Security within Cisco DevNet. Within this role he serves as a technical evangelist and is the \"voice of the developer\" within Cisco, actively engaging internally and externally to build a community of developers and engineers. From Rotterdam, Netherlands, of Dutch and American nationality. Christopher studied at the University of Amsterdam, majoring in Neuroscience with a Computer Science minor. He achieved his Masters in Information Sciences, and joined Cisco through the Graduate program.",
        "avatar": null,
        "slug": "christopher-van-der-made"
      }
    ],
    "submission_type": "Talk",
    "slug": "common-python-mistakes-with-kubernetes-how-they-can-cause-vulnerabilities-and-how-to-solve-them",
    "track": "~None of the above",
    "state": "accepted",
    "abstract": "In this session, we will have a look at common mistakes in Python, that can cause serious code vulnerabilities, specifically for Kubernetes deployments of the code. We will subsequently have a look at what those vulnerabilities actually can result in and how your containerized application can get “hacked” as a result. We will also discuss how developer and security teams struggle to talk in a common language to prevent and mitigate these vulnerabilities. Lastly, we will see how you can prevent and mitigate these vulnerabilities in real-life.",
    "description": "In this session, we will have a look at common mistakes in Python, that can cause serious code vulnerabilities, specifically for Kubernetes deployments of the code. We will subsequently have a look at what those vulnerabilities actually can result in and how your containerized application can get \"compromised\" as a result. We will also discuss how developer and security teams struggle to talk in a common language to prevent and mitigate these vulnerabilities. Lastly, we will see how you can prevent and mitigate these vulnerabilities in real-life using tools like Falco, TUF, Open Policy Agent and Bandit. We will also see how a CI/CD pipeline should look like, to build, test and deploy something in real-life. During this session you will learn a ton, see cool demos and all of the samples will be available to the attendees afterwards.\r\n\r\nMy session will benefit the ecosystem by pointing out common mistakes that can be made when writing Python code and deploying this via Kubernetes. This can cause serious breaches when exploited by attackers. The goal of the session is to both educate attendees on these vulnerabilities, as well as on how to fix them.\r\nI will be talking about multiple open source projects that can secure code and deployment. I will not cover any commercial products.\r\nFalco\r\nTUF\r\nOpen Policy Agent\r\nBandit (not CNCF)\r\nGitLab (not CNCF)",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "QMZDVX",
    "title": "Is the news media polarized? Or are we being conditioned to think it is?",
    "speakers": [
      {
        "code": "HKHYS9",
        "name": "Aroma Rodrigues",
        "biography": "Aroma Rodrigues is a master's student at UMass Amherst. She believes that Automation is the path to Inclusion. In 2016, a teammate of her \"Shoes for the Visually Impaired\" project presented it at the FOSSASIA. She reads, writes and enjoys walking to explore places. She presently works in a financial services firm and believes that solving problems that she has would solve problems for a large chunk of the world. An ML enthusiast she has about 20+ Coursera Certifications with the respective project work to support her learning in that field. She presented a talk on “De-mystifying Terms and Conditions using NLP” at PyCon 2018 and a talk called “Propaganda Detection in Fake News using Natural Language Processing” at PyCon ZA 2019 in Johannesburg. She spoke on detecting gender roles based biases in school textbooks at PyOhio 2020.",
        "avatar": "https://program.europython.eu/media/avatars/IMG20180523181017_xqVcRmM.jpg",
        "slug": "aroma-rodrigues"
      }
    ],
    "submission_type": "Talk",
    "slug": "is-the-news-media-polarized-or-are-we-being-conditioned-to-think-it-is",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "accepted",
    "abstract": "In this talk, we aim to find if polarization is induced in a neural\r\nnetwork by feeding it newspaper articles with manufactured sentiments according to the\r\nAllsides Media Bias chart for the level of faith people on various aisles of the political\r\nspectrum. This project consists of a set of experiments on similar data-sets from news\r\nagencies across the various subsets in the ”media-bias” chart. News Media perceived bias\r\nis common across consumers that belong to various political affiliations. While anecdotal\r\nevidence of this exists and there exist annotated datasets that aim to annotate the ”spin”\r\na news agency puts on certain events and entities, whether this is a widespread problem\r\nand whether it can be detected by the neural network topically or temporally is a problem that needs to be explored. The news media bias analysis is modelled as a Natural\r\nLanguage Processing sentiment analysis task and a fake news binary classification task to\r\ndeduce the level of polarization in a neural network by feeding it headlines embedded using\r\npre-trained sentiment models from news publications across the political spectrum. When\r\nit came to fake news vulnerability, news from all kinds of perceived politically affiliated\r\nnews media holds up well against a fake news dataset with a very good accuracy. None of\r\nthe accuracies dropped below 95%. This is a significant result that sort of debunks the AllSlides categorization",
    "description": "This work is an example of an intersection of a non\r\nscientific field with computer science and mathematics, trying to quantify, measure and identify\r\nnon mathematical phenomena in the language of mathematics. It is important because it could\r\nbe the basis of the scientific approaches that the next generation policy makers, voters, non\r\nprofit social organizations and governments could use to make life changing decisions for their\r\ncitizens.\r\n2\r\nThe questions that this study tries to answer is whether a neural network can learn biases from\r\nthe news media based on perceived bias scores obtained from independent agencies. It also\r\nseeks to answer whether any of these political leanings of the news media affect the vulnerability of their consumer when it comes to fake news. The results of this experiment aim to show\r\n\r\nConclusions\r\n1. SVMs perform better clustering with respect to the categories than neural networks, however the maximum does not cross 67%\r\n2. The most significant conclusion from this work is that though there is a perceived bias\r\nwhen it comes to news agencies, when looked at from a neural networks standpoint, it\r\nis negligible. Mainstream news agencies are not able to polarize a neural network with\r\ninherent biases in their headlines.\r\n3. There may be topical biases that need to be examined by using an Entity linking and bias\r\ncalculation approach\r\n4. Most mainstream news agencies do not make the consumer vulnerable to believing fake\r\nnews. This study needs to be conducted with data from popular social media ”news”\r\ngroups or popular TV shows that masquerade as news but may technically not even be\r\nnews channels.\r\n5. It is safe to conclude that the perceived bias that stems from social media polarization is\r\nbeing extended to news media when their contribution to the polarization may be negligible.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "RQQYNB",
    "title": "BERT's Achilles' heel? Applying contrastive learning to fight anisotropy in language models.",
    "speakers": [
      {
        "code": "DGHVRT",
        "name": "Aleksander Molak",
        "biography": "I am a Machine Learning Engineer and Researcher at IRONSCALES and ML Researcher at TensorCell. Before joining IRONSCALES, I worked as an Innovation Lead and ML Researcher at Data Science and Artificial Intelligence Center of Excellence at Lingaro, building end-to-end machine learning systems for Fortune Global 100 and 500 companies.\r\nI am a speaker and a blogger, author of #SundayAiPapers - a weekly LinkedIn microblog presenting the most recent papers on natural language processing, causal inference and probabilistic modeling. I am interested in NLP, causality, probabilistic modeling, representation learning and graph neural networks.\r\nI love traveling with my wife. I am passionate about vegan food, languages and running.\r\n\r\nWebsite: https://alxndr.io\r\nLinkedIn: https://www.linkedin.com/in/aleksandermolak/",
        "avatar": "https://program.europython.eu/media/avatars/portrait_square_1000px_3XGszET.jpg",
        "slug": "aleksander-molak"
      }
    ],
    "submission_type": "Talk",
    "slug": "bert-s-achilles-heel-applying-contrastive-learning-to-fight-anisotropy-in-language-models",
    "track": "PyData: Deep Learning, NLP, CV",
    "state": "accepted",
    "abstract": "Transformer models became state-of-the-art in natural language processing. Word representations learned by these models offer great flexibility for many types of downstream tasks from classification to summarization. Nonetheless, these representations suffer from certain conditions that impair their effectiveness. Researchers have demonstrated that BERT and GPT embeddings tend to cluster in a narrow cone of the embedding space which leads to unwanted consequences (e.g. spurious similarities between unrelated words). During the talk we’ll introduce SimCSE – a contrastive learning method that helps to regularize the embeddings and reduce the problem of anisotropy. We will demonstrate hoe SimCSE can be implemented in Python.",
    "description": "Brief Bullet Point Outline:\r\n\r\n- Introduction (1 min)\r\n- A refresher on Transformer model (3 min)\r\n- What is anisotropy? (3 min)\r\n- Contrastive learning – what and why? (5 min)\r\n- Embeddings and SimCSE in Python (13 min)\r\n- Q&A (5 min)\r\n\r\nPrerequisites\r\n\r\nPeople of all backgrounds and experience levels are invited to participate in the talk. To get the most out of the presentation, the following skills are recommended: \r\n\r\n•\tFamiliarity with Python\r\n\r\n•\tGood understanding of basic NLP concepts, in particular embeddings\r\n\r\n•\tBasic understanding of Transformer architecture\r\n\r\n•\tSound understanding of supervised and unsupervised learning",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "HLYETC",
    "title": "I have to Confess, I still Love Pandas",
    "speakers": [
      {
        "code": "8EGVC9",
        "name": "Cheuk Ting Ho",
        "biography": "Before working in Developer Relations, Cheuk has been a Data Scientist in various companies which demands high numerical and programmatical skills, especially in Python. To follow her passion for the tech community, now Cheuk is the Developer Relations Lead at TerminusDB - an open-source graph database. Cheuk maintains its Python client and engages with its user community daily.\r\n\r\nBesides her work, Cheuk enjoys talking about Python on personal streaming platforms and podcasts. Cheuk has also been a speaker at Universities and various conferences. Besides speaking at conferences, Cheuk also organises events for developers. Conferences that Cheuk has organized include EuroPython (which she is a board member of), PyData Global and Pyjamas Conf. Believing in Tech Diversity and Inclusion, Cheuk constantly organizes workshops and mentored sprints for minority groups. In 2021, Cheuk has become a Python Software Foundation fellow.",
        "avatar": "https://program.europython.eu/media/avatars/Cheuk_Ting_Ho_myGoldi.JPG",
        "slug": "cheuk-ting-ho"
      }
    ],
    "submission_type": "Talk",
    "slug": "i-have-to-confess-i-still-love-pandas",
    "track": "PyData: Machine Learning, Stats",
    "state": "confirmed",
    "abstract": "Pandas is the first Python library that I learned to use. It is used by data scientists to manage, transform and inspect data. As more and more open-source tools appear, it seems the spotlight has shifted and I would love to shine some light on this tool that all should know.",
    "description": "In this talk, Cheuk will reapproach Pandas as someone who is a fluent user of the library. Cheuk will review why Pandas is useful to work with data and what advantage it has over the alternatives methods. As Pandas has many functionalities, Cheuk will dissect the discussion on the potential usage of Pandas in day-to-day data science workflow: data inspection, data cleaning, feature engineering etc.\r\n\r\nAfter discussing the advantage of using Pandas, Cheuk will discuss the flip side. What makes Pandas a difficult tool to use at first. Here Cheuk will share how she used it efficiently with new users and some fundamental concepts about Pandas.\r\n\r\nThis talk is for Pandas users (new and old) or potential users. Those who are familiar with Pandas may get a refreshing idea from a new angle about the tool. And for the new users, it will be a good startup guide to make the journey of using it a bit easier.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "YMAR7H",
    "title": "Jupyter - Under the Hood",
    "speakers": [
      {
        "code": "7VMLGN",
        "name": "Dhanshree Arora",
        "biography": "Hi I am Dhanshree, \r\nI have been developing with Python for over 3 years now. I enjoy working with computers. I work with machine learning, backend development, cloud and infrastructure.",
        "avatar": "https://program.europython.eu/media/avatars/image_QQzHuxX.png",
        "slug": "dhanshree-arora"
      }
    ],
    "submission_type": "Talk",
    "slug": "jupyter-under-the-hood",
    "track": "PyData: Software Packages & Jupyter",
    "state": "confirmed",
    "abstract": "Jupyter Notebooks at their core are just JSON documents that contain all your code, markdown styles and outputs. Yet when you run a notebook, there's a lot that's happening under the hood - from starting a session with the notebook server, to launching an IPython kernel, and a rich Web UI communicating with the notebook server and the IPython kernel using Jupyter's REST APIs and ZMQ websockets. We will explore the Jupyter ecosystem (Jupyter, JupyterLab, JupyterHub) and see how this system comes together.",
    "description": "Jupyter Notebooks at their core are just JSON documents that contain all your code, markdown styles and outputs. Yet when you run a notebook, there's a lot that's happening under the hood - from starting a session with the notebook server, to launching an IPython kernel, and a rich Web UI communicating with the notebook server and the IPython kernel using Jupyter's REST APIs and ZMQ websockets. We will explore the Jupyter ecosystem and see how this system comes together. \r\n\r\nThe architecture of all the offerings in the Jupyter Project (such as the classic Jupyter Notebook), the newer JupyterLab IDE, or the scalable multi-user environment - JupyterHub is completely distributed.\r\nAt their core, there's a front end client like a web browser or a qt console that talks to the Notebook server using its many APIs (like the kernel API) and to the language kernel (in our case IPython) using ZMQ Sockets, allowing the Jupyter architecture to scale easily. \r\nIn this presentation, we look closely at these REST API calls, and the ZMQ socket traffic using simple tools like the browser's network tab. We will also try to manipulate a notebook using simple code to get a full appreciation of these internals.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "BL9NGV",
    "title": "Protocols - Static duck typing for decoupled code",
    "speakers": [
      {
        "code": "V7BWTA",
        "name": "Ran Zvi",
        "biography": "I'm a software engineer currently living in USA. I enjoy learning new languages and learning about them.",
        "avatar": "https://program.europython.eu/media/avatars/image1_eD11cms.jpeg",
        "slug": "ran-zvi"
      }
    ],
    "submission_type": "Talk",
    "slug": "protocols-static-duck-typing-for-decoupled-code",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Python introduces Protocols to support static duck typing, where static type checkers (mypy) and other tools can verify code correctness prior to runtime.\r\n\r\nThis was added in order to circumvent explicitly inheriting from ABCs (Abstract base classes) which is \"unpythonic and unlike what one would normally do in idiomatic dynamically typed Python code\" - according to PEP 544.\r\n\r\nWe will explore the different use cases for Protocols and how to use them correctly.",
    "description": "Outline\r\n\r\n- What are protocols:\r\n   - Structural vs nominal typing\r\n   - Static duck typing\r\n   - Difference between ABCs and protocols\r\n\r\n- Examples\r\n    - Simple example\r\n    - Extending protocols\r\n\r\n- Use cases\r\n    - Dynamically typed code\r\n    - Library types\r\n\r\nDuring this talk we will go over Protocols and how they can be employed to achieve better code. Take the following code snippet as an example:\r\n\r\n```python\r\nfrom typing import Sized, Iterable, Iterator\r\n\r\nclass Bucket(Sized, Iterable[int]):\r\n    ...\r\n    def __len__(self) -> int: ...\r\n    def __iter__(self) -> Iterator[int]: ...\r\n```\r\n\r\nThe problem here is that you must explicitly inherit these bases classes to register them as subtypes of their parents.\r\n\r\nThis is particularly difficult to do with library types as the type objects may be hidden deep in the implementation of the library. Also, extensive use of ABCs might impose additional runtime costs.\r\n\r\nConsider the following snippet as a solution:\r\n\r\n```python\r\nfrom typing import Iterator, Iterable\r\n\r\nclass Bucket:\r\n    ...\r\n    def __len__(self) -> int: ...\r\n    def __iter__(self) -> Iterator[int]: ...\r\n\r\ndef collect(items: Iterable[int]) -> int: ...\r\nresult: int = collect(Bucket())  # Passes type check\r\n```\r\n\r\nProtocols enable you to pass static type checking implicitly.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "BADDYW",
    "title": "Secure Python ML: Automated Security Best Practices in Machine Learning",
    "speakers": [
      {
        "code": "EQMGKH",
        "name": "Alejandro Saucedo",
        "biography": "Alejandro is the Chief Scientist at the Institute for Ethical AI & Machine Learning, where he contributes to policy and industry standards on the responsible design, development and operation of AI, including the fields of explainability, GPU acceleration, privacy preserving ML and other key machine learning research areas. Alejandro Saucedo is also Director of Engineering at Seldon Technologies, where he leads teams of machine learning engineers focused on the scalability and extensibility of machine learning deployment and monitoring products. With over 10 years of software development experience, Alejandro has held technical leadership positions across hyper-growth scale-ups and has a strong track record building cross-functional teams of software engineers. He is currently appointed as governing council Member-at-Large at the Association for Computing Machinery, and is currently the Chairperson of the GPU Acceleration Kompute Committee at the Linux Foundation.\r\n\r\nLInkedin: https://linkedin.com/in/axsaucedo\r\nTwitter: https://twitter.com/axsaucedo\r\nGithub: https://github.com/axsaucedo\r\nWebsite: https://ethical.institute/",
        "avatar": "https://program.europython.eu/media/avatars/aletechuk-high-res_m9IQ6Nl.png",
        "slug": "alejandro-saucedo"
      }
    ],
    "submission_type": "Talk",
    "slug": "secure-python-ml-automated-security-best-practices-in-machine-learning",
    "track": "Security",
    "state": "confirmed",
    "abstract": "In this talk we introduce the conceptual and practical topics around MLSecOps that data science practitioners will be able to adopt, implement and/or advocate for. We will also provide an intuition on key security challenges that arise in production machine learning systems as well as best practices and frameworks that can be adopted to help mitigate security risks in ML models, ML pipelines and ML services.",
    "description": "#### Overview\r\n\r\nThe operation and maintenance of large scale production machine learning systems has uncovered new challenges which have required fundamentally different approaches to that of traditional software. The area of security in MLOps has seen a rise in attention as machine learning infrastructure expands to further critical usecases across industry. \r\n\r\nIn this talk we introduce the conceptual and practical topics around MLSecOps that data science practitioners will be able to adopt or advocate for. We will also provide an intuition on key security challenges that arise in production machine learning systems as well as best practices and frameworks that can be adopted to help mitigate security risks in ML models, ML pipelines and ML services. \r\n\r\nWe will cover a practical example showing how we can secure a machine learning model, and showcasing the security risks and best practices that can be adopted during the feature engineering, model training, model deployment and model monitoring stages of the machine learning lifecycle.\r\n\r\n\r\n#### Benefits to the ecosystem\r\n\r\nThis talk will provide practitioners with the intuition and tools to secure production machine learning systems, as well as further the discussion around best practices reinforcing SecOps into MLOps.\r\n\r\nIt will provide best practices on a critical area of machine learning operations which is of paramount importance in production.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "NL8HRY",
    "title": "Build-A-Database with Python",
    "speakers": [
      {
        "code": "RTG9TS",
        "name": "Sangarshanan",
        "biography": "My name is Sangarshanan and I am a Software Engineer. I love making stuff that helps and amuses me in equal measure and standing upside down while holding a banana. When I'm bored you can find me making absurdist memes, yet another Spotify playlist or staring straight into the void",
        "avatar": "https://program.europython.eu/media/avatars/my_pic_AtjHUk4.jpeg",
        "slug": "sangarshanan"
      }
    ],
    "submission_type": "Talk",
    "slug": "build-a-database-with-python",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Databases are beautiful beasts built with several layers of abstractions that we rarely have to know or even care about, now it's time to break them open and discuss the different components that maketh a database and how one would go about building one if they wanted. This would be based on my learnings when I went about building my own Toy Database in Python",
    "description": "This talk will help unlock the internal workings of a Database by breaking down the abstractions that make it. We will use Python as our weapon of choice to slowly discuss how you would \r\ngo about building the different components of a database.\r\n\r\n1) Talking to your Database: We start by building out an interface and a language that helps us communicate with our database. We will use the Prompt toolkit to build a REPL & use a simple SQL-based language with basic regular expressions that can parse it to instruction to execute.\r\n\r\n2) Working with Data: Now that we can communicate with our database using instructions. we start the actual work in building out the Datastore, We initially store all the data in a simple in-memory dictionary and then move to persist this data to disk. We now read the data from the disk to memory every time we query the data and write back the data to the disk but this makes things very slow :(\r\nThis problem is our entry into the beautiful world of Indexes so by building a very basic Btree index to store references in memory to quickly access only what we require from the data on disk we can actually speed up our access times for basic row access queries from O(N) to O(1) where N is the number of rows in a table\r\n\r\n3) Future: We can now proudly demo our new and polished database that can store data, persist it, and can run queries that are quite fast thanks to our Btree Indexes. We also discuss how this Database can be improved in the future by supporting full ACID Transactions, allowing concurrency, and handling locks\r\n\r\nOur Database journey now comes to an End and As they say, The best way to understand something is to build it yourself :)",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "BRSSQK",
    "title": "TDD in Python with pytest",
    "speakers": [
      {
        "code": "7BS3PU",
        "name": "Leonardo Giordani",
        "biography": "Born in 1977 together with Star Wars, bash, Apple ][, Dire Straits, The Silmarillion, and many other great things.\r\n\r\nI started coding in April 1987 on a Sinclair ZX Spectrum. I then moved to MS-DOS PCs and in 1996 I started using Linux and became interested in operating system internals. I love software architectures, algorithms, mathematics and cryptography.\r\n\r\nI’m mainly interested in open source software. I like both the theoretical and practical aspects of computer science.\r\n\r\nI am currently working as a contractor DevOps and Python developer while I design a DevOps bootcamp that I will run in London from June 2022.\r\n\r\nFrom 2013 I blog some technical thoughts at http://thedigitalcatonline.com.\r\n\r\nIn 2018 I published the free book “Clean Architectures in Python” http://bit.ly/getpycabook",
        "avatar": "https://program.europython.eu/media/avatars/Avatar400x400_cuVmtE6.jpg",
        "slug": "leonardo-giordani"
      }
    ],
    "submission_type": "Tutorial",
    "slug": "tdd-in-python-with-pytest",
    "track": "Testing",
    "state": "confirmed",
    "abstract": "This workshop will guide you step-by-step through the implementation of a very simple Python library following a strict TDD workflow. At the end of the workshop you will have grasped the main principles of TDD and learned the fundamentals of the Python testing library pytest.",
    "description": "Test-Driven Development (TDD) is fortunately one of the names that I can spot most frequently when people talk about methodologies. Unfortunately, many programmers still do not follow it, fearing that it will impose a further burden on the already difficult life of a developer.\r\n\r\nTDD is a methodology, something that can help you to create better code. But it is not going to solve all your problems. As with all methodologies you have to pay attention not to commit blindly to it. Try to understand the reasons why certain practices are suggested by the methodology and you will also understand when and why you can or have to be flexible.\r\n\r\nDuring the workshop we will learn what TDD is, and what are the main rules. We will do this developing a very simple Python library together in a sort of a game that mirrors a daily TDD development routine. While we do this, we will also learn how to use pytest, which is one of the most used testing libraries in Python. Oh, we will also learn when NOT to follow the rules!",
    "duration": "180",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "FZQGFP",
    "title": "How to embed a Python interpreter in an iOS app",
    "speakers": [
      {
        "code": "YFCVFV",
        "name": "Łukasz Langa",
        "biography": "CPython Developer in Residence, Python 3.8 and 3.9 release manager, creator of Black, pianist, dad.\r\n\r\nEqually interested in music and software engineering, as a classically-trained pianist and a long-time contributor to the Python programming language. Loves to build software for musical instruments. Makes music under the [RPLKTR](https://rplktr.com/) moniker.",
        "avatar": "https://program.europython.eu/media/avatars/%C5%81ukasz_Langa_Portret_2021.10_Prawy_profil_VNI4Aj1.jpeg",
        "slug": "lukasz-langa"
      }
    ],
    "submission_type": "Talk",
    "slug": "how-to-embed-a-python-interpreter-in-an-ios-app",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Come see how you can make a native mobile app that embeds Python 3.10 to allow users to script app behavior. It's allowed by Apple but is currently underutilized by the app makers. Add superpowers to your iPhone app with Python!\r\n\r\nNative mobile applications have many advantages over mobile websites or apps made with cross-platform toolkits. They will use less battery, allow for richer graphics, more consistent UI behavior, and enable more functionality through device-specific APIs. Wouldn't it be great to have access to all this from Python?\r\n\r\nIn this talk, we'll marry a native iOS app written in Swift with an embedded Python 3.10 interpreter to allow users to customize what the application is doing. We'll go through the entire process of:\r\n\r\n- embedding Python from source;\r\n- building it into the Swift mobile app in Xcode;\r\n- adding a few pre-compiled third-party libraries like numpy and Pillow to broaden the scope of what the user can do;\r\n- running the resulting app on an iPhone 13;\r\n- modifying the app behavior at runtime thanks to our new Python superpowers!\r\n\r\nKnowledge of Swift is not required for attendees of this talk. However, it will be needed later if you're willing to embed Python in an iPhone app. Embedding Python doesn't really let you make an app without knowing Swift. Don't fret though! It's pretty easy to get a hang of Swift when you're fluent in Python.",
    "description": "",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "some"
  },
  {
    "code": "8JSS8X",
    "title": "Lessons learnt from building my own library",
    "speakers": [
      {
        "code": "FDHNUF",
        "name": "Stephanos",
        "biography": "Before becoming a software engineer, Stephanos used to be a number theorist, working on Arithmetic Geometry and Diophantine Equations. During his research, he realised his passion for coding and decided to pursue a career in it.\r\n\r\nHe is currently working as a Software Engineer at Piper, handling the infrastructure, the databases and the backend of the company.",
        "avatar": "https://program.europython.eu/media/avatars/avatar_real_Sb142ar.jpeg",
        "slug": "stephanos"
      }
    ],
    "submission_type": "Talk",
    "slug": "lessons-learnt-from-building-my-own-library",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "One of the many strengths of python is PyPI, which complements and enhances the \"batteries included\" approach of the standard library. Building a library, and publishing it to PyPI has a number of challenges, pitfalls, and choices that someone has to make. In this talk, I would share my journey from v0.1.0 to v1.0.0 and all the moments that I said: \"I wish I knew this thing before\".",
    "description": "This talk is about all the mistakes that I made while building a library, how I would have avoided making them if I started today, what turns I would have taken differently, what choices I made, and why I made them. Examples are drawn from the building of a specific library, but it's not about a specific one. \r\n\r\nThe aim is to give some insights more into how to make choices when building a library available to the world, and less on the specific set of choices that I made.\r\n\r\nIt will not be technically challenging, but some familiarity with the Python ecosystem is advised.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "F9M9BR",
    "title": "Maps with Django",
    "speakers": [
      {
        "code": "BGLPFA",
        "name": "Paolo Melchiorre",
        "biography": "I’m Paolo Melchiorre, a longtime Python backend developer who contributes to the Django project and gives talks at tech conferences.\r\n\r\nI’ve been a GNU/Linux user for over 20 years and I use and promote Free Software.\r\n\r\nI graduated in Software Engineering and I’m an alumnus of the University of Bologna, Italy.\r\n\r\nI’ve been working in the web for 15 years and now I’m the CTO of 20tab, a pythonic software company, for which I work remotely.",
        "avatar": "https://program.europython.eu/media/avatars/1-IMG_20170423_153741-192x192_Q5gms7I.jpg",
        "slug": "paolo-melchiorre"
      }
    ],
    "submission_type": "Talk",
    "slug": "maps-with-django",
    "track": "Django",
    "state": "confirmed",
    "abstract": "Keeping in mind the **Pythonic** principle that _“simple is better than complex”_ we'll see how to create a web **map** with the **Python** based _web framework_ **Django** using its **GeoDjango** module, storing _geographic data_ in your _local database_ on which to run _geospatial queries_.",
    "description": "A *map* in a website is the best way to make geographic data easily accessible to users because it represents, in a simple way, the information relating to a specific geographical area and is in fact used by many online services.\r\n\r\nImplementing a web *map* can be complex and many adopt the strategy of using external services, but in most cases this strategy turns out to be a major data and cost management problem.\r\n\r\nIn this talk we'll see how to create a web *map* with the **Python** based web framework **Django** using its **GeoDjango** module, storing geographic data in your local database on which to run geospatial queries.\r\n\r\nThrough this intervention you can learn how to add a *map* on your website, starting from a simple *map* based on **Spatialite/SQLite** up to a more complex and interactive *map* based on **PostGIS/PostgreSQL**.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "98XE8Q",
    "title": "When to refactor your code into generators and how",
    "speakers": [
      {
        "code": "MDZNRX",
        "name": "Jan-Hein Bührman",
        "biography": "Jan-Hein is a software engineer who witnessed Python’s first baby steps up very close, and loves programming in Python since then. While he worked in different software development roles, he always kept an eye on its development. After he has founded a dedicated Python software unit within Ordina, the company he works for, he’s now back at the work that leaves him with a positive energy balance at the end of the day: programming in Python!",
        "avatar": "https://program.europython.eu/media/avatars/Jan-Hein_helderder_aClbtTP.jpg",
        "slug": "jan-hein-buhrman"
      }
    ],
    "submission_type": "Talk",
    "slug": "when-to-refactor-your-code-into-generators-and-how",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Have you ever found yourself coding variations of a loop construct where fragments of the loop code were exactly the same between the variations? Or, in an attempt to factor out these common parts, you ended up with a loop construct containing a lot of conditional code for varying start, stop, or selection criteria?\r\n\r\nYou might have felt that the end result just didn't look right. Because of the duplicated parts in your code, you noticed that the code didn't conform to the DRY (_Don't Repeat Yourself_) principle. Or, after an attempt to combine the variations into a single loop, with consequently a lot of conditional code, your inner voice told you that the resulting code had become too complex and difficult to maintain.\r\n\r\nThis talk will show you a way out of this situation. It demonstrates how you can create a **generator function** that implements only the common parts of your loop construct. Subsequently you will learn how you can combine this generator function with distinct hand-crafted functions or building blocks from the standard library `itertools` module or the `more-itertools` package.\r\n\r\nAs an example, imagine you'd need to implement some varying functionality based on the Fibonacci sequence. This talk shows you how it would look like before and after you've refactored it into a **pipeline of generators**.\r\n\r\nAfter having seen this pattern, you will recognize more quickly when this kind of refactoring helps you to create more maintainable and more Pythonic code.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "39YWUH",
    "title": "Working with Audio in Python (feat. Pedalboard)",
    "speakers": [
      {
        "code": "XSUHP3",
        "name": "Peter Sobot",
        "biography": "Peter is a Staff Machine Learning Engineer at Spotify in New York, where he helps lead their Audio Intelligence Lab - an ML research lab dedicated to pushing the state of the art in audio-based machine learning. He hails from Canada (and so spells colour the _correct_ way) and when not hacking on audio software, he plays drums and bass in a handful of bands.",
        "avatar": "https://program.europython.eu/media/avatars/2020-09-08-straightened_agoHJCQ.png",
        "slug": "peter-sobot"
      }
    ],
    "submission_type": "Talk",
    "slug": "working-with-audio-in-python-feat-pedalboard",
    "track": "Python Libraries",
    "state": "confirmed",
    "abstract": "Come _hear_ about how to play with audio in only a couple lines of Python!\r\n\r\nPython can do (nearly) anything, but using Python to work with audio has always been a complicated and messy affair. In this talk, we'll be going through how digital audio works, how Python can be used to work with audio data audio, and how a new library - Pedalboard - can help. Pedalboard is a simple, fast, and performant library for doing common audio tasks in Python, including applying effects, using VSTs and audio plugins, and encoding/decoding various audio formats.",
    "description": "Digital audio has been around for 40 years, but working with audio data can still be complicated, especially in Python. In this talk, we'll talk about how digital audio works from the ground up (from sounds, to bytes, to files), how you can use Python to do a bunch of really neat things with audio, and how a new Python library - Pedalboard - helps make working with audio much easier.\r\n\r\nEver used a digital audio workstation (DAW) like GarageBand, Ableton Live, Logic, or Pro Tools? Today's musicians use DAWs as instruments in themselves. But what if you want to combine the power of a DAW with the flexibility of writing your own code?\r\n\r\nPedalboard was built to fill this niche: to pull the power of a DAW into your Python code. Pedalboard makes it easy to build and apply audio effects, read and write audio files, and load audio plug-ins (\"VSTs\") without any complicated dependencies or frameworks. Just `import pedalboard` and go!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "VAGHFS",
    "title": "Using Python to  manage Software Bill of Materials",
    "speakers": [
      {
        "code": "JGAHYH",
        "name": "Anthony Harrison",
        "biography": "An experienced solution architect and cyber security consultant delivering and securing mission critical systems. In his spare time, teaches Python at Manchester CoderDojo and has acts as a mentor for Google Summer of Code (GSOC) projects supported by the Python Software Foundation.",
        "avatar": null,
        "slug": "anthony-harrison"
      }
    ],
    "submission_type": "Talk",
    "slug": "using-python-to-manage-software-bill-of-materials",
    "track": "DevOps",
    "state": "confirmed",
    "abstract": "Software has become increasingly complex as it is constructed from a multitude of software components. In many cases the identification of these components are hidden as they are included through implicit dependencies. Without fully understanding the dependencies of your product it is not possible to understand the current vulnerability status of your software product or system.\r\nIn the past 12 months, there has been an increasing focus on the use Software Bill of Materials (SBOMs) as a key artefact to be delivered with a software product; it will be mandated for all software products in some markets later in 2022. SBOMs which were initially developed to capture the inter-dependencies between components (the focus was on capturing the different types of open source licences used within a product) but with the latest evolution, tracking of vulnerabilities within a product can now be performed.\r\n\r\nThis talk will introduce the SBOM concept and show how Python and its ecosystem can be used to create, manage and use SBOMs as part of your development pipeline.",
    "description": "",
    "duration": "30",
    "python_level": "none",
    "domain_level": "none"
  },
  {
    "code": "BLHK9U",
    "title": "When gRPC met Python",
    "speakers": [
      {
        "code": "WHQUTW",
        "name": "Sanket Singh",
        "biography": "Sanket Singh is an avid and passionate Software Engineer at Google. He has worked with organizations like LinkedIn and Harvard - Berkman Klein Centre in the past. He is curious to build products that can solve simple and complex problems but in a graceful way. \r\nSanket has always been a forefront runner for writing high-quality code. But he also understands that it is a gradual process and thus it is important to always look back every few months and refractor the code whenever possible so that it's easier to debug in case of any issues. \r\nHe has taken multiple workshops in the past to promote the same and encouraged many engineers to not neglect the power of well refactored code. \r\nHe has taught more than 15000 budding engineers and wants to create a community of people with impactful skills. He runs a YouTube channel with a 25k+ subscriber base where he shares unpopular opinions and his tech journey experiences. \r\nIn his free time, he likes to play chess and mentor budding engineers in the industry.",
        "avatar": "https://program.europython.eu/media/avatars/9579-200o200o2-NhELdkcqcQAigZMCd47Efx_gFsCRU8.jpeg",
        "slug": "sanket-singh"
      }
    ],
    "submission_type": "Talk",
    "slug": "when-grpc-met-python",
    "track": "Web",
    "state": "confirmed",
    "abstract": "What if we can have a tool that helps us to do intelligent load balancing or What if we can do selective compression of the data and extremely fast and light weight transfer of data? Then let me introduce gRPC, the technology that helps us to do all of this and how can we integrate gRPC with Python.",
    "description": "gRPC is one of the most new breakthroughs in the world of client server interaction. Using gRPC our client can directly make a call to a server on a different machine as if it were a local object. gRPC has low latency, high scalability and supports multiple use cases for distributed system. We can even build mobile clients which can communicate to a cloud server. gRPC uses Protocol Buffers which is an open source mechanism for serialising structured data, which makes payloads faster, smaller and simpler. In this talk we will try to understand how can we get started with gRPC in Python. grpcio package of python will be used for the demonstration of the examples and we will cover basics of gRPC as well. We will build a basic gRPC service and define protocol buffers for it. Demonstration of how a client and a server can be made through gRPC and how can they communicate.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "8JDRVD",
    "title": "Writing secure code in Python",
    "speakers": [
      {
        "code": "SA3X9R",
        "name": "yyyyyyyan",
        "biography": "yyyyyyyan is a Brazilian Python developer, speaker, privacy freak and security enthusiast. He's worked as a teacher and takes education as a true passion in his life. Whenever he finds time, yyyyyyyan ends up writing blog posts and essays and talking in conferences everywhere, following what he believes is most important in the world - sharing knowledge.",
        "avatar": null,
        "slug": "yyyyyyyan"
      }
    ],
    "submission_type": "Talk",
    "slug": "writing-secure-code-in-python",
    "track": "Security",
    "state": "confirmed",
    "abstract": "The talk will analyze a series of vulnerabilities that given some common mistakes might end up damaging your Python programs (with lots of exemples!). At the end, a precaution and audit method will be presented.",
    "description": "Is your Python code secure? This talk will show how some inattentions, mistakes and assumptions that we, as developers, carry in our code can lead to serious vulnerabilities in our applications. All of that, of course, with lots of examples! At the end, the talk will present a simple way to audit Python code in order to facilitate the maintenance of your security with the identification of possible vulnerabilities.\r\n\r\n- Learn how `eval()`, pickle, and pip are vulnerable to arbitrary code execution\r\n- Understand the importance of cryptographically-secure randomness\r\n- Learn how to audit your code and keep your programs secure\r\n- ... and more!",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "TXFX77",
    "title": "Automated Refactoring Large Python Codebases",
    "speakers": [
      {
        "code": "7DHKEF",
        "name": "Jimmy Lai",
        "biography": "Jimmy Lai is a Software Engineer in Instagram and Carta Infrastructure. He love Python and like to share his love in tech talks. His recent interest is automated refactoring and his prior sharing topics include profiling, optimization, asyncio and type annotations.",
        "avatar": null,
        "slug": "jimmy-lai"
      }
    ],
    "submission_type": "Talk",
    "slug": "automated-refactoring-large-python-codebases",
    "track": "Software Engineering & Architecture",
    "state": "confirmed",
    "abstract": "Like many companies with multi-million-line Python codebases, Carta has struggled to adopt best practices like Black formatting and type annotation. The extra work needed to do the right thing competes with the almost overwhelming need for new development, and unclear code ownership and lack of insight into the size and scope of type problems add to the burden. We’ve greatly mitigated these problems by building an automated refactoring pipeline that applies Black formatting and backfills missing types via incremental Github pull requests. Our refactor applications use LibCST and MonkeyType to modify the Python syntax tree and use GitPython/PyGithub to create and manage pull requests. It divides changes into small, easily reviewed pull requests and assigns appropriate code owners to review them. After creating and merging more than 3,000 pull requests, we have fully converted our large codebase to Black format and have added type annotations to more than 50,000 functions. In this talk, you’ll learn to use LibCST to build automated refactoring tools that fix general Python code quality issues at scale and how to use GitPython/PyGithub to automate the code review process.",
    "description": "",
    "duration": "30",
    "python_level": "some",
    "domain_level": "some"
  },
  {
    "code": "YYQBM3",
    "title": "Choosing the right database for your next project - Looking at options beyond PostgreSQL and MySQL",
    "speakers": [
      {
        "code": "QYTJB9",
        "name": "Marc-Andre Lemburg",
        "biography": "Marc-Andre is the CEO and founder of eGenix.com, a Python-focused project and consulting company based in Germany, specializing in the data, finance and database space. He has a degree in mathematics from the University of Düsseldorf.\r\n\r\nHis work with and for Python started in 1994. He is a Python Core Developer, designed and implemented the Unicode support in Python, and author of the mx Extensions, e.g. mxTools, mxDateTime and mxODBC, which are now distributed and maintained through eGenix.com.\r\n\r\nMarc-Andre is a EuroPython Society (EPS) Fellow, a Python Software Foundation (PSF) founding Fellow and co-founded a local Python meeting in Düsseldorf (PyDDF). He served on the board of the PSF and EPS for many terms and loves to contribute to the growth of Python where ever he can.\r\n\r\nMore information is available on https://malemburg.com/",
        "avatar": "https://program.europython.eu/media/avatars/mal-business-2-170x170_VPXpWrX.jpg",
        "slug": "marc-andre-lemburg"
      }
    ],
    "submission_type": "Talk",
    "slug": "choosing-the-right-database-for-your-next-project-looking-at-options-beyond-postgresql-and-mysql",
    "track": "PyData: Data Engineering",
    "state": "confirmed",
    "abstract": "In the last few years, lots of new database engines have been developed, making the selection process even more challenging than it was before, if you want to maintain an edge.\r\n\r\nThe talk will give an overview of what to consider in different situations.",
    "description": "In the last few years, lots of new database engines have been developed and existing ones have been extended to cover new application spaces and features, making the selection process even more challenging than it was before, if you want to maintain an edge.\r\n\r\nThe talk will highlight the most important database engines to consider and their strengths when using them with Python applications, covering relational databases for general purpose tasks, data warehouse workloads, data analytics, machine learning, streaming data and massive scalability, to name a few aspects.",
    "duration": "30",
    "python_level": "some",
    "domain_level": "expert"
  },
  {
    "code": "XSRUNF",
    "title": "Revolutionizing Education: How Python is Essential Beyond Computer Science",
    "speakers": [
      {
        "code": "9WBNHR",
        "name": "Srivatsa Kundurthy",
        "biography": "Srivatsa Kundurthy is a student based in the Greater New York City Area. As a Python practitioner, his projects include Open Source Intelligence tools for extracting public data and Python notebooks for explaining and simulating chaotic dynamical systems. His work in machine learning includes studying computer vision for problems in ecology and researching neural networks for predicting states of chaotic dynamical systems. Additionally, he is working with the LAION Research Group to develop and strengthen the world’s largest image-text dataset. Apart from Machine Learning Research, Srivatsa is greatly interested in technology policy and community-related issues, particularly those extending to the accessibility of programming education. On the side, Srivatsa enjoys science communication and stargazing.",
        "avatar": "https://program.europython.eu/media/avatars/IMG-1848-Original-Original_qSILF51.jpg",
        "slug": "srivatsa-kundurthy"
      }
    ],
    "submission_type": "Talk",
    "slug": "revolutionizing-education-how-python-is-essential-beyond-computer-science",
    "track": "Education, Teaching & Further Training",
    "state": "confirmed",
    "abstract": "Python has had a transformational effect on countless fields so far, but its permeation can be accelerated through the integration of Python into non-computing coursework. Currently, Python’s presence within secondary and post-secondary schools varies greatly between different institutions, but the continuity in the lack of interdisciplinary coursework is a key limiting factor in the widespread growth of computing education. This is due to a variety of factors, including stereotypes and policy issues, but the bottom line is that Python being restricted to only computing classes restricts career opportunities and misrepresents the professional world. With support from a case-study of college-level physics students exposed to scientific programming, we propose novel methods of integrating Python into traditional coursework during this talk. The overarching mission of this discussion is to demonstrate how Python literacy in non-computing coursework can ultimately help in streamlining processes and accelerating progress in various industries. Attendees will have the opportunity to hear about the exciting prospect of expanding Python beyond the confines of computer science, and will have an exclusive look at a case-study that offers insight into student benefits of integrated coursework: as concerned stakeholders, it is ultimately well-informed Python community members who must unite to make a positive impact on the education system.",
    "description": "Introduction and Motivation: \r\n\r\nThe goal of many within the Python community has been to increase the reach of computer science education in classrooms and institutions around the world. Various studies have pointed out the problem-solving and planning abilities forged by computer science coursework (Salehi et al., 2020; Arfé et al., 2020), and other research has investigated the social stigma (McCartney et al., 2017) and instructor bottlenecks (Raman et al., 2015) that inhibit accessibility to computer science courses. In recent years, significant steps have been taken towards increasing computer science education. However, most of these efforts are largely focused on the introduction of standalone computer science courses rather than integrated coursework.\r\n\r\nIn this talk, we explore the seldom-discussed idea of integrating programming into traditional, non-computing fields such as mathematics, social studies, and science. Interdisciplinary coursework is not a new concept in education: students in an English class are expected to be able to understand, produce, and analyze data visualizations, and mathematics students learn to communicate their work formally in language (Lynch, 2020). However, the current belief in the education realm is that computer science is only for a small sect of highly capable students expressing a deep career interest in the field, a clear misconception that has been debunked by studies (Patitsas et al., 2019) and the experiences of countless professionals applying computational resources in traditionally non-computing industries. As a result of such factors, computer science education is fundamentally isolated from the core curriculum, which is to the detriment of learners and the fields that they pursue. \r\n\r\nIn support of the discussion, we unveil the results of surveys given to physics students enrolled in college-level coursework. In this case-study, students of varied backgrounds in computing are given a lecture on chaotic dynamical systems, and are then shown Python-implemented Runge-Kutta numerical integration methods and simulations to solve and visualize the systems. The insights provided by these students provide great perspective on benefits, reception, and nuances in integrating Python into core classes. Overwhelmingly, many indicated that they believed that the Python demonstrations aided in their understanding of the material. For the attendee, this exclusive look at a case-study will help develop a well-informed perspective on the role of Python beyond just computer science.\r\n\r\nWe conclude the presentation with recommendations for integrated Python coursework, calling for global policymakers and Python community members to step forward and do their part as stakeholders. We pinpoint why Python is the best choice, touching on factors such as its readable syntax, high volume of functional open-source libraries, ever-growing industry demand. The versatility afforded by such elements makes learners of all backgrounds better equipped for solving the challenging problems they will face in their careers. Community members in attendance will gain essential knowledge regarding the issue of Python integration, making them better equipped to argue on behalf of the educational community.\r\n\r\nFor students, seeing how complex differential equations can be numerically approached and solved by computers, understanding how new solar systems are discovered by crunching vast astronomical data, and witnessing a computer rapidly sequence a lengthy DNA chain forges an instant, permanent connection that fosters career interests and prepares students for an increasingly computerized professional world. We seek to advocate for every student to have this opportunity.\r\n\r\nThe key takeaway for talk attendees will be a fresh perspective on the issue of Python’s absence beyond the confines of computer science coursework, as well as methods for mitigation and steps that they can take. Changing education with programming is a long-term investment that will unequivocally accelerate student preparedness and capabilities, but it begins with the focused efforts of an informed public rallying in support of progress. \r\n\r\nSchedule and Format:\r\n\r\n5 minutes: The problem of computer science in education and why we should focus on increasing Python’s role in non-computing classes\r\n\r\n10 minutes: Presenting research: a case study on introducing scientific Python to physics students\r\n\r\n5 minutes: Why Python is the best option and the role and impact on the Python community\r\n\r\n5 minutes: Proposals for Solutions to the Problem\r\n\r\n5 minutes: Question and Answer Session",
    "duration": "30",
    "python_level": "some",
    "domain_level": "none"
  },
  {
    "code": "VFEVKR",
    "title": "Making AI Happen at Your Company",
    "speakers": [
      {
        "code": "8F38DV",
        "name": "Alexander CS Hendorf",
        "biography": null,
        "avatar": "https://program.europython.eu/media/avatars/hendorf-2020_square_1LJOKAe.jpg",
        "slug": "alexander-cs-hendorf"
      }
    ],
    "submission_type": "Talk",
    "slug": "making-ai-happen-at-your-company",
    "track": "~None of the above",
    "state": "confirmed",
    "abstract": "All one needs is strategy, skill and resources to make digitalization and AI happen. So why is everything taking so long? Shouldn’t you all be finished yesterday already? An honest talk about how to address the complexity of making AI happen in enterprises.",
    "description": "Many incumbents are transitioning to new technologies while their businesses operate on systems that are years or decades old. Introducing new technologies is not just about introducing Open Source or introducing community culture or working agile or SCRUM or explaining the complicated technology stuff to executives. The truth is: it requires all of it and likely even more. Mastering innovation requires having many balls in the air at once.\r\nIn this talk I’ll present a transformation use case of an established player including our best practices and anti-patterns.\r\nWe will discuss the following aspects:\r\n\r\n* From idea to strategy\r\n* Assessing the status quo\r\n* Introducing Python and Open Source and what to use (or not)\r\n* Legacy is in the the house, still\r\n* Getting all departments on the same page\r\n* Introducing a community-driven collaborative culture",
    "duration": "30",
    "python_level": "none",
    "domain_level": "some"
  },
  {
    "code": "TF9Z8Q",
    "title": "HPy: a better C API for Python",
    "speakers": [
      {
        "code": "T8FUFL",
        "name": "Ronan Lamy",
        "biography": "I'm a freelance software developer and open-source consultant. I'm a cofounder of HPy and I've been a PyPy core developer since 2012.",
        "avatar": null,
        "slug": "ronan-lamy"
      }
    ],
    "submission_type": "Talk",
    "slug": "hpy-a-better-c-api-for-python",
    "track": "(c)Python Internals",
    "state": "confirmed",
    "abstract": "The official Python C API is specific to the current implementation of CPython. It has served us well and forms the basis upon which our entire extension ecosystem rests. \r\nHowever, it exposes a lot of internal details which makes it hard to implement it for other Python implementations (e.g. PyPy, GraalPython, Jython, IronPython, etc.), and \r\nprevents major evolutions of CPython itself, such as using a GC instead of refcounting, or removing the GIL.\r\n\r\nThis is where HPy comes in. It's a new C API designed from the ground up according to the following goals:\r\n* running much faster on alternate implementations, and at native speed on CPython\r\n* making it possible to compile a single binary which runs unmodified on all supported Python implementations and versions\r\n* being simpler and more manageable than the Python/C API\r\n* providing an improved debugging experience.\r\n\r\nWe'll discuss its current status and show how existing extensions can be gradually ported to it.",
    "description": "",
    "duration": "30",
    "python_level": "expert",
    "domain_level": "some"
  }
]
